{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q3fif1XuUgOa"
      },
      "source": [
        "# Full Flow\n",
        "0. *EDA*\n",
        "1. *파생변수 생성*  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**파생변수 생성된 상태의 df 불러오기**  \n",
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "**2\\. 데이터 전처리**\n",
        "\n",
        "-   수치형 변수 (sen\\_len, word\\_len, winning\\_percent)\n",
        "-   범주형 변수 (first\\_party, second\\_party, issued\\_area)\n",
        "    -   one_hot encoding : 더미변수화\n",
        "-    fact\\_cleaning\n",
        "    -   data\\_cleaning 함수 적용\n",
        "        -   특수문자 및 기호 등 필요없는 문자 제거\n",
        "        -   대소문자 모두 소문자로 통일\n",
        "        -   이름 | 불영어 제거\n",
        "        -   어근 추출 및 표제어 추출\n",
        "    -   벡터화\n",
        "        -   TF-IDF 모듈 적용\n",
        "-    target 변수\n",
        "    -   가중치를 이용해 불균형 해결\n",
        "\n",
        "**3\\. 모델 적합**  \n",
        "\n",
        "- **Pycaret**\n",
        "\n",
        "**4\\. 하이퍼 파라미터 튜닝**          \n",
        "- **GridSearchCV**     \n",
        "\n",
        "**5\\. 모델 앙상블**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "iRPp8KUvoaYe"
      },
      "source": [
        "# 라이브러리 및 데이터 불러오기"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Fr8-RTbxZgiz",
        "outputId": "e41c24c5-bdfb-4126-e6bd-3b30b6ff6162"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NelRLK8QJwCF"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')\n",
        "\n",
        "# TF-IDF\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "# Catboost 모델링\n",
        "from catboost import CatBoostClassifier, Pool"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kleGCkExQIeg",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d087e379-9c6f-4681-9468-f8ca116c5621"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Package indian is already up-to-date!\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    |   Package jeita is already up-to-date!\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Package kimmo is already up-to-date!\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    |   Package knbc is already up-to-date!\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package large_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package lin_thesaurus is already up-to-date!\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Package mac_morpho is already up-to-date!\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    |   Package machado is already up-to-date!\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    |   Package masc_tagged is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_ne_chunker is already up-to-date!\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package maxent_treebank_pos_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package moses_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package movie_reviews is already up-to-date!\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Package mte_teip5 is already up-to-date!\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Package mwa_ppdb is already up-to-date!\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Package names is already up-to-date!\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    |   Package nombank.1.0 is already up-to-date!\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package nonbreaking_prefixes is already up-to-date!\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Package nps_chat is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    |   Package omw-1.4 is already up-to-date!\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package opinion_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package panlex_swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Package paradigms is already up-to-date!\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Package pe08 is already up-to-date!\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package perluniprops is already up-to-date!\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Package pil is already up-to-date!\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Package pl196x is already up-to-date!\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Package porter_test is already up-to-date!\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Package ppattach is already up-to-date!\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package problem_reports is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_1 is already up-to-date!\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package product_reviews_2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    |   Package propbank is already up-to-date!\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Package pros_cons is already up-to-date!\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Package ptb is already up-to-date!\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Package punkt is already up-to-date!\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Package qc is already up-to-date!\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    |   Package reuters is already up-to-date!\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Package rslp is already up-to-date!\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Package rte is already up-to-date!\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sample_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    |   Package semcor is already up-to-date!\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Package senseval is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentence_polarity is already up-to-date!\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sentiwordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Package shakespeare is already up-to-date!\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package sinica_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Package smultron is already up-to-date!\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package snowball_data is already up-to-date!\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package spanish_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Package state_union is already up-to-date!\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Package stopwords is already up-to-date!\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package subjectivity is already up-to-date!\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Package swadesh is already up-to-date!\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Package switchboard is already up-to-date!\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Package tagsets is already up-to-date!\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Package timit is already up-to-date!\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Package toolbox is already up-to-date!\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Package treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package twitter_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr is already up-to-date!\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Package udhr2 is already up-to-date!\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package unicode_samples is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_tagset is already up-to-date!\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package universal_treebanks_v20 is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package vader_lexicon is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Package verbnet3 is already up-to-date!\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Package webtext is already up-to-date!\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Package wmt15_eval is already up-to-date!\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package word2vec_sample is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2021 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet2022 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet31 is already up-to-date!\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Package wordnet_ic is already up-to-date!\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Package words is already up-to-date!\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Package ycoe is already up-to-date!\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n"
          ]
        }
      ],
      "source": [
        "import nltk # 문장 토크나이저\n",
        "nltk.download('all')\n",
        "\n",
        "from nltk.corpus import names #corpus=말뭉치,이름 관련 부분 다루기 위한 객체\n",
        "\n",
        "from nltk.corpus import stopwords # 영어 불용어 - 불용어 모아 놓은 리스트 다운로드해 제거\n",
        "\n",
        "from nltk.tokenize import word_tokenize # 토큰화\n",
        "from nltk.stem.porter import PorterStemmer # 어근 동일화 <-> 이거 말고도 \"Lancaster Stemmer\"\n",
        "\n",
        "# 표제어 추출\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# 정규표현 처리\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Z0Jzl1O2Knbh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e23c8606-7def-4391-a4d3-dbd623a85eb2"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# 구글 드라이브에서 데이터 불러오기\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7GNZs1ciKqzI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bcb88653-a0d8-4279-eeb2-09ebc8656370"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "sample_submission.csv\n",
            "test.csv\n",
            "train.csv\n"
          ]
        }
      ],
      "source": [
        "import zipfile\n",
        "\n",
        "# ZIP 파일 열기\n",
        "with zipfile.ZipFile('/content/gdrive/MyDrive/0000/dacon_lawwinner/open.zip', 'r') as zip_ref:\n",
        "    # 파일 목록 가져오기\n",
        "    file_list = zip_ref.namelist()\n",
        "\n",
        "    # 파일 목록 출력\n",
        "    for file in file_list:\n",
        "        print(file)\n",
        "\n",
        "    # 모든 파일 압축 해제\n",
        "    zip_ref.extractall()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 전처리 하지 않은 raw 데이터셋\n",
        "train = pd.read_csv(\"train.csv\")\n",
        "test = pd.read_csv(\"/content/test.csv\")\n",
        "sample_submission = pd.read_csv(\"/content/sample_submission.csv\")\n",
        "\n",
        "# keywords_list 데이터\n",
        "keywords_list = pd.read_csv('/content/gdrive/MyDrive/0000/dacon_lawwinner/keywords_list.csv')"
      ],
      "metadata": {
        "id": "IXCOcK_xqx35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jlQJ7PNeyk0i"
      },
      "source": [
        "# 파생변수 생성"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yEUcy72P3ad_"
      },
      "source": [
        "### sentence / word Len"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NCK9FTesKJrz"
      },
      "source": [
        "##### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wLJD0bEjylhY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "92b946cb-64d4-452a-fcf1-a243575099b5"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           ID                  first_party                    second_party  \\\n",
              "0  TRAIN_0000            Phil A. St. Amant              Herman A. Thompson   \n",
              "1  TRAIN_0001               Stephen Duncan                  Lawrence Owens   \n",
              "2  TRAIN_0002            Billy Joe Magwood  Tony Patterson, Warden, et al.   \n",
              "3  TRAIN_0003                   Linkletter                          Walker   \n",
              "4  TRAIN_0004           William Earl Fikes                         Alabama   \n",
              "5  TRAIN_0005  C & A Carbone, Inc., et al.              Town of Clarkstown   \n",
              "6  TRAIN_0006       David Jennings, et al.     Alejandro Rodriguez, et al.   \n",
              "7  TRAIN_0007             US Airways, Inc.                         Barnett   \n",
              "8  TRAIN_0008     Ron Davis, Acting Warden                    Hector Ayala   \n",
              "9  TRAIN_0009             Paul A. McDaniel         Selma Cash Paty, et al.   \n",
              "\n",
              "                                               facts  sen_len  word_len  \\\n",
              "0  On June 27, 1962, Phil St. Amant, a candidate ...        7       201   \n",
              "1  Ramon Nelson was riding his bike when he suffe...        7       219   \n",
              "2  An Alabama state court convicted Billy Joe Mag...        8       191   \n",
              "3  Victor Linkletter was convicted in state court...        3        59   \n",
              "4  On April 24, 1953 in Selma, Alabama, an intrud...        9       200   \n",
              "5  A New York town, Clarkstown, allowed a contrac...       11       210   \n",
              "6  Sections of the Immigration and Nationality Ac...        7       264   \n",
              "7  In 1990, Robert Barnett injured his back while...        6       205   \n",
              "8  Hector Ayala, a Hispanic man, was charged with...       12       478   \n",
              "9  Since its first state Constitution in 1796, Te...        7       144   \n",
              "\n",
              "   first_party_winner  \n",
              "0                   1  \n",
              "1                   0  \n",
              "2                   1  \n",
              "3                   0  \n",
              "4                   1  \n",
              "5                   1  \n",
              "6                   1  \n",
              "7                   1  \n",
              "8                   1  \n",
              "9                   1  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-bb9dbf47-6c19-4d9e-a72c-ac9b41014f2d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>facts</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "      <th>first_party_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>Phil A. St. Amant</td>\n",
              "      <td>Herman A. Thompson</td>\n",
              "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
              "      <td>7</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>Stephen Duncan</td>\n",
              "      <td>Lawrence Owens</td>\n",
              "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
              "      <td>7</td>\n",
              "      <td>219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>Billy Joe Magwood</td>\n",
              "      <td>Tony Patterson, Warden, et al.</td>\n",
              "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
              "      <td>8</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>Linkletter</td>\n",
              "      <td>Walker</td>\n",
              "      <td>Victor Linkletter was convicted in state court...</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>William Earl Fikes</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
              "      <td>9</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TRAIN_0005</td>\n",
              "      <td>C &amp; A Carbone, Inc., et al.</td>\n",
              "      <td>Town of Clarkstown</td>\n",
              "      <td>A New York town, Clarkstown, allowed a contrac...</td>\n",
              "      <td>11</td>\n",
              "      <td>210</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TRAIN_0006</td>\n",
              "      <td>David Jennings, et al.</td>\n",
              "      <td>Alejandro Rodriguez, et al.</td>\n",
              "      <td>Sections of the Immigration and Nationality Ac...</td>\n",
              "      <td>7</td>\n",
              "      <td>264</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TRAIN_0007</td>\n",
              "      <td>US Airways, Inc.</td>\n",
              "      <td>Barnett</td>\n",
              "      <td>In 1990, Robert Barnett injured his back while...</td>\n",
              "      <td>6</td>\n",
              "      <td>205</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TRAIN_0008</td>\n",
              "      <td>Ron Davis, Acting Warden</td>\n",
              "      <td>Hector Ayala</td>\n",
              "      <td>Hector Ayala, a Hispanic man, was charged with...</td>\n",
              "      <td>12</td>\n",
              "      <td>478</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TRAIN_0009</td>\n",
              "      <td>Paul A. McDaniel</td>\n",
              "      <td>Selma Cash Paty, et al.</td>\n",
              "      <td>Since its first state Constitution in 1796, Te...</td>\n",
              "      <td>7</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-bb9dbf47-6c19-4d9e-a72c-ac9b41014f2d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-bb9dbf47-6c19-4d9e-a72c-ac9b41014f2d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-bb9dbf47-6c19-4d9e-a72c-ac9b41014f2d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "train['sen_len'] = 0 # 문장 토큰화\n",
        "train['word_len'] = 0 # 단어 토큰화\n",
        "\n",
        "for i in range(len(train)):\n",
        "  train.sen_len[i] = len(nltk.sent_tokenize(train.facts[i]))\n",
        "  train.word_len[i] = len(word_tokenize(train.facts[i]))\n",
        "\n",
        "train = train[['ID', 'first_party', 'second_party', 'facts', 'sen_len', 'word_len', 'first_party_winner']]\n",
        "train.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KF3E14LWKM2N"
      },
      "source": [
        "##### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vMieXMAdcWWB",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a9fa4b18-120a-4f34-bc78-2d3250954638"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "          ID                                        first_party  \\\n",
              "0  TEST_0000                                            Salerno   \n",
              "1  TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n",
              "2  TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n",
              "3  TEST_0003                                    Harold Kaufman    \n",
              "4  TEST_0004                                             Berger   \n",
              "5  TEST_0005                        Air Line Pilots Association   \n",
              "6  TEST_0006           Traffic Stream (BVI) Infrastructure Ltd.   \n",
              "7  TEST_0007                     NRG Power Marketing LLC et al.   \n",
              "8  TEST_0008                                      United States   \n",
              "9  TEST_0009                  United States Catholic Conference   \n",
              "\n",
              "                               second_party  \\\n",
              "0                             United States   \n",
              "1                             Lexecon, Inc.   \n",
              "2     Fox Television Stations, Inc., et al.   \n",
              "3                             United States   \n",
              "4                                    Hanlon   \n",
              "5                                    Miller   \n",
              "6                       JPMorgan Chase Bank   \n",
              "7  Maine Public Utilities Commission et al.   \n",
              "8                         Deondery Chambers   \n",
              "9        Abortion Rights Mobilization, Inc.   \n",
              "\n",
              "                                               facts  sen_len  word_len  \n",
              "0  The 1984 Bail Reform Act allowed the federal c...        2        55  \n",
              "1  Lexecon Inc. was a defendant in a class action...        7       209  \n",
              "2  In 2002 and 2003, Fox Television Stations broa...        7       181  \n",
              "3  During his trial for armed robbery of a federa...        6        99  \n",
              "4  In 1993, a magistrate judge issued a warrant a...        6       154  \n",
              "5  The Air Line Pilots Association (ALPA), a priv...        9       163  \n",
              "6  Traffic Stream (BVI) Infrastructure Ltd. is a ...        5       177  \n",
              "7  The Maine Public Utilities Commission along wi...        7       194  \n",
              "8  Deondery Chambers pled guilty to being a felon...        8       243  \n",
              "9  Abortion Rights Mobilization, Inc. and a colle...        6       225  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-54043bbd-ce06-4146-a76d-b510e65a5f92\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>facts</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>Salerno</td>\n",
              "      <td>United States</td>\n",
              "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n",
              "      <td>Lexecon, Inc.</td>\n",
              "      <td>Lexecon Inc. was a defendant in a class action...</td>\n",
              "      <td>7</td>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n",
              "      <td>Fox Television Stations, Inc., et al.</td>\n",
              "      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n",
              "      <td>7</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>Harold Kaufman</td>\n",
              "      <td>United States</td>\n",
              "      <td>During his trial for armed robbery of a federa...</td>\n",
              "      <td>6</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>Berger</td>\n",
              "      <td>Hanlon</td>\n",
              "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
              "      <td>6</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>TEST_0005</td>\n",
              "      <td>Air Line Pilots Association</td>\n",
              "      <td>Miller</td>\n",
              "      <td>The Air Line Pilots Association (ALPA), a priv...</td>\n",
              "      <td>9</td>\n",
              "      <td>163</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>TEST_0006</td>\n",
              "      <td>Traffic Stream (BVI) Infrastructure Ltd.</td>\n",
              "      <td>JPMorgan Chase Bank</td>\n",
              "      <td>Traffic Stream (BVI) Infrastructure Ltd. is a ...</td>\n",
              "      <td>5</td>\n",
              "      <td>177</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>TEST_0007</td>\n",
              "      <td>NRG Power Marketing LLC et al.</td>\n",
              "      <td>Maine Public Utilities Commission et al.</td>\n",
              "      <td>The Maine Public Utilities Commission along wi...</td>\n",
              "      <td>7</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>TEST_0008</td>\n",
              "      <td>United States</td>\n",
              "      <td>Deondery Chambers</td>\n",
              "      <td>Deondery Chambers pled guilty to being a felon...</td>\n",
              "      <td>8</td>\n",
              "      <td>243</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>TEST_0009</td>\n",
              "      <td>United States Catholic Conference</td>\n",
              "      <td>Abortion Rights Mobilization, Inc.</td>\n",
              "      <td>Abortion Rights Mobilization, Inc. and a colle...</td>\n",
              "      <td>6</td>\n",
              "      <td>225</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-54043bbd-ce06-4146-a76d-b510e65a5f92')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-54043bbd-ce06-4146-a76d-b510e65a5f92 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-54043bbd-ce06-4146-a76d-b510e65a5f92');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ],
      "source": [
        "test['sen_len'] = 0 # 문장 토큰화\n",
        "test['word_len'] = 0 # 단어 토큰화\n",
        "\n",
        "for i in range(len(test)):\n",
        "  test.sen_len[i] = len(nltk.sent_tokenize(test.facts[i]))\n",
        "  test.word_len[i] = len(word_tokenize(test.facts[i]))\n",
        "\n",
        "test = test[['ID', 'first_party', 'second_party', 'facts', 'sen_len', 'word_len']]\n",
        "test.head(10)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "C6vVvxUT3eaw"
      },
      "source": [
        "### issued_area"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "keywords_list = keywords_list.values.tolist()"
      ],
      "metadata": {
        "id": "4E6l8HC3sYCt",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        },
        "outputId": "4d86fba1-056c-416b-d7d5-0217e2915dcb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "AttributeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-31-b6350e365258>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mkeywords_list\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mkeywords_list\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'values'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1S--yzdAzWyj"
      },
      "outputs": [],
      "source": [
        "train['keywords_list'] = keywords_list"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xhgZOAY10UaJ"
      },
      "source": [
        "#### 판결 유형 대분류표 생성\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "![image.png](data:image/png;base64,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)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "HJF-BGZXLrol",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "bc1fc144-54c6-43b9-b9d4-a1f55476adf9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                          main_words        category            main_procssing\n",
              "0                             murder        criminal                    murder\n",
              "1                            robbery        criminal                   robberi\n",
              "2                               rape        criminal                      rape\n",
              "3                              theft        criminal                     theft\n",
              "4                            larceny        criminal                   larceni\n",
              "5                           criminal        criminal                    crimin\n",
              "6                            assault        criminal                   assault\n",
              "7                               drug        criminal                      drug\n",
              "8                            traffic        criminal                   traffic\n",
              "9                                spy        criminal                       spi\n",
              "10                         espionage        criminal                  espionag\n",
              "11                         marijuana        criminal                 marijuana\n",
              "12                              rape        criminal                      rape\n",
              "13                       burglarious        criminal                  burglari\n",
              "14                          lawsuits           civil                   lawsuit\n",
              "15               contract violations           civil           contract violat\n",
              "16                           divorce           civil                    divorc\n",
              "17                     child custody           civil             child custodi\n",
              "18                       inheritance           civil                   inherit\n",
              "19                      labor unions           civil               labor union\n",
              "20                       wage claims           civil                wage claim\n",
              "21                      terminations           civil                    termin\n",
              "22                        defamation           civil                     defam\n",
              "23                           Slander           civil                   slander\n",
              "24                             libel           civil                     libel\n",
              "25                        reputation           civil                     reput\n",
              "26                        bankruptcy           civil                bankruptci\n",
              "27                             fraud           civil                     fraud\n",
              "28                            kidnap           civil                    kidnap\n",
              "29          Constitutional Petitions  constitutional           constitut petit\n",
              "30           constitutional disputes  constitutional          constitut disput\n",
              "31  individual constitutional rights  constitutional  individu constitut right"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1cfd8894-6bf2-46a7-9cd2-081c32c26cd1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>main_words</th>\n",
              "      <th>category</th>\n",
              "      <th>main_procssing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>murder</td>\n",
              "      <td>criminal</td>\n",
              "      <td>murder</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>robbery</td>\n",
              "      <td>criminal</td>\n",
              "      <td>robberi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>rape</td>\n",
              "      <td>criminal</td>\n",
              "      <td>rape</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>theft</td>\n",
              "      <td>criminal</td>\n",
              "      <td>theft</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>larceny</td>\n",
              "      <td>criminal</td>\n",
              "      <td>larceni</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>criminal</td>\n",
              "      <td>criminal</td>\n",
              "      <td>crimin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>assault</td>\n",
              "      <td>criminal</td>\n",
              "      <td>assault</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>drug</td>\n",
              "      <td>criminal</td>\n",
              "      <td>drug</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>traffic</td>\n",
              "      <td>criminal</td>\n",
              "      <td>traffic</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>spy</td>\n",
              "      <td>criminal</td>\n",
              "      <td>spi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>espionage</td>\n",
              "      <td>criminal</td>\n",
              "      <td>espionag</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>marijuana</td>\n",
              "      <td>criminal</td>\n",
              "      <td>marijuana</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>rape</td>\n",
              "      <td>criminal</td>\n",
              "      <td>rape</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>burglarious</td>\n",
              "      <td>criminal</td>\n",
              "      <td>burglari</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>lawsuits</td>\n",
              "      <td>civil</td>\n",
              "      <td>lawsuit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>contract violations</td>\n",
              "      <td>civil</td>\n",
              "      <td>contract violat</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>divorce</td>\n",
              "      <td>civil</td>\n",
              "      <td>divorc</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>child custody</td>\n",
              "      <td>civil</td>\n",
              "      <td>child custodi</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>inheritance</td>\n",
              "      <td>civil</td>\n",
              "      <td>inherit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>labor unions</td>\n",
              "      <td>civil</td>\n",
              "      <td>labor union</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>wage claims</td>\n",
              "      <td>civil</td>\n",
              "      <td>wage claim</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>terminations</td>\n",
              "      <td>civil</td>\n",
              "      <td>termin</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>defamation</td>\n",
              "      <td>civil</td>\n",
              "      <td>defam</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>Slander</td>\n",
              "      <td>civil</td>\n",
              "      <td>slander</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>24</th>\n",
              "      <td>libel</td>\n",
              "      <td>civil</td>\n",
              "      <td>libel</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25</th>\n",
              "      <td>reputation</td>\n",
              "      <td>civil</td>\n",
              "      <td>reput</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>26</th>\n",
              "      <td>bankruptcy</td>\n",
              "      <td>civil</td>\n",
              "      <td>bankruptci</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>27</th>\n",
              "      <td>fraud</td>\n",
              "      <td>civil</td>\n",
              "      <td>fraud</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>28</th>\n",
              "      <td>kidnap</td>\n",
              "      <td>civil</td>\n",
              "      <td>kidnap</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>29</th>\n",
              "      <td>Constitutional Petitions</td>\n",
              "      <td>constitutional</td>\n",
              "      <td>constitut petit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>30</th>\n",
              "      <td>constitutional disputes</td>\n",
              "      <td>constitutional</td>\n",
              "      <td>constitut disput</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>31</th>\n",
              "      <td>individual constitutional rights</td>\n",
              "      <td>constitutional</td>\n",
              "      <td>individu constitut right</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1cfd8894-6bf2-46a7-9cd2-081c32c26cd1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1cfd8894-6bf2-46a7-9cd2-081c32c26cd1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1cfd8894-6bf2-46a7-9cd2-081c32c26cd1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 35
        }
      ],
      "source": [
        "## 형사\n",
        "criminal = ['murder', 'robbery', 'rape', 'theft','larceny', 'criminal','assault',\n",
        "'drug', 'traffic', 'spy', 'espionage', 'marijuana', 'rape', 'burglarious']\n",
        "\n",
        "## 민사\n",
        "civil = ['lawsuits', 'contract violations',\n",
        "'divorce', 'child custody', 'inheritance',\n",
        "'labor unions' , 'wage claims', 'terminations',\n",
        "'defamation','Slander', 'libel', 'reputation','bankruptcy', 'fraud','kidnap'\n",
        "]\n",
        "\n",
        "## 헌법\n",
        "constitutional = ['Constitutional Petitions',\n",
        "'constitutional disputes',\n",
        "'individual constitutional rights']\n",
        "\n",
        "df = pd.DataFrame({\n",
        "    'main_words':criminal + civil + constitutional,\n",
        "    'category' : len(criminal)*[\"criminal\"]+len(civil)*[\"civil\"]+len(constitutional)*[\"constitutional\"]\n",
        "})\n",
        "\n",
        "df['main_procssing']= df['main_words'].apply(cleaning)\n",
        "df"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train : 최종 category 변수 생성"
      ],
      "metadata": {
        "id": "EiFJJWNL_VaW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def finding_cateory(lst):\n",
        "    k = 0\n",
        "    for item in lst:\n",
        "      if item in df.main_procssing.values:\n",
        "        k = df.loc[df['main_procssing'] == item, 'category'].values[0]\n",
        "      # 값이 저장되었다면 for 구문 중단\n",
        "      if k != 0:\n",
        "        break\n",
        "    # k 값이 없다면 기타\n",
        "    if k == 0:\n",
        "      k = 'others'\n",
        "    return k"
      ],
      "metadata": {
        "id": "c1c44gS46Szi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train['category'] = 0\n",
        "\n",
        "for i in range(len(train)):\n",
        "  train['category'][i] = finding_cateory(keywords_list[i])"
      ],
      "metadata": {
        "id": "hrjWpK6jBISt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train = train[['ID', 'first_party', 'second_party', 'facts','category', 'sen_len', 'word_len', 'first_party_winner'  ]]\n",
        "train = train.rename(columns={'category':'issued_area'})\n",
        "train"
      ],
      "metadata": {
        "id": "zNLoWHxX8bnZ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "ffcc99c1-1468-492e-f21a-e0ff30f9e142"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              ID                                   first_party  \\\n",
              "0     TRAIN_0000                             Phil A. St. Amant   \n",
              "1     TRAIN_0001                                Stephen Duncan   \n",
              "2     TRAIN_0002                             Billy Joe Magwood   \n",
              "3     TRAIN_0003                                    Linkletter   \n",
              "4     TRAIN_0004                            William Earl Fikes   \n",
              "...          ...                                           ...   \n",
              "2473  TRAIN_2473  HollyFrontier Cheyenne Refining, LLC, et al.   \n",
              "2474  TRAIN_2474           Grupo Mexicano de Desarrollo, S. A.   \n",
              "2475  TRAIN_2475                                       Peguero   \n",
              "2476  TRAIN_2476        Immigration and Naturalization Service   \n",
              "2477  TRAIN_2477                                       Markman   \n",
              "\n",
              "                             second_party  \\\n",
              "0                      Herman A. Thompson   \n",
              "1                          Lawrence Owens   \n",
              "2          Tony Patterson, Warden, et al.   \n",
              "3                                  Walker   \n",
              "4                                 Alabama   \n",
              "...                                   ...   \n",
              "2473  Renewable Fuels Association, et al.   \n",
              "2474             Alliance Bond Fund, Inc.   \n",
              "2475                        United States   \n",
              "2476                              St. Cyr   \n",
              "2477           Westview Instruments, Inc.   \n",
              "\n",
              "                                                  facts issued_area  sen_len  \\\n",
              "0     On June 27, 1962, Phil St. Amant, a candidate ...      others        7   \n",
              "1     Ramon Nelson was riding his bike when he suffe...    criminal        7   \n",
              "2     An Alabama state court convicted Billy Joe Mag...    criminal        8   \n",
              "3     Victor Linkletter was convicted in state court...      others        3   \n",
              "4     On April 24, 1953 in Selma, Alabama, an intrud...      others        9   \n",
              "...                                                 ...         ...      ...   \n",
              "2473  Congress amended the Clean Air Act through the...      others        5   \n",
              "2474  Alliance Bond Fund, Inc., an investment fund, ...      others        7   \n",
              "2475  In 1992, the District Court sentenced Manuel D...    criminal        6   \n",
              "2476  On March 8, 1996, Enrico St. Cyr, a lawful per...      others        8   \n",
              "2477  Herbert Markman owns the patent to a system th...      others        6   \n",
              "\n",
              "      word_len  first_party_winner  \n",
              "0          201                   1  \n",
              "1          219                   0  \n",
              "2          191                   1  \n",
              "3           59                   0  \n",
              "4          200                   1  \n",
              "...        ...                 ...  \n",
              "2473       144                   1  \n",
              "2474       184                   1  \n",
              "2475       195                   0  \n",
              "2476       194                   0  \n",
              "2477       205                   0  \n",
              "\n",
              "[2478 rows x 8 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-86008bb1-b073-4195-927a-fcaddeac8a80\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>facts</th>\n",
              "      <th>issued_area</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "      <th>first_party_winner</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>Phil A. St. Amant</td>\n",
              "      <td>Herman A. Thompson</td>\n",
              "      <td>On June 27, 1962, Phil St. Amant, a candidate ...</td>\n",
              "      <td>others</td>\n",
              "      <td>7</td>\n",
              "      <td>201</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>Stephen Duncan</td>\n",
              "      <td>Lawrence Owens</td>\n",
              "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>219</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>Billy Joe Magwood</td>\n",
              "      <td>Tony Patterson, Warden, et al.</td>\n",
              "      <td>An Alabama state court convicted Billy Joe Mag...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>8</td>\n",
              "      <td>191</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>Linkletter</td>\n",
              "      <td>Walker</td>\n",
              "      <td>Victor Linkletter was convicted in state court...</td>\n",
              "      <td>others</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>William Earl Fikes</td>\n",
              "      <td>Alabama</td>\n",
              "      <td>On April 24, 1953 in Selma, Alabama, an intrud...</td>\n",
              "      <td>others</td>\n",
              "      <td>9</td>\n",
              "      <td>200</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>TRAIN_2473</td>\n",
              "      <td>HollyFrontier Cheyenne Refining, LLC, et al.</td>\n",
              "      <td>Renewable Fuels Association, et al.</td>\n",
              "      <td>Congress amended the Clean Air Act through the...</td>\n",
              "      <td>others</td>\n",
              "      <td>5</td>\n",
              "      <td>144</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>TRAIN_2474</td>\n",
              "      <td>Grupo Mexicano de Desarrollo, S. A.</td>\n",
              "      <td>Alliance Bond Fund, Inc.</td>\n",
              "      <td>Alliance Bond Fund, Inc., an investment fund, ...</td>\n",
              "      <td>others</td>\n",
              "      <td>7</td>\n",
              "      <td>184</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>TRAIN_2475</td>\n",
              "      <td>Peguero</td>\n",
              "      <td>United States</td>\n",
              "      <td>In 1992, the District Court sentenced Manuel D...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>6</td>\n",
              "      <td>195</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>TRAIN_2476</td>\n",
              "      <td>Immigration and Naturalization Service</td>\n",
              "      <td>St. Cyr</td>\n",
              "      <td>On March 8, 1996, Enrico St. Cyr, a lawful per...</td>\n",
              "      <td>others</td>\n",
              "      <td>8</td>\n",
              "      <td>194</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>TRAIN_2477</td>\n",
              "      <td>Markman</td>\n",
              "      <td>Westview Instruments, Inc.</td>\n",
              "      <td>Herbert Markman owns the patent to a system th...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>205</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2478 rows × 8 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-86008bb1-b073-4195-927a-fcaddeac8a80')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-86008bb1-b073-4195-927a-fcaddeac8a80 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-86008bb1-b073-4195-927a-fcaddeac8a80');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test"
      ],
      "metadata": {
        "id": "cTDtHoZUsrsz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "test['category'] = 0\n",
        "\n",
        "for i in range(len(test)):\n",
        "  test['category'][i] = finding_cateory(keywords_list[i])"
      ],
      "metadata": {
        "id": "jOiqmKN0s2t9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test = test[['ID', 'first_party', 'second_party', 'facts','category', 'sen_len', 'word_len']]\n",
        "test = test.rename(columns={'category':'issued_area'})\n",
        "test"
      ],
      "metadata": {
        "id": "HzXtjgSfspfW",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7349e492-0958-4409-a60a-e33d22b83cf0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID                                        first_party  \\\n",
              "0     TEST_0000                                            Salerno   \n",
              "1     TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n",
              "2     TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n",
              "3     TEST_0003                                    Harold Kaufman    \n",
              "4     TEST_0004                                             Berger   \n",
              "...         ...                                                ...   \n",
              "1235  TEST_1235              Haitian Centers Council, Inc., et al.   \n",
              "1236  TEST_1236                                            Whitman   \n",
              "1237  TEST_1237                Linda A. Matteo and John J. Madigan   \n",
              "1238  TEST_1238      Washington State Apple Advertising Commission   \n",
              "1239  TEST_1239                                   Theodore Stovall   \n",
              "\n",
              "                                           second_party  \\\n",
              "0                                         United States   \n",
              "1                                         Lexecon, Inc.   \n",
              "2                 Fox Television Stations, Inc., et al.   \n",
              "3                                         United States   \n",
              "4                                                Hanlon   \n",
              "...                                                 ...   \n",
              "1235  Chris Sale, Acting Commissioner, Immigration A...   \n",
              "1236               American Trucking Associations, Inc.   \n",
              "1237                                    William G. Barr   \n",
              "1238                                               Hunt   \n",
              "1239                              Wilfred Denno, Warden   \n",
              "\n",
              "                                                  facts issued_area  sen_len  \\\n",
              "0     The 1984 Bail Reform Act allowed the federal c...      others        2   \n",
              "1     Lexecon Inc. was a defendant in a class action...    criminal        7   \n",
              "2     In 2002 and 2003, Fox Television Stations broa...    criminal        7   \n",
              "3     During his trial for armed robbery of a federa...      others        6   \n",
              "4     In 1993, a magistrate judge issued a warrant a...      others        6   \n",
              "...                                                 ...         ...      ...   \n",
              "1235  According to Executive Order No. 12807 signed ...    criminal        5   \n",
              "1236  Section 109(a) of the Clean Air Act (CAA) requ...    criminal        7   \n",
              "1237  Linda Matteo and John Madigan created a plan f...      others       12   \n",
              "1238  In 1972, the North Carolina Board of Agricultu...      others        3   \n",
              "1239  On August 23, 1961, Dr. Paul Berheldt was stab...      others       12   \n",
              "\n",
              "      word_len  \n",
              "0           55  \n",
              "1          209  \n",
              "2          181  \n",
              "3           99  \n",
              "4          154  \n",
              "...        ...  \n",
              "1235       156  \n",
              "1236       221  \n",
              "1237       236  \n",
              "1238        84  \n",
              "1239       240  \n",
              "\n",
              "[1240 rows x 7 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93d7d502-e3a2-432c-b855-0c48d3414fea\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>facts</th>\n",
              "      <th>issued_area</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>Salerno</td>\n",
              "      <td>United States</td>\n",
              "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n",
              "      <td>Lexecon, Inc.</td>\n",
              "      <td>Lexecon Inc. was a defendant in a class action...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>209</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n",
              "      <td>Fox Television Stations, Inc., et al.</td>\n",
              "      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>181</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>Harold Kaufman</td>\n",
              "      <td>United States</td>\n",
              "      <td>During his trial for armed robbery of a federa...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>99</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>Berger</td>\n",
              "      <td>Hanlon</td>\n",
              "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>154</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>TEST_1235</td>\n",
              "      <td>Haitian Centers Council, Inc., et al.</td>\n",
              "      <td>Chris Sale, Acting Commissioner, Immigration A...</td>\n",
              "      <td>According to Executive Order No. 12807 signed ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>5</td>\n",
              "      <td>156</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>TEST_1236</td>\n",
              "      <td>Whitman</td>\n",
              "      <td>American Trucking Associations, Inc.</td>\n",
              "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>221</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>TEST_1237</td>\n",
              "      <td>Linda A. Matteo and John J. Madigan</td>\n",
              "      <td>William G. Barr</td>\n",
              "      <td>Linda Matteo and John Madigan created a plan f...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>236</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>TEST_1238</td>\n",
              "      <td>Washington State Apple Advertising Commission</td>\n",
              "      <td>Hunt</td>\n",
              "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
              "      <td>others</td>\n",
              "      <td>3</td>\n",
              "      <td>84</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>TEST_1239</td>\n",
              "      <td>Theodore Stovall</td>\n",
              "      <td>Wilfred Denno, Warden</td>\n",
              "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>240</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows × 7 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93d7d502-e3a2-432c-b855-0c48d3414fea')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93d7d502-e3a2-432c-b855-0c48d3414fea button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93d7d502-e3a2-432c-b855-0c48d3414fea');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yfbZxF4v3r1x"
      },
      "source": [
        "### winning_percent\n",
        "**first_party_win_percent**\n",
        "  첫 번째 당사자가 승소할 확률.\n",
        "- 출현 빈도가 2이상일때만 반영함. 1일때는 0.5\n",
        "- test에서는 first_party가 train의 first_party와 겹치는 경우에는 해당 사람의 승소할 확률을 반영함. 겹치지 않는 경우는 0.5로 반영함."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wPmczv8VKC3N"
      },
      "source": [
        "##### train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M1n5lsmrvSq-"
      },
      "outputs": [],
      "source": [
        "# winner: 해당 사건에서 승소한 사람\n",
        "# win_percentage: 승소한 사람이 다른 사건에서도 승소할 확률\n",
        "\n",
        "train['winner']=0\n",
        "for i in range(2478):\n",
        "  if train['first_party_winner'][i]==1:\n",
        "    train['winner'][i] = train['first_party'][i]\n",
        "  else:\n",
        "    train['winner'][i] = train['second_party'][i]\n",
        "\n",
        "train['win_percentage']=0\n",
        "for i in range(2478):\n",
        "  winner_exp = len(train.loc[train['first_party'] == train['winner'][i]])\n",
        "  loose_exp = len(train.loc[train['second_party'] == train['winner'][i]])\n",
        "  train['win_percentage'][i]= len(train.loc[train['winner'] == train['winner'][i]]) /(winner_exp + loose_exp)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YXs0jNyHx7Mb"
      },
      "outputs": [],
      "source": [
        "# first_party_frequency: first_party가 나타난 빈도\n",
        "# first_party_win_percent: first_party가 승소할 확률\n",
        "train['first_party_win_percent'] = 0\n",
        "train['first_party_frequency'] = 0\n",
        "\n",
        "for i in range(2478):\n",
        "  train['first_party_frequency'][i] = len(train.loc[train['first_party'] == train['first_party'][i]]) + len(train.loc[train['second_party'] == train['first_party'][i]])\n",
        "\n",
        "  # 출현 빈도가 2이상일때만 반영함. 1일때는 0.5\n",
        "  if train['first_party_frequency'][i] > 1:\n",
        "    p = len(train.loc[train['winner'] == train['first_party'][i]]) / train['first_party_frequency'][i]\n",
        "    train['first_party_win_percent'][i] = p\n",
        "  else:\n",
        "    train['first_party_win_percent'][i] = 0.5"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Xx-CBb9FKE_D"
      },
      "source": [
        "##### test"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4GFNh4P0KfUQ",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "32da3ad5-e642-4bd4-9ce7-082f932f1029"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0       False\n",
              "1       False\n",
              "2       False\n",
              "3       False\n",
              "4       False\n",
              "        ...  \n",
              "2470    False\n",
              "2473    False\n",
              "2474    False\n",
              "2475    False\n",
              "2477    False\n",
              "Length: 2110, dtype: bool"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ],
      "source": [
        "# train 기준 컬럼 생성\n",
        "train_first_party = train[['first_party','first_party_win_percent']]\n",
        "train_first_party = train_first_party.drop_duplicates()\n",
        "train_first_party.duplicated()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "aDEDJwyHKVJl"
      },
      "outputs": [],
      "source": [
        "# 병합\n",
        "test_percent = pd.merge(test.first_party, train_first_party, how='left')\n",
        "test_percent = test_percent.fillna(0.5)\n",
        "\n",
        "# test에 새로운 컬럼 추가\n",
        "test['first_party_win_percent'] = test_percent['first_party_win_percent']"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "##### category"
      ],
      "metadata": {
        "id": "zt4ZEt7B1TcP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_probability(x):\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    elif 0 < x <= 0.33:\n",
        "        return 1\n",
        "    elif 0.33 < x < 0.5:\n",
        "        return 2\n",
        "    elif x == 0.5:\n",
        "        return 3\n",
        "    elif 0.5 < x < 0.57:\n",
        "        return 2\n",
        "    elif 0.57 <= x < 0.75:\n",
        "        return 4\n",
        "    elif 0.75 <= x < 1:\n",
        "        return 5\n",
        "    elif x == 1:\n",
        "        return 6\n",
        "    else:\n",
        "        return -1"
      ],
      "metadata": {
        "id": "2k0r6_V01X_z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_probability2(x):\n",
        "    if 0 <= x < 0.5:\n",
        "        return 1\n",
        "    elif x == 0.5:\n",
        "        return 2\n",
        "    elif 0.5 < x <= 1:\n",
        "        return 3"
      ],
      "metadata": {
        "id": "IMqmwFHR6wZ7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수적용\n",
        "train['winning_percent'] = train['first_party_win_percent'].apply(categorize_probability2)\n",
        "test['winning_percent'] = test['first_party_win_percent'].apply(categorize_probability2)"
      ],
      "metadata": {
        "id": "MbiXSnFp1X4W"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### party 분류\n",
        "Defining Entity type for each party\n",
        "- https://github.com/smitp415/CSCI_544_Final_Project"
      ],
      "metadata": {
        "id": "mNKIfQVKglX_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_sm\")"
      ],
      "metadata": {
        "id": "xS4OCzzHgqWZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def data_distribution_graph(df, cols):\n",
        "    for feature in cols:\n",
        "        fig, ax = plt.subplots()\n",
        "        percent = df.groupby(feature).size() / df[feature].count() * 100\n",
        "        count = df.groupby(feature).size()\n",
        "\n",
        "        if feature == 'facts_len':\n",
        "          count = pd.cut(df['facts_len'], [1,50,500,1000,1500,3000,7000], include_lowest=True)\n",
        "          percent = df.groupby(count).size() / df[feature].count() * 100\n",
        "          count = df.groupby(count).size()\n",
        "          ax = percent.plot(kind='barh', figsize=(10,10), xticks = range(0,101,5), fontsize=12)\n",
        "        elif feature == 'term':\n",
        "          ax = percent.plot(kind='barh', figsize=(10,20), xticks = range(0,101,5), fontsize=12)\n",
        "        else:\n",
        "          ax = percent.plot(kind='barh', figsize=(10,10), xticks = range(0,101,5), fontsize=12)\n",
        "\n",
        "        # print count and percentage on grapp\n",
        "        for i, v in enumerate(zip(percent.values, count.values)):\n",
        "            percent = '{v}%'.format(v = round(v[0],2))\n",
        "            ax.text(v[0] + 2, i - .25, percent, color='black', fontweight='bold', fontsize=12)\n",
        "            ax.text(v[0] + 15, i - .25, str(v[1]), color='blue', fontweight='bold', fontsize=12)\n",
        "\n",
        "        ax.set_title('Data Distribution - {feature}'.format(feature= feature), fontsize=20)\n",
        "        ax.set_xlabel(\"Percentage\", fontsize=20)\n",
        "        ax.set_ylabel(feature, fontsize=20)"
      ],
      "metadata": {
        "id": "V8Cm0X3zgqR4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train"
      ],
      "metadata": {
        "id": "Ehd609yniglg"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, value in train.iterrows():\n",
        "  first = value['first_party']\n",
        "  second = value['second_party']\n",
        "  doc = nlp(first)\n",
        "  for ent in doc.ents:\n",
        "    train.loc[idx, 'first_party_ner'] = ent.label_\n",
        "  doc = nlp(second)\n",
        "  for ent in doc.ents:\n",
        "    train.loc[idx, 'second_party_ner'] = ent.label_"
      ],
      "metadata": {
        "id": "H69tGz2ygqUB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test"
      ],
      "metadata": {
        "id": "lWvq8i8wij9k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for idx, value in test.iterrows():\n",
        "  first = value['first_party']\n",
        "  second = value['second_party']\n",
        "  doc = nlp(first)\n",
        "  for ent in doc.ents:\n",
        "    test.loc[idx, 'first_party_ner'] = ent.label_\n",
        "  doc = nlp(second)\n",
        "  for ent in doc.ents:\n",
        "    test.loc[idx, 'second_party_ner'] = ent.label_"
      ],
      "metadata": {
        "id": "Lh_JlQk7ilhy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### 카테고리 통합\n",
        "\n",
        "person / org / gpe / others ( 나머지 카테고리 포함 + 결측값 )"
      ],
      "metadata": {
        "id": "ZXCPcVE7o8ci"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train.first_party_ner.value_counts(), train.second_party_ner.value_counts(),test.first_party_ner.value_counts(), test.second_party_ner.value_counts()"
      ],
      "metadata": {
        "id": "tLP55WXzilXk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1c9b72e7-8451-43d0-a830-8be1aaa2e62d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PERSON         851\n",
              " ORG            759\n",
              " GPE            498\n",
              " NORP            11\n",
              " CARDINAL         9\n",
              " LOC              4\n",
              " PRODUCT          3\n",
              " LAW              2\n",
              " MONEY            2\n",
              " WORK_OF_ART      2\n",
              " LANGUAGE         1\n",
              " DATE             1\n",
              " FAC              1\n",
              " Name: first_party_ner, dtype: int64,\n",
              " PERSON         790\n",
              " ORG            695\n",
              " GPE            658\n",
              " NORP            18\n",
              " LOC              7\n",
              " CARDINAL         6\n",
              " WORK_OF_ART      4\n",
              " FAC              2\n",
              " PRODUCT          2\n",
              " DATE             1\n",
              " LAW              1\n",
              " Name: second_party_ner, dtype: int64,\n",
              " PERSON      417\n",
              " ORG         366\n",
              " GPE         279\n",
              " NORP         10\n",
              " LAW           3\n",
              " CARDINAL      2\n",
              " LOC           2\n",
              " DATE          1\n",
              " Name: first_party_ner, dtype: int64,\n",
              " PERSON      417\n",
              " ORG         366\n",
              " GPE         279\n",
              " NORP         10\n",
              " LAW           3\n",
              " LOC           2\n",
              " CARDINAL      2\n",
              " DATE          1\n",
              " Name: second_party_ner, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 52
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "tXkM-KPypCS9",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "aeabdb97-a0b1-4435-826b-b94c0a3c1d5f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                           0\n",
              "first_party                  0\n",
              "second_party                 0\n",
              "facts                        0\n",
              "issued_area                  0\n",
              "sen_len                      0\n",
              "word_len                     0\n",
              "first_party_winner           0\n",
              "winner                       0\n",
              "win_percentage               0\n",
              "first_party_win_percent      0\n",
              "first_party_frequency        0\n",
              "winning_percent              0\n",
              "first_party_ner            334\n",
              "second_party_ner           294\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 53
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "통합 !"
      ],
      "metadata": {
        "id": "Xa9mgTRYpeW6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "my_list = ['NORP', 'CARDINAL', 'LOC', 'PRODUCT', 'LAW', 'MONEY',\n",
        "           'WORK_OF_ART', 'LANGUAGE', 'DATE', 'FAC']\n",
        "\n",
        "# 다른 카테고리 모두 others로 통합\n",
        "## train\n",
        "train.loc[train['first_party_ner'].isin(my_list), 'first_party_ner'] = 'others'\n",
        "train.loc[train['second_party_ner'].isin(my_list), 'second_party_ner'] = 'others'\n",
        "\n",
        "## test\n",
        "test.loc[test['first_party_ner'].isin(my_list), 'first_party_ner'] = 'others'\n",
        "test.loc[test['second_party_ner'].isin(my_list), 'second_party_ner'] = 'others'"
      ],
      "metadata": {
        "id": "PkGqPf8TpeLJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 결측값을 'others'로 치환\n",
        "train.fillna('others', inplace=True)\n",
        "test.fillna('others', inplace=True)"
      ],
      "metadata": {
        "id": "ajrjbTXJMOBx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train.isnull().sum()"
      ],
      "metadata": {
        "id": "I1UR98IqMTWy",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "d2254c0f-c978-4697-a59a-971f6c2ebe24"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID                         0\n",
              "first_party                0\n",
              "second_party               0\n",
              "facts                      0\n",
              "issued_area                0\n",
              "sen_len                    0\n",
              "word_len                   0\n",
              "first_party_winner         0\n",
              "winner                     0\n",
              "win_percentage             0\n",
              "first_party_win_percent    0\n",
              "first_party_frequency      0\n",
              "winning_percent            0\n",
              "first_party_ner            0\n",
              "second_party_ner           0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 56
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train.first_party_ner.value_counts(), train.second_party_ner.value_counts(),test.first_party_ner.value_counts(), test.second_party_ner.value_counts()"
      ],
      "metadata": {
        "id": "IkBsN9E4l7Fc",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "da7d1971-3d44-4694-973b-8bfc8a42672e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(PERSON    851\n",
              " ORG       759\n",
              " GPE       498\n",
              " others    370\n",
              " Name: first_party_ner, dtype: int64,\n",
              " PERSON    790\n",
              " ORG       695\n",
              " GPE       658\n",
              " others    335\n",
              " Name: second_party_ner, dtype: int64,\n",
              " PERSON    417\n",
              " ORG       366\n",
              " GPE       279\n",
              " others    178\n",
              " Name: first_party_ner, dtype: int64,\n",
              " PERSON    417\n",
              " ORG       366\n",
              " GPE       279\n",
              " others    178\n",
              " Name: second_party_ner, dtype: int64)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### party name 치환"
      ],
      "metadata": {
        "id": "3WZ8uOMMuiMH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 이름 치환함수\n",
        "def replace_name(name, text, replace_word):\n",
        "    names = name.split('|')\n",
        "    words = text.split()\n",
        "    for word in words:\n",
        "      for n in names:\n",
        "        if n in word:\n",
        "            text = text.replace(word, replace_word)\n",
        "\n",
        "    return text\n",
        "\n",
        "# 정규표현식으로 first_party 여러번 중복 연달아 나오는 거 한 번만 나오게 바꾸기\n",
        "def remove_duplicates(text):\n",
        "    modified_text1 = re.sub(r'(<p1>\\s*)+', '<p1> ', text)\n",
        "    modified_text2 = re.sub(r'(<p2>\\s*)+', '<p2> ', modified_text1)\n",
        "\n",
        "    return modified_text2"
      ],
      "metadata": {
        "id": "E9CkvT67xUmB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### train"
      ],
      "metadata": {
        "id": "fCY0JVdHw2fb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 손실 방지를 위해 값 복사\n",
        "train['first_party1'] = train['first_party'].str.strip()\n",
        "train['second_party1'] = train['second_party'].str.strip()\n",
        "train['facts1'] = train['facts']\n",
        "\n",
        "# 이름 치환을 위한 base\n",
        "train['first_party1'] = train['first_party1'].str.replace(\" \", \"|\")\n",
        "train['second_party1'] = train['second_party1'].str.replace(\" \", \"|\")"
      ],
      "metadata": {
        "id": "bULyiB2LumPY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 각각 적용\n",
        "for i in range(len(train)):\n",
        "  train['facts1'][i] = replace_name(train['first_party1'][i], train['facts1'][i], '<p1>')\n",
        "  train['facts1'][i] = replace_name(train['second_party1'][i], train['facts1'][i], '<p2>')\n",
        "  train['facts1'][i] = remove_duplicates(train['facts1'][i])"
      ],
      "metadata": {
        "id": "9N8W7dFoxUhr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### test"
      ],
      "metadata": {
        "id": "HaNFyCf8yeDY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 손실 방지를 위해 값 복사\n",
        "test['first_party1'] = test['first_party'].str.strip()\n",
        "test['second_party1'] = test['second_party'].str.strip()\n",
        "test['facts1'] = test['facts']\n",
        "\n",
        "# 이름 치환을 위한 base\n",
        "test['first_party1'] = test['first_party1'].str.replace(\" \", \"|\")\n",
        "test['second_party1'] = test['second_party1'].str.replace(\" \", \"|\")"
      ],
      "metadata": {
        "id": "4pqoMYLjyTLE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 함수 각각 적용\n",
        "for i in range(len(test)):\n",
        "  test['facts1'][i] = replace_name(test['first_party1'][i], test['facts1'][i], '<p1>')\n",
        "  test['facts1'][i] = replace_name(test['second_party1'][i], test['facts1'][i], '<p2>')\n",
        "  test['facts1'][i] = remove_duplicates(test['facts1'][i])"
      ],
      "metadata": {
        "id": "B0isBHiQyTEr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test"
      ],
      "metadata": {
        "id": "l_vCuq2l7_2H",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1a4356a8-1a2f-400f-b981-e090bb94da4e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "             ID                                        first_party  \\\n",
              "0     TEST_0000                                            Salerno   \n",
              "1     TEST_0001             Milberg Weiss Bershad Hynes and Lerach   \n",
              "2     TEST_0002  No. 07-582\\t Title: \\t Federal Communications ...   \n",
              "3     TEST_0003                                    Harold Kaufman    \n",
              "4     TEST_0004                                             Berger   \n",
              "...         ...                                                ...   \n",
              "1235  TEST_1235              Haitian Centers Council, Inc., et al.   \n",
              "1236  TEST_1236                                            Whitman   \n",
              "1237  TEST_1237                Linda A. Matteo and John J. Madigan   \n",
              "1238  TEST_1238      Washington State Apple Advertising Commission   \n",
              "1239  TEST_1239                                   Theodore Stovall   \n",
              "\n",
              "                                           second_party  \\\n",
              "0                                         United States   \n",
              "1                                         Lexecon, Inc.   \n",
              "2                 Fox Television Stations, Inc., et al.   \n",
              "3                                         United States   \n",
              "4                                                Hanlon   \n",
              "...                                                 ...   \n",
              "1235  Chris Sale, Acting Commissioner, Immigration A...   \n",
              "1236               American Trucking Associations, Inc.   \n",
              "1237                                    William G. Barr   \n",
              "1238                                               Hunt   \n",
              "1239                              Wilfred Denno, Warden   \n",
              "\n",
              "                                                  facts issued_area  sen_len  \\\n",
              "0     The 1984 Bail Reform Act allowed the federal c...      others        2   \n",
              "1     Lexecon Inc. was a defendant in a class action...    criminal        7   \n",
              "2     In 2002 and 2003, Fox Television Stations broa...    criminal        7   \n",
              "3     During his trial for armed robbery of a federa...      others        6   \n",
              "4     In 1993, a magistrate judge issued a warrant a...      others        6   \n",
              "...                                                 ...         ...      ...   \n",
              "1235  According to Executive Order No. 12807 signed ...    criminal        5   \n",
              "1236  Section 109(a) of the Clean Air Act (CAA) requ...    criminal        7   \n",
              "1237  Linda Matteo and John Madigan created a plan f...      others       12   \n",
              "1238  In 1972, the North Carolina Board of Agricultu...      others        3   \n",
              "1239  On August 23, 1961, Dr. Paul Berheldt was stab...      others       12   \n",
              "\n",
              "      word_len  first_party_win_percent  winning_percent second_party_ner  \\\n",
              "0           55                      0.5                2              GPE   \n",
              "1          209                      0.5                2              ORG   \n",
              "2          181                      0.5                2              ORG   \n",
              "3           99                      0.5                2              GPE   \n",
              "4          154                      0.5                2           others   \n",
              "...        ...                      ...              ...              ...   \n",
              "1235       156                      0.5                2              ORG   \n",
              "1236       221                      0.5                2              ORG   \n",
              "1237       236                      0.5                2           PERSON   \n",
              "1238        84                      0.5                2           PERSON   \n",
              "1239       240                      0.5                2              GPE   \n",
              "\n",
              "     first_party_ner                                       first_party1  \\\n",
              "0             others                                            Salerno   \n",
              "1             PERSON             Milberg|Weiss|Bershad|Hynes|and|Lerach   \n",
              "2                ORG  No.|07-582\\t|Title:|\\t|Federal|Communications|...   \n",
              "3             PERSON                                     Harold|Kaufman   \n",
              "4             PERSON                                             Berger   \n",
              "...              ...                                                ...   \n",
              "1235             ORG              Haitian|Centers|Council,|Inc.,|et|al.   \n",
              "1236          others                                            Whitman   \n",
              "1237          PERSON                Linda|A.|Matteo|and|John|J.|Madigan   \n",
              "1238             ORG      Washington|State|Apple|Advertising|Commission   \n",
              "1239          PERSON                                   Theodore|Stovall   \n",
              "\n",
              "                                          second_party1  \\\n",
              "0                                         United|States   \n",
              "1                                         Lexecon,|Inc.   \n",
              "2                 Fox|Television|Stations,|Inc.,|et|al.   \n",
              "3                                         United|States   \n",
              "4                                                Hanlon   \n",
              "...                                                 ...   \n",
              "1235  Chris|Sale,|Acting|Commissioner,|Immigration|A...   \n",
              "1236               American|Trucking|Associations,|Inc.   \n",
              "1237                                    William|G.|Barr   \n",
              "1238                                               Hunt   \n",
              "1239                              Wilfred|Denno,|Warden   \n",
              "\n",
              "                                                 facts1  \n",
              "0     The 1984 Bail Reform Act allowed the federal c...  \n",
              "1     Lexecon <p2> was a defendant in a class action...  \n",
              "2     In 2002 and 2003, <p2> Stations broadcast the ...  \n",
              "3     During his trial for armed robbery of a federa...  \n",
              "4     In 1993, a magistrate judge issued a warrant a...  \n",
              "...                                                 ...  \n",
              "1235  According to Executive Order No. 12807 signed ...  \n",
              "1236  Section 109(a) of the Clean Air Act (CAA) requ...  \n",
              "1237  <p1> created a plan for utilizing $2.6 million...  \n",
              "1238  In 1972, the North Carolina Board of Agricultu...  \n",
              "1239  On August 23, 1961, Dr. Paul Berheldt was stab...  \n",
              "\n",
              "[1240 rows x 14 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-7957540d-daef-49a5-a3e2-44f1735bbf4d\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>facts</th>\n",
              "      <th>issued_area</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "      <th>first_party_win_percent</th>\n",
              "      <th>winning_percent</th>\n",
              "      <th>second_party_ner</th>\n",
              "      <th>first_party_ner</th>\n",
              "      <th>first_party1</th>\n",
              "      <th>second_party1</th>\n",
              "      <th>facts1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>Salerno</td>\n",
              "      <td>United States</td>\n",
              "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>GPE</td>\n",
              "      <td>others</td>\n",
              "      <td>Salerno</td>\n",
              "      <td>United|States</td>\n",
              "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>Milberg Weiss Bershad Hynes and Lerach</td>\n",
              "      <td>Lexecon, Inc.</td>\n",
              "      <td>Lexecon Inc. was a defendant in a class action...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>209</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>ORG</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>Milberg|Weiss|Bershad|Hynes|and|Lerach</td>\n",
              "      <td>Lexecon,|Inc.</td>\n",
              "      <td>Lexecon &lt;p2&gt; was a defendant in a class action...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>No. 07-582\\t Title: \\t Federal Communications ...</td>\n",
              "      <td>Fox Television Stations, Inc., et al.</td>\n",
              "      <td>In 2002 and 2003, Fox Television Stations broa...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>181</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>No.|07-582\\t|Title:|\\t|Federal|Communications|...</td>\n",
              "      <td>Fox|Television|Stations,|Inc.,|et|al.</td>\n",
              "      <td>In 2002 and 2003, &lt;p2&gt; Stations broadcast the ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>Harold Kaufman</td>\n",
              "      <td>United States</td>\n",
              "      <td>During his trial for armed robbery of a federa...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>99</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>GPE</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>Harold|Kaufman</td>\n",
              "      <td>United|States</td>\n",
              "      <td>During his trial for armed robbery of a federa...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>Berger</td>\n",
              "      <td>Hanlon</td>\n",
              "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>154</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>others</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>Berger</td>\n",
              "      <td>Hanlon</td>\n",
              "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>TEST_1235</td>\n",
              "      <td>Haitian Centers Council, Inc., et al.</td>\n",
              "      <td>Chris Sale, Acting Commissioner, Immigration A...</td>\n",
              "      <td>According to Executive Order No. 12807 signed ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>5</td>\n",
              "      <td>156</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>Haitian|Centers|Council,|Inc.,|et|al.</td>\n",
              "      <td>Chris|Sale,|Acting|Commissioner,|Immigration|A...</td>\n",
              "      <td>According to Executive Order No. 12807 signed ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>TEST_1236</td>\n",
              "      <td>Whitman</td>\n",
              "      <td>American Trucking Associations, Inc.</td>\n",
              "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>221</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>ORG</td>\n",
              "      <td>others</td>\n",
              "      <td>Whitman</td>\n",
              "      <td>American|Trucking|Associations,|Inc.</td>\n",
              "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>TEST_1237</td>\n",
              "      <td>Linda A. Matteo and John J. Madigan</td>\n",
              "      <td>William G. Barr</td>\n",
              "      <td>Linda Matteo and John Madigan created a plan f...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>236</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>Linda|A.|Matteo|and|John|J.|Madigan</td>\n",
              "      <td>William|G.|Barr</td>\n",
              "      <td>&lt;p1&gt; created a plan for utilizing $2.6 million...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>TEST_1238</td>\n",
              "      <td>Washington State Apple Advertising Commission</td>\n",
              "      <td>Hunt</td>\n",
              "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
              "      <td>others</td>\n",
              "      <td>3</td>\n",
              "      <td>84</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>ORG</td>\n",
              "      <td>Washington|State|Apple|Advertising|Commission</td>\n",
              "      <td>Hunt</td>\n",
              "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>TEST_1239</td>\n",
              "      <td>Theodore Stovall</td>\n",
              "      <td>Wilfred Denno, Warden</td>\n",
              "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>240</td>\n",
              "      <td>0.5</td>\n",
              "      <td>2</td>\n",
              "      <td>GPE</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>Theodore|Stovall</td>\n",
              "      <td>Wilfred|Denno,|Warden</td>\n",
              "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows × 14 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-7957540d-daef-49a5-a3e2-44f1735bbf4d')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-7957540d-daef-49a5-a3e2-44f1735bbf4d button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-7957540d-daef-49a5-a3e2-44f1735bbf4d');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 63
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_hkRipUgK4Bp"
      },
      "source": [
        "# Data Preprocessing"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## df 확인"
      ],
      "metadata": {
        "id": "8GBBZDkAdSMp"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train[['ID',\n",
        "                  'first_party_ner', 'second_party_ner',\n",
        "                  'facts1',\n",
        "                  'issued_area',\n",
        "                 'sen_len', 'word_len',\n",
        "                  'winning_percent',\n",
        "                  'first_party_winner']]\n",
        "test_df = test[['ID',\n",
        "                  'first_party_ner', 'second_party_ner',\n",
        "                  'facts1',\n",
        "                  'issued_area',\n",
        "                 'sen_len', 'word_len',\n",
        "                  'winning_percent']]\n",
        "\n",
        "train_df = train_df.rename(columns={\"first_party_ner\":\"first_party\",\n",
        "                                    \"second_party_ner\":\"second_party\",\n",
        "                                    'facts1':\"fact\",\n",
        "                                    \"first_party_win_percent\":\"winning_percent\"\n",
        "                                    })\n",
        "test_df = test_df.rename(columns={\"first_party_ner\":\"first_party\",\n",
        "                                    \"second_party_ner\":\"second_party\",\n",
        "                                    'facts1':\"fact\",\n",
        "                                    \"first_party_win_percent\":\"winning_percent\"\n",
        "                                    })\n",
        "\n",
        "# feature1, feature2를 범주형 변수로 변경\n",
        "train_df['first_party'] = train_df['first_party'].astype('category')\n",
        "train_df['second_party'] = train_df['second_party'].astype('category')\n",
        "train_df['issued_area'] = train_df['issued_area'].astype('category')\n",
        "train_df['winning_percent'] = train_df['winning_percent'].astype('category')\n",
        "\n",
        "test_df['first_party'] = test_df['first_party'].astype('category')\n",
        "test_df['second_party'] = test_df['second_party'].astype('category')\n",
        "test_df['issued_area'] = test_df['issued_area'].astype('category')"
      ],
      "metadata": {
        "id": "XnZ9gepRdRe1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "NDMI7GTLrEac"
      },
      "source": [
        "## one_hot"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UQMsYF3jt8e6"
      },
      "outputs": [],
      "source": [
        "# 특정 범주형 변수(categorical variable)을 더미변수 생성\n",
        "train_cat = pd.get_dummies(data = train_df[[\"first_party\",\"second_party\",\"issued_area\"]], drop_first=True)\n",
        "test_cat = pd.get_dummies(data = test_df[[\"first_party\",\"second_party\",\"issued_area\"]], drop_first=True)\n",
        "\n",
        "#train_cat = train_df[list(train_df.select_dtypes(include='category').columns)]\n",
        "#test_cat = test_df[list(train_df.select_dtypes(include='category').columns)]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CZ7zdXtQuHX9"
      },
      "source": [
        "## fact_cleaning"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pSw-PEiTuLdM"
      },
      "outputs": [],
      "source": [
        "# 영어 데이터 전처리 함수\n",
        "stops = set(stopwords.words('english'))\n",
        "ps = nltk.stem.porter.PorterStemmer()\n",
        "all_names=set(names.words())\n",
        "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "\n",
        "def cleaning(str):\n",
        "    replaceAll = str\n",
        "\n",
        "    # 특수문자 및 기호 등 필요없는 문자 제거\n",
        "    words = replaceAll.split()\n",
        "    only_english = ''\n",
        "    for word in words:\n",
        "      if word in ['<p1>','<p2>']:\n",
        "        only_english = only_english + word + ' '\n",
        "      else:\n",
        "        only_english += re.sub(r\"[^a-zA-Z]\", ' ', word)\n",
        "        only_english += ' '  # 띄어쓰기 추가\n",
        "    only_english = only_english.strip()\n",
        "\n",
        "    # 대소문자 모두 소문자로 통일\n",
        "    no_capitals = only_english.lower().split()\n",
        "\n",
        "    # 이름, 불용어(분석에 필요없는 토큰) 제거\n",
        "    all_names=set(names.words())\n",
        "    no_stops = [word for word in no_capitals if not word in all_names|stops]\n",
        "\n",
        "    # 표제어 : 단어의 원형 형태를 나타내며, 명사의 경우 복수형이나 동사의 경우 시제 등을 고려하여 변환\n",
        "    lem_text = [lem.lemmatize(word, pos='v') for word in no_stops]\n",
        "\n",
        "    # 어근 추츨 : 단어의 형태를 보존하는 특징이 있지만 추출된 어근이 실제로는 사전에 존재하지 않은 단어일 수 있음\n",
        "    stemmer_words = [ps.stem(word) for word in lem_text]\n",
        "\n",
        "    # back to string from list\n",
        "    text = \" \".join(stemmer_words)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mIEHM_-PzD0i"
      },
      "outputs": [],
      "source": [
        "# max_features: 기본값은 None이며, 추출할 최대 특징 수를 지정\n",
        "vectorizer = TfidfVectorizer(max_features=400)\n",
        "\n",
        "def get_vector(vectorizer, df, train_mode):\n",
        "    if train_mode:\n",
        "        X_facts = vectorizer.fit_transform(df['fact_processing'])\n",
        "    else:\n",
        "        X_facts = vectorizer.transform(df['fact_processing'])\n",
        "\n",
        "    X = np.concatenate([X_facts.todense()], axis=1)\n",
        "    return X"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Nlk5XpU1uPH3"
      },
      "outputs": [],
      "source": [
        "# 데이터 클리닝\n",
        "train_df[\"fact_processing\"] = train_df[\"fact\"].apply(cleaning)\n",
        "#train_fact = train_df[\"fact_processing\"]\n",
        "\n",
        "test_df[\"fact_processing\"] = test_df[\"fact\"].apply(cleaning)\n",
        "#test_fact = test_df[\"fact_processing\"]"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[['fact_processing']]"
      ],
      "metadata": {
        "id": "MnDzOp-zrLmE",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e48bba48-d04f-47d9-bbda-40697721956b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "                                        fact_processing\n",
              "0     june <p1> candid public offic make televis spe...\n",
              "1     ramon nelson rid bike suffer lethal blow back ...\n",
              "2     alabama state court convict <p1> murder senten...\n",
              "3     victor <p1> convict state court evid illeg obt...\n",
              "4     april selma <p2> intrud break apart daughter c...\n",
              "...                                                 ...\n",
              "2473  congress amend clean air act energi polici act...\n",
              "2474  <p2> invest fund purchas approxim million unse...\n",
              "2475  district court sentenc manuel <p1> month impri...\n",
              "2476  march enrico <p2> law perman resid plead guilt...\n",
              "2477  herbert <p1> own patent system track cloth dri...\n",
              "\n",
              "[2478 rows x 1 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-32561c7d-27a0-4448-a4a5-9139ed3fe7f1\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>fact_processing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>june &lt;p1&gt; candid public offic make televis spe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>ramon nelson rid bike suffer lethal blow back ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>alabama state court convict &lt;p1&gt; murder senten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>victor &lt;p1&gt; convict state court evid illeg obt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>april selma &lt;p2&gt; intrud break apart daughter c...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>congress amend clean air act energi polici act...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>&lt;p2&gt; invest fund purchas approxim million unse...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>district court sentenc manuel &lt;p1&gt; month impri...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>march enrico &lt;p2&gt; law perman resid plead guilt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>herbert &lt;p1&gt; own patent system track cloth dri...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2478 rows × 1 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-32561c7d-27a0-4448-a4a5-9139ed3fe7f1')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-32561c7d-27a0-4448-a4a5-9139ed3fe7f1 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-32561c7d-27a0-4448-a4a5-9139ed3fe7f1');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LiayMlTPzGsC"
      },
      "outputs": [],
      "source": [
        "# 데이터 벡터화\n",
        "train_fact = get_vector(vectorizer, train_df, True)\n",
        "train_fact = np.asarray(train_fact)\n",
        "train_fact = pd.DataFrame(data=train_fact, columns=vectorizer.get_feature_names_out())\n",
        "\n",
        "test_fact = get_vector(vectorizer, test_df, True)\n",
        "test_fact = np.asarray(test_fact)\n",
        "test_fact = pd.DataFrame(data=test_fact, columns=vectorizer.get_feature_names_out())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0o54bQ-7vJmi"
      },
      "source": [
        "## 수치형"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-dqJ80XUrEOx"
      },
      "outputs": [],
      "source": [
        "train_num = train_df[['sen_len', 'word_len']]\n",
        "train_target = train_df[['first_party_winner']]\n",
        "\n",
        "test_num = train_df[['sen_len', 'word_len']]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "7PQ6PkqcpSfm"
      },
      "source": [
        "## df 통합"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "utGhG0_jpUqN"
      },
      "outputs": [],
      "source": [
        "train_fin = pd.concat([train_fact,train_cat,train_num,train_target],axis=1,join='inner')\n",
        "test_fin = pd.concat([test_fact, test_cat, test_num],axis=1,join='inner')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DsTjkZ-DLSQd"
      },
      "source": [
        "# Define Model & Train"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train_fin.drop(columns={'first_party_winner'})\n",
        "y = train_fin['first_party_winner']\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                            #        test_size=0.2,\n",
        "                                             #       random_state=0)"
      ],
      "metadata": {
        "id": "P7g_JxMqAar6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0sBWBvGTMySZ"
      },
      "source": [
        "## CatBoost Classifier\n",
        "- 범주형 변수를 One-hot Encoding, Label Encoding 등 encoding 작업을 하지 않고도 그대로 모델의 input으로 사용\n",
        "- 하지만 범주형 변수의 cardinality가 작은 경우에는 One-hot Encoding을 진행\n",
        "  - Python의 CatBoostClassifier 혹은 CatBoostRegressor의 one_hot_max_size를 설정하면 범주형 변수의 범주 수가 지정된 값보다 작으면 One-hot Encoding을 진행\n",
        "\n",
        "\n",
        "\n",
        "---\n",
        "- iterations: 훈련 반복 횟수를 지정합니다.\n",
        "- learning_rate: 학습률을 조정하여 모델 훈련 속도와 정확도를 조절합니다.\n",
        "- depth: 트리의 깊이를 제어하여 모델의 복잡성을 조정합니다.\n",
        "- l2_leaf_reg: L2 정규화 항에 대한 가중치를 지정합니다. 모델의 일반화 성능을 향상시키는 데 도움이 될 수 있습니다.\n",
        "- border_count: 범주형 특성 분할에 사용되는 트리 노드의 최대 개수를 지정합니다.\n",
        "- colsample_bylevel: 각 레벨에서 사용할 특성의 비율을 지정합니다.\n",
        "- eval_metric: 모델의 평가 메트릭을 선택합니다.    \n",
        "  분류 문제에서는 Accuracy, Logloss, AUC 등을 사용할 수 있습니다.\n",
        "- random_seed: 재현성을 위해 사용되는 난수 시드 값을 설정합니다.\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 클래스에 대해 다른 가중치를 부여\n",
        "y = train['first_party_winner']\n",
        "counts = list(y.value_counts())\n",
        "class_weight = [counts[1]/sum(counts), counts[0]/sum(counts)]\n",
        "print(\"weight :\", class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Eo2b3p-XVkvt",
        "outputId": "b8636690-7d03-4008-dac8-40114d81b9b8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight : [0.33454398708635996, 0.66545601291364]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PDC6GMbBNP_R",
        "outputId": "d43c125e-7000-4e9f-d1dc-87b2b07467f0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<catboost.core.CatBoostClassifier at 0x7f252e3bb6d0>"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ],
      "source": [
        "# 범주형 변수 지정\n",
        "# cat_features = list(train_df.select_dtypes(include='category').columns)\n",
        "\n",
        "# 모델 정의\n",
        "model = CatBoostClassifier(random_seed=42,\n",
        "                           class_weights=class_weight,\n",
        "                           verbose=0\n",
        "                     #      cat_features=cat_features\n",
        "                           )\n",
        "\n",
        "# 모델 적합\n",
        "model.fit(X, y)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "'''# ML Metrics\n",
        "from sklearn.metrics import make_scorer, accuracy_score\n",
        "# ML Model selection\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "model_cat = CatBoostClassifier()\n",
        "params = {'iterations': [500],\n",
        "          'depth': [4, 5, 6],\n",
        "          'loss_function': ['Logloss'],\n",
        " #         'l2_leaf_reg': np.logspace(-20, -19, 3),\n",
        " #         'leaf_estimation_iterations': [10],\n",
        "          'eval_metric': ['Accuracy'],\n",
        "           'use_best_model': ['True'],\n",
        "          'random_seed': [42]\n",
        "         }\n",
        "scorer = make_scorer(accuracy_score)\n",
        "clf_grid = GridSearchCV(estimator=model_cat,\n",
        "                        param_grid=params,\n",
        "                        scoring=scorer,\n",
        "                        cv=5\n",
        "                        )\n",
        "clf_grid.fit(X,y)\n",
        "best_param = clf_grid.best_params_\n",
        "best_param'''"
      ],
      "metadata": {
        "id": "rAxzGiN5PRyn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = test_fin\n",
        "X_test = np.asarray(X_test)\n",
        "Y_pred = model.predict(X_test)"
      ],
      "metadata": {
        "id": "0CSrPLeJpi2C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 테스트 데이터로 예측 수행\n",
        "y_pred = model.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9SizUvGGEGao",
        "outputId": "5ff27af7-7e6b-41fb-c2df-3a0be6442472"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1219\n",
              "0      21\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 104
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DHC0JCAxLRoY"
      },
      "source": [
        "## XGBoost Classifier\n",
        "\n",
        "\n",
        "\n",
        "---------\n",
        "- max_depth (default=6): 트리의 최대 깊이를 제어\n",
        "- learning_rate (default=0.1): 학습률로, 각 트리의 기여를 제어\n",
        "- n_estimators (default=100): 생성할 트리의 개수\n",
        "- subsample (default=1): 각 트리에 사용할 샘플의 비율을 제어\n",
        "- colsample_bytree (default=1): 각 트리에 사용할 특성의 비율을 제어\n",
        "- reg_alpha (default=0): L1 정규화 항의 가중치\n",
        "- reg_lambda (default=1): L2 정규화 항의 가중치입\n",
        "- gamma (default=0): 트리 노드의 분할을 위한 최소 손실 감소량"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 각 클래스에 대해 다른 가중치를 부여\n",
        "y = train['first_party_winner']\n",
        "counts = list(y.value_counts())\n",
        "class_weight = [counts[1]/sum(counts), counts[0]/sum(counts)]\n",
        "print(\"weight :\", class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "f6828070-367b-4f2d-f807-10eeb5808248",
        "id": "RJoo8VgELRoa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight : [0.33454398708635996, 0.66545601291364]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 248
        },
        "id": "-I4Hm0gjLRob",
        "outputId": "865ceae2-e220-44cb-c68e-64f74de4e6e2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
              "              predictor=None, random_state=2, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
              "              predictor=None, random_state=2, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=3, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=-1, num_parallel_tree=None,\n",
              "              predictor=None, random_state=2, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ],
      "source": [
        "# 모델 정의\n",
        "from xgboost import XGBClassifier\n",
        "model_xgb = XGBClassifier(n_jobs=-1,\n",
        "                    scale_pos_weight=4.6,\n",
        "                    max_depth=3,\n",
        "                    random_state=2)\n",
        "# 모델 적합\n",
        "model_xgb.fit(X, y)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "- estimator: 사용할 모델 객체를 지정합니다.\n",
        "- param_grid: 탐색할 하이퍼파라미터 조합을 딕셔너리 형태로 지정합니다.\n",
        "- scoring: 모델의 성능을 평가하는 방법을 지정합니다.\n",
        "- cv: 교차 검증을 위한 폴드 수를 지정합니다.\n",
        "- refit: 그리드 서치 종료 후, 최적의 하이퍼파라미터로 전체 데이터에 대해 모델을 학습할지 여부를 지정합니다.\n",
        "- error_score: 모델이 학습 중 오류가 발생했을 때의 처리 방식을 지정합니다.\n",
        "- n_jobs: 병렬로 그리드 서치를 수행할 때 사용할 CPU 코어 수를 지정합니다.\n",
        "- verbose: 그리드 서치 수행 과정에서의 출력 레벨을 지정"
      ],
      "metadata": {
        "id": "sbaKV58FVk-E"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (1) 첫번째 시도"
      ],
      "metadata": {
        "id": "hzssB8mIjga0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('standard_scaler', StandardScaler()),\n",
        "    ('pca', PCA()),\n",
        "    ('model', model_xgb)\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
        "    'model__max_depth': [2, 3, 5, 7, 10],\n",
        "    'model__n_estimators': [10, 100, 500],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, error_score='raise')\n",
        "grid.fit(X, y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "ZpWuhMMgVHkH",
        "outputId": "f898c46c-6116-4ee6-d6ad-00a62841ce9a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-89-7301f1b1f772>\u001b[0m in \u001b[0;36m<cell line: 17>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     15\u001b[0m }\n\u001b[1;32m     16\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 17\u001b[0;31m \u001b[0mgrid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpipeline\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0merror_score\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'raise'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     18\u001b[0m \u001b[0mgrid\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'GridSearchCV' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.decomposition import PCA\n",
        "\n",
        "pipeline = Pipeline([\n",
        "    ('standard_scaler', StandardScaler()),\n",
        "    ('pca', PCA()),\n",
        "    ('model', model_xgb)\n",
        "])\n",
        "\n",
        "param_grid = {\n",
        "    'pca__n_components': [5, 10, 15, 20, 25, 30],\n",
        "    'model__max_depth': [2, 3, 5, 7, 10],\n",
        "    'model__n_estimators': [10, 100, 500],\n",
        "}\n",
        "\n",
        "grid = GridSearchCV(pipeline, param_grid, cv=5, n_jobs=-1, error_score='raise')\n",
        "grid.fit(X, y)"
      ],
      "metadata": {
        "id": "A_L0xNIBk7SF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#튜닝된 파라미터 출력\n",
        "print(grid.best_params_)"
      ],
      "metadata": {
        "id": "n8pi_ZsEgIhT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 1차적으로 튜닝된 파라미터를 가지고 객체 생성\n",
        "xgb_model = XGBClassifier(max_depth = 2,\n",
        "                         n_estimators = 100,\n",
        "                         n_components = 10)\n",
        "\n",
        "# 학습\n",
        "xgb_model.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 303
        },
        "id": "nXhRNWoCgiKj",
        "outputId": "f8dbcb74-c697-47da-b267-653b50fc973f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[00:30:54] WARNING: ../src/learner.cc:767: \n",
            "Parameters: { \"n_components\" } are not used.\n",
            "\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_components=10, n_estimators=100, n_jobs=None,\n",
              "              num_parallel_tree=None, predictor=None, ...)"
            ],
            "text/html": [
              "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_components=10, n_estimators=100, n_jobs=None,\n",
              "              num_parallel_tree=None, predictor=None, ...)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_components=10, n_estimators=100, n_jobs=None,\n",
              "              num_parallel_tree=None, predictor=None, ...)</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 90
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train 기준 accuracy 확인\n",
        "y_pred = xgb_model.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "R2m1_aM9jvaH",
        "outputId": "2b3940bd-361d-413d-91a7-0b2a13578882"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-91-30c382c4578e>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train 기준 accuracy 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mxgb_model\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 확인\n",
        "X_test = np.asarray(test_fin)\n",
        "Y_pred = xgb_model.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LcnXRMHSWjgt",
        "outputId": "41fadcc7-6806-464e-f7ab-541f99d0004f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    947\n",
              "0    293\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 92
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit['first_party_winner'] = Y_pred\n",
        "submit.to_csv('./submit_xgboost.csv', index=False)\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "12_BOiP4yR7R",
        "outputId": "80be9274-b635-4347-ecf9-5d977b628719"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "import pandas as pd\n",
        "\n",
        "ftr_importances_values = xgb_model.feature_importances_\n",
        "ftr_importances = pd.Series(ftr_importances_values, index=X.columns)\n",
        "ftr_importances = ftr_importances.sort_values(ascending=False)  # 정렬\n",
        "\n",
        "top_k = 50  # 확인하려는 상위 레코드 개수\n",
        "\n",
        "plt.figure(figsize=(8,6))\n",
        "plt.title('Top {} Feature Importances'.format(top_k))\n",
        "sns.barplot(x=ftr_importances[:top_k], y=ftr_importances.index[:top_k])\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "ni8Hz_GRuRLA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "lst = [str(idx) for idx in list(ftr_importances.index[:50])]\n",
        "train_xx = train_fin.copy()\n",
        "train_xx.columns = train_xx.columns.astype(str)\n",
        "\n",
        "train_xx[lst]"
      ],
      "metadata": {
        "id": "OQVY1f4vu-Nj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### (2) *두번째 시도*"
      ],
      "metadata": {
        "id": "jgi9881xjlIs"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pipeline = Pipeline([\n",
        "    ('standard_scaler', StandardScaler()),\n",
        "    ('pca', PCA(n_components = 10)),\n",
        "    ('model', XGBClassifier(max_depth = 2,\n",
        "                         n_estimators = 100))\n",
        "])\n",
        "\n",
        "pipeline.fit(X,y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 160
        },
        "id": "lCuPt8OhkNfA",
        "outputId": "2f98fecc-da0c-49b9-8f81-88f2baf636d0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Pipeline(steps=[('standard_scaler', StandardScaler()),\n",
              "                ('pca', PCA(n_components=10)),\n",
              "                ('model',\n",
              "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=None,\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=None,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=2, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=100,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=None, ...))])"
            ],
            "text/html": [
              "<style>#sk-container-id-3 {color: black;background-color: white;}#sk-container-id-3 pre{padding: 0;}#sk-container-id-3 div.sk-toggleable {background-color: white;}#sk-container-id-3 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-3 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-3 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-3 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-3 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-3 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-3 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-3 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-3 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-3 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-3 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-3 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-3 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-3 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-3 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-3 div.sk-item {position: relative;z-index: 1;}#sk-container-id-3 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-3 div.sk-item::before, #sk-container-id-3 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-3 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-3 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-3 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-3 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-3 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-3 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-3 div.sk-label-container {text-align: center;}#sk-container-id-3 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-3 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-3\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;standard_scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;pca&#x27;, PCA(n_components=10)),\n",
              "                (&#x27;model&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=None,\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=None,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=2, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=100,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=None, ...))])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;standard_scaler&#x27;, StandardScaler()),\n",
              "                (&#x27;pca&#x27;, PCA(n_components=10)),\n",
              "                (&#x27;model&#x27;,\n",
              "                 XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "                               colsample_bylevel=None, colsample_bynode=None,\n",
              "                               colsample_bytree=None,\n",
              "                               early_stopping_rounds=None,\n",
              "                               enable_categorical=False, eval_metric=None,\n",
              "                               feature_types=None, gamma=None, gpu_id=None,\n",
              "                               grow_policy=None, importance_type=None,\n",
              "                               interaction_constraints=None, learning_rate=None,\n",
              "                               max_bin=None, max_cat_threshold=None,\n",
              "                               max_cat_to_onehot=None, max_delta_step=None,\n",
              "                               max_depth=2, max_leaves=None,\n",
              "                               min_child_weight=None, missing=nan,\n",
              "                               monotone_constraints=None, n_estimators=100,\n",
              "                               n_jobs=None, num_parallel_tree=None,\n",
              "                               predictor=None, random_state=None, ...))])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-4\" type=\"checkbox\" ><label for=\"sk-estimator-id-4\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">StandardScaler</label><div class=\"sk-toggleable__content\"><pre>StandardScaler()</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-5\" type=\"checkbox\" ><label for=\"sk-estimator-id-5\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">PCA</label><div class=\"sk-toggleable__content\"><pre>PCA(n_components=10)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-6\" type=\"checkbox\" ><label for=\"sk-estimator-id-6\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">XGBClassifier</label><div class=\"sk-toggleable__content\"><pre>XGBClassifier(base_score=None, booster=None, callbacks=None,\n",
              "              colsample_bylevel=None, colsample_bynode=None,\n",
              "              colsample_bytree=None, early_stopping_rounds=None,\n",
              "              enable_categorical=False, eval_metric=None, feature_types=None,\n",
              "              gamma=None, gpu_id=None, grow_policy=None, importance_type=None,\n",
              "              interaction_constraints=None, learning_rate=None, max_bin=None,\n",
              "              max_cat_threshold=None, max_cat_to_onehot=None,\n",
              "              max_delta_step=None, max_depth=2, max_leaves=None,\n",
              "              min_child_weight=None, missing=nan, monotone_constraints=None,\n",
              "              n_estimators=100, n_jobs=None, num_parallel_tree=None,\n",
              "              predictor=None, random_state=None, ...)</pre></div></div></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 96
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# train 기준 accuracy 확인\n",
        "y_pred = pipeline.predict(X)\n",
        "accuracy = accuracy_score(y, y_pred)\n",
        "accuracy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 228
        },
        "id": "VUrDmljkkNUN",
        "outputId": "47b497a3-ce2c-448c-d4b4-7181a3e742aa"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-97-e16e7765c6d3>\u001b[0m in \u001b[0;36m<cell line: 3>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m# train 기준 accuracy 확인\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0my_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpipeline\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0maccuracy\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0maccuracy_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0maccuracy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'accuracy_score' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# test 확인\n",
        "X_test = np.asarray(test_fin)\n",
        "Y_pred = pipeline.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r1pnRIIckNLX",
        "outputId": "2ded6d4b-409a-417d-9f16-ae295e130258"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1180\n",
              "0      60\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## LGBM\n",
        "\n",
        "\n",
        "\n",
        "---------\n",
        "- boosting_type (기본값='gbdt'): 부스팅 유형을 지정합니다. 'gbdt'는 일반적인 그래디언트 부스팅을 의미하며, 'dart', 'goss' 등 다른 옵션도 사용할 수 있습니다.\n",
        "- num_leaves (기본값=31): 트리에 존재할 수 있는 최대 잎의 수입니다. 높은 값은 모델의 복잡도를 증가시킬 수 있지만, 과적합의 위험도 증가할 수 있습니다.\n",
        "- max_depth (기본값=-1): 트리의 최대 깊이를 제한합니다. 음수 값인 경우 제한이 없습니다.\n",
        "- learning_rate (기본값=0.1): 학습 속도를 조절하는 값으로, 각 트리의 영향력을 조절합니다.\n",
        "- n_estimators (기본값=100): 생성할 트리의 개수입니다.\n",
        "- subsample (기본값=1.0): 각 트리의 학습에 사용될 샘플의 비율을 지정합니다. 과적합 방지를 위해 값이 1.0보다 작게 설정할 수 있습니다.\n",
        "- colsample_bytree (기본값=1.0): 각 트리의 학습에 사용될 특성의 비율을 지정합니다.\n",
        "-reg_alpha (기본값=0.0): L1 정규화(규제)의 강도를 조절합니다.\n",
        "- reg_lambda (기본값=0.0): L2 정규화(규제)의 강도를 조절합니다.\n",
        "- min_child_samples (기본값=20): 리프 노드가 되기 위한 최소한의 데이터 샘플 개수를 지정합니다. 과적합 방지를 위해 사용됩니다."
      ],
      "metadata": {
        "id": "fothpbIZspcb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 범주형 변수(categorical variable)을 더미변수 생성\n",
        "#train_cat = pd.get_dummies(data = train_df[[\"first_party\",\"second_party\",\"issued_area\"]], drop_first=True)\n",
        "#test_cat = pd.get_dummies(data = test_df[[\"first_party\",\"second_party\",\"issued_area\"]], drop_first=True)\n",
        "\n",
        "train_cat = train_df[list(train_df.select_dtypes(include='category').columns)]\n",
        "test_cat = test_df[list(train_df.select_dtypes(include='category').columns)]\n",
        "\n",
        "train_fin = pd.concat([train_fact,train_cat,train_num,train_target],axis=1,join='inner')\n",
        "test_fin = pd.concat([test_fact, test_cat, test_num],axis=1,join='inner')"
      ],
      "metadata": {
        "id": "7h4mRIOfLLoq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X = train_fin.drop(columns={'first_party_winner'})\n",
        "y = train_fin['first_party_winner']\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y,\n",
        "                                                    test_size=0.2,\n",
        "                                                    random_state=0)"
      ],
      "metadata": {
        "id": "oSTtgxRu3Tcb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# prediction, label -> f1 score\n",
        "from sklearn.metrics import log_loss, roc_auc_score, matthews_corrcoef, f1_score\n",
        "\n",
        "def get_f1_score(preds, labels):\n",
        "  preds = np.argmax(preds, axis = 1)\n",
        "\n",
        "  score = f1_score(preds, labels, average='macro')\n",
        "\n",
        "  return score"
      ],
      "metadata": {
        "id": "SWbc2uc_4RDs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import lightgbm as model_lgb\n",
        "\n",
        "def lightgbm_train(x_train: pd.DataFrame,\n",
        "                   y_train: pd.DataFrame,\n",
        "                   x_valid: pd.DataFrame,\n",
        "                   y_valid: pd.DataFrame,\n",
        "                   categorical_features: list,\n",
        "                   params):\n",
        "\n",
        "      lgb_train = model_lgb.Dataset(x_train, y_train, categorical_feature=categorical_features)\n",
        "      lgb_valid = model_lgb.Dataset(x_valid, y_valid, categorical_feature=categorical_features)\n",
        "\n",
        "      model = model_lgb.train(\n",
        "                params = params,\n",
        "                train_set = lgb_train,\n",
        "                valid_sets = lgb_valid,\n",
        "                num_boost_round = 10000,\n",
        "      )\n",
        "\n",
        "      ## prediction\n",
        "      valid_pred = model.predict(x_valid)\n",
        "      train_pred = model.predict(x_train)\n",
        "\n",
        "      train_f1 = get_f1_score(train_pred, y_train)\n",
        "      valid_f1 = get_f1_score(valid_pred, y_valid)\n",
        "\n",
        "      print(f\"lightgbm: train_f1 = {train_f1}\")\n",
        "      print(f\"lightgbm: valid_f1 = {valid_f1}\")\n",
        "\n",
        "      return model"
      ],
      "metadata": {
        "id": "BNSYsl91sp3C"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 범주형 변수 지정\n",
        "cat_features = list(train_df.select_dtypes(include='category').columns)\n",
        "\n",
        "# 베이스 파라미터\n",
        "lgb_params_base = {\n",
        "      'objective': 'multiclass',\n",
        "      'metric': 'multi_logloss',\n",
        "      'num_class': 3,\n",
        "      'device_type':'cpu',\n",
        "      'feature_fraction': 0.50,\n",
        "      'bagging_fraction': 0.80,\n",
        "      'n_jobs': -1,\n",
        "      'is_unbalance':True,\n",
        "      'seed': 42,\n",
        "      'early_stopping':200,\n",
        "      'learning_rate': 0.005,\n",
        "      'num_leaves': 5,\n",
        "      'lambda_l1':3,\n",
        "      'lambda_l2': 4,\n",
        "      'verbose':1000\n",
        "    }\n",
        "\n",
        "\n",
        "# base 모델\n",
        "lgb_model_base = lightgbm_train(X_train, y_train,\n",
        "                                X_test, y_test,\n",
        "                                cat_features,\n",
        "                                lgb_params_base)"
      ],
      "metadata": {
        "id": "KAVWXeuvsq4t",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c5c58ee1-c12d-4da7-fa2e-bd939b0e4559"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[LightGBM] [Debug] Dataset::GetMultiBinFromSparseFeatures: sparse rate 0.918759\n",
            "[LightGBM] [Debug] Dataset::GetMultiBinFromAllFeatures: sparse rate 0.896564\n",
            "[LightGBM] [Debug] init for col-wise cost 0.008905 seconds, init for row-wise cost 0.009845 seconds\n",
            "[LightGBM] [Warning] Auto-choosing col-wise multi-threading, the overhead of testing was 0.010732 seconds.\n",
            "You can set `force_col_wise=true` to remove the overhead.\n",
            "[LightGBM] [Info] Total Bins 24263\n",
            "[LightGBM] [Info] Number of data points in the train set: 1982, number of used features: 406\n",
            "[LightGBM] [Info] Start training from score -1.121062\n",
            "[LightGBM] [Info] Start training from score -0.394426\n",
            "[LightGBM] [Info] Start training from score -34.538776\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1]\tvalid_0's multi_logloss: 0.662415\n",
            "Training until validation scores don't improve for 200 rounds\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[2]\tvalid_0's multi_logloss: 0.662308\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[3]\tvalid_0's multi_logloss: 0.662183\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[4]\tvalid_0's multi_logloss: 0.662019\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[5]\tvalid_0's multi_logloss: 0.661935\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[6]\tvalid_0's multi_logloss: 0.661818\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[7]\tvalid_0's multi_logloss: 0.661665\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[8]\tvalid_0's multi_logloss: 0.661566\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[9]\tvalid_0's multi_logloss: 0.661468\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[10]\tvalid_0's multi_logloss: 0.661371\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[11]\tvalid_0's multi_logloss: 0.661192\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[12]\tvalid_0's multi_logloss: 0.66111\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[13]\tvalid_0's multi_logloss: 0.660974\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[14]\tvalid_0's multi_logloss: 0.660923\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[15]\tvalid_0's multi_logloss: 0.660803\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[16]\tvalid_0's multi_logloss: 0.660745\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[17]\tvalid_0's multi_logloss: 0.660623\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[18]\tvalid_0's multi_logloss: 0.660536\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[19]\tvalid_0's multi_logloss: 0.6604\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[20]\tvalid_0's multi_logloss: 0.660251\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[21]\tvalid_0's multi_logloss: 0.660123\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[22]\tvalid_0's multi_logloss: 0.659962\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[23]\tvalid_0's multi_logloss: 0.659893\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[24]\tvalid_0's multi_logloss: 0.659816\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[25]\tvalid_0's multi_logloss: 0.659687\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[26]\tvalid_0's multi_logloss: 0.65955\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[27]\tvalid_0's multi_logloss: 0.659463\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[28]\tvalid_0's multi_logloss: 0.659331\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[29]\tvalid_0's multi_logloss: 0.659256\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[30]\tvalid_0's multi_logloss: 0.659112\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[31]\tvalid_0's multi_logloss: 0.65901\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[32]\tvalid_0's multi_logloss: 0.658977\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[33]\tvalid_0's multi_logloss: 0.658808\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[34]\tvalid_0's multi_logloss: 0.658618\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[35]\tvalid_0's multi_logloss: 0.65856\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[36]\tvalid_0's multi_logloss: 0.65848\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[37]\tvalid_0's multi_logloss: 0.658283\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[38]\tvalid_0's multi_logloss: 0.658148\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[39]\tvalid_0's multi_logloss: 0.658113\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[40]\tvalid_0's multi_logloss: 0.657946\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[41]\tvalid_0's multi_logloss: 0.657873\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[42]\tvalid_0's multi_logloss: 0.657803\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[43]\tvalid_0's multi_logloss: 0.657743\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[44]\tvalid_0's multi_logloss: 0.657654\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[45]\tvalid_0's multi_logloss: 0.657455\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[46]\tvalid_0's multi_logloss: 0.657401\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[47]\tvalid_0's multi_logloss: 0.657213\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[48]\tvalid_0's multi_logloss: 0.657066\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[49]\tvalid_0's multi_logloss: 0.656962\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[50]\tvalid_0's multi_logloss: 0.656917\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[51]\tvalid_0's multi_logloss: 0.656863\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[52]\tvalid_0's multi_logloss: 0.656797\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[53]\tvalid_0's multi_logloss: 0.656706\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[54]\tvalid_0's multi_logloss: 0.656638\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[55]\tvalid_0's multi_logloss: 0.656581\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[56]\tvalid_0's multi_logloss: 0.656499\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[57]\tvalid_0's multi_logloss: 0.656387\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[58]\tvalid_0's multi_logloss: 0.65627\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[59]\tvalid_0's multi_logloss: 0.656158\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[60]\tvalid_0's multi_logloss: 0.656044\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[61]\tvalid_0's multi_logloss: 0.655901\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[62]\tvalid_0's multi_logloss: 0.655806\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[63]\tvalid_0's multi_logloss: 0.655724\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[64]\tvalid_0's multi_logloss: 0.655578\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[65]\tvalid_0's multi_logloss: 0.655492\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[66]\tvalid_0's multi_logloss: 0.655391\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[67]\tvalid_0's multi_logloss: 0.655299\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[68]\tvalid_0's multi_logloss: 0.655233\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[69]\tvalid_0's multi_logloss: 0.655187\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[70]\tvalid_0's multi_logloss: 0.655145\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[71]\tvalid_0's multi_logloss: 0.655055\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[72]\tvalid_0's multi_logloss: 0.655014\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[73]\tvalid_0's multi_logloss: 0.65488\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[74]\tvalid_0's multi_logloss: 0.654811\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[75]\tvalid_0's multi_logloss: 0.654706\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[76]\tvalid_0's multi_logloss: 0.654546\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[77]\tvalid_0's multi_logloss: 0.654483\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[78]\tvalid_0's multi_logloss: 0.654408\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[79]\tvalid_0's multi_logloss: 0.654352\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[80]\tvalid_0's multi_logloss: 0.65426\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[81]\tvalid_0's multi_logloss: 0.654189\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[82]\tvalid_0's multi_logloss: 0.65409\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[83]\tvalid_0's multi_logloss: 0.654049\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[84]\tvalid_0's multi_logloss: 0.653869\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[85]\tvalid_0's multi_logloss: 0.653836\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[86]\tvalid_0's multi_logloss: 0.653773\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[87]\tvalid_0's multi_logloss: 0.653583\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[88]\tvalid_0's multi_logloss: 0.653416\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[89]\tvalid_0's multi_logloss: 0.653363\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[90]\tvalid_0's multi_logloss: 0.653354\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[91]\tvalid_0's multi_logloss: 0.653247\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[92]\tvalid_0's multi_logloss: 0.653106\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[93]\tvalid_0's multi_logloss: 0.652988\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[94]\tvalid_0's multi_logloss: 0.65283\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[95]\tvalid_0's multi_logloss: 0.652653\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[96]\tvalid_0's multi_logloss: 0.652602\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[97]\tvalid_0's multi_logloss: 0.652581\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[98]\tvalid_0's multi_logloss: 0.652487\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[99]\tvalid_0's multi_logloss: 0.652367\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[100]\tvalid_0's multi_logloss: 0.652307\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[101]\tvalid_0's multi_logloss: 0.652214\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[102]\tvalid_0's multi_logloss: 0.652173\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[103]\tvalid_0's multi_logloss: 0.652056\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[104]\tvalid_0's multi_logloss: 0.651941\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[105]\tvalid_0's multi_logloss: 0.651902\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[106]\tvalid_0's multi_logloss: 0.651811\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[107]\tvalid_0's multi_logloss: 0.651731\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[108]\tvalid_0's multi_logloss: 0.651642\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[109]\tvalid_0's multi_logloss: 0.651556\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[110]\tvalid_0's multi_logloss: 0.651541\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[111]\tvalid_0's multi_logloss: 0.651441\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[112]\tvalid_0's multi_logloss: 0.651332\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[113]\tvalid_0's multi_logloss: 0.651225\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[114]\tvalid_0's multi_logloss: 0.651141\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[115]\tvalid_0's multi_logloss: 0.65108\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[116]\tvalid_0's multi_logloss: 0.650993\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[117]\tvalid_0's multi_logloss: 0.650968\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[118]\tvalid_0's multi_logloss: 0.650813\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[119]\tvalid_0's multi_logloss: 0.650737\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[120]\tvalid_0's multi_logloss: 0.650628\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[121]\tvalid_0's multi_logloss: 0.650551\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[122]\tvalid_0's multi_logloss: 0.650537\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[123]\tvalid_0's multi_logloss: 0.650506\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[124]\tvalid_0's multi_logloss: 0.650366\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[125]\tvalid_0's multi_logloss: 0.650312\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[126]\tvalid_0's multi_logloss: 0.650226\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[127]\tvalid_0's multi_logloss: 0.650159\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[128]\tvalid_0's multi_logloss: 0.650018\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[129]\tvalid_0's multi_logloss: 0.649917\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[130]\tvalid_0's multi_logloss: 0.649785\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[131]\tvalid_0's multi_logloss: 0.649684\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[132]\tvalid_0's multi_logloss: 0.649611\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[133]\tvalid_0's multi_logloss: 0.64947\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[134]\tvalid_0's multi_logloss: 0.649454\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[135]\tvalid_0's multi_logloss: 0.649404\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[136]\tvalid_0's multi_logloss: 0.649317\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[137]\tvalid_0's multi_logloss: 0.649281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[138]\tvalid_0's multi_logloss: 0.649199\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[139]\tvalid_0's multi_logloss: 0.649161\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[140]\tvalid_0's multi_logloss: 0.649048\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[141]\tvalid_0's multi_logloss: 0.648913\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[142]\tvalid_0's multi_logloss: 0.648875\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[143]\tvalid_0's multi_logloss: 0.648822\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[144]\tvalid_0's multi_logloss: 0.648777\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[145]\tvalid_0's multi_logloss: 0.648752\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[146]\tvalid_0's multi_logloss: 0.64867\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[147]\tvalid_0's multi_logloss: 0.648599\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[148]\tvalid_0's multi_logloss: 0.648514\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[149]\tvalid_0's multi_logloss: 0.64842\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[150]\tvalid_0's multi_logloss: 0.648351\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[151]\tvalid_0's multi_logloss: 0.64831\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[152]\tvalid_0's multi_logloss: 0.648238\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[153]\tvalid_0's multi_logloss: 0.648142\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[154]\tvalid_0's multi_logloss: 0.648079\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[155]\tvalid_0's multi_logloss: 0.647989\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[156]\tvalid_0's multi_logloss: 0.647962\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[157]\tvalid_0's multi_logloss: 0.647944\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[158]\tvalid_0's multi_logloss: 0.647815\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[159]\tvalid_0's multi_logloss: 0.647762\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[160]\tvalid_0's multi_logloss: 0.647732\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[161]\tvalid_0's multi_logloss: 0.647751\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[162]\tvalid_0's multi_logloss: 0.647732\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[163]\tvalid_0's multi_logloss: 0.647664\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[164]\tvalid_0's multi_logloss: 0.647606\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[165]\tvalid_0's multi_logloss: 0.647578\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[166]\tvalid_0's multi_logloss: 0.647479\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[167]\tvalid_0's multi_logloss: 0.647431\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[168]\tvalid_0's multi_logloss: 0.647327\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[169]\tvalid_0's multi_logloss: 0.647235\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[170]\tvalid_0's multi_logloss: 0.647204\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[171]\tvalid_0's multi_logloss: 0.647163\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[172]\tvalid_0's multi_logloss: 0.647121\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[173]\tvalid_0's multi_logloss: 0.647112\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[174]\tvalid_0's multi_logloss: 0.6471\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[175]\tvalid_0's multi_logloss: 0.647075\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[176]\tvalid_0's multi_logloss: 0.646978\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[177]\tvalid_0's multi_logloss: 0.646937\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[178]\tvalid_0's multi_logloss: 0.646897\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[179]\tvalid_0's multi_logloss: 0.646878\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[180]\tvalid_0's multi_logloss: 0.64687\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[181]\tvalid_0's multi_logloss: 0.646852\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[182]\tvalid_0's multi_logloss: 0.646792\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[183]\tvalid_0's multi_logloss: 0.646735\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[184]\tvalid_0's multi_logloss: 0.646733\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[185]\tvalid_0's multi_logloss: 0.646692\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[186]\tvalid_0's multi_logloss: 0.646673\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[187]\tvalid_0's multi_logloss: 0.646653\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[188]\tvalid_0's multi_logloss: 0.646611\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[189]\tvalid_0's multi_logloss: 0.646575\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[190]\tvalid_0's multi_logloss: 0.646495\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[191]\tvalid_0's multi_logloss: 0.646484\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[192]\tvalid_0's multi_logloss: 0.646385\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[193]\tvalid_0's multi_logloss: 0.64639\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[194]\tvalid_0's multi_logloss: 0.646394\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[195]\tvalid_0's multi_logloss: 0.646357\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[196]\tvalid_0's multi_logloss: 0.646303\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[197]\tvalid_0's multi_logloss: 0.646218\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[198]\tvalid_0's multi_logloss: 0.646136\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[199]\tvalid_0's multi_logloss: 0.646048\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[200]\tvalid_0's multi_logloss: 0.646009\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[201]\tvalid_0's multi_logloss: 0.645941\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[202]\tvalid_0's multi_logloss: 0.645862\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[203]\tvalid_0's multi_logloss: 0.645825\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[204]\tvalid_0's multi_logloss: 0.645734\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[205]\tvalid_0's multi_logloss: 0.645662\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[206]\tvalid_0's multi_logloss: 0.645598\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[207]\tvalid_0's multi_logloss: 0.645586\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[208]\tvalid_0's multi_logloss: 0.64554\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[209]\tvalid_0's multi_logloss: 0.645487\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[210]\tvalid_0's multi_logloss: 0.64544\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[211]\tvalid_0's multi_logloss: 0.645434\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[212]\tvalid_0's multi_logloss: 0.645346\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[213]\tvalid_0's multi_logloss: 0.645304\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[214]\tvalid_0's multi_logloss: 0.645255\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[215]\tvalid_0's multi_logloss: 0.645205\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[216]\tvalid_0's multi_logloss: 0.64512\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[217]\tvalid_0's multi_logloss: 0.645058\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[218]\tvalid_0's multi_logloss: 0.644987\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[219]\tvalid_0's multi_logloss: 0.644924\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[220]\tvalid_0's multi_logloss: 0.644898\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[221]\tvalid_0's multi_logloss: 0.644814\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[222]\tvalid_0's multi_logloss: 0.644779\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[223]\tvalid_0's multi_logloss: 0.64472\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[224]\tvalid_0's multi_logloss: 0.644647\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[225]\tvalid_0's multi_logloss: 0.644633\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[226]\tvalid_0's multi_logloss: 0.644589\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[227]\tvalid_0's multi_logloss: 0.644504\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[228]\tvalid_0's multi_logloss: 0.644483\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[229]\tvalid_0's multi_logloss: 0.64445\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[230]\tvalid_0's multi_logloss: 0.644396\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[231]\tvalid_0's multi_logloss: 0.644315\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[232]\tvalid_0's multi_logloss: 0.644239\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[233]\tvalid_0's multi_logloss: 0.644211\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[234]\tvalid_0's multi_logloss: 0.644165\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[235]\tvalid_0's multi_logloss: 0.64411\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[236]\tvalid_0's multi_logloss: 0.644072\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[237]\tvalid_0's multi_logloss: 0.644054\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[238]\tvalid_0's multi_logloss: 0.644015\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[239]\tvalid_0's multi_logloss: 0.643966\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[240]\tvalid_0's multi_logloss: 0.643908\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[241]\tvalid_0's multi_logloss: 0.643858\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[242]\tvalid_0's multi_logloss: 0.643821\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[243]\tvalid_0's multi_logloss: 0.643721\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[244]\tvalid_0's multi_logloss: 0.64366\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[245]\tvalid_0's multi_logloss: 0.643682\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[246]\tvalid_0's multi_logloss: 0.643641\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[247]\tvalid_0's multi_logloss: 0.643597\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[248]\tvalid_0's multi_logloss: 0.64359\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[249]\tvalid_0's multi_logloss: 0.643541\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[250]\tvalid_0's multi_logloss: 0.643494\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[251]\tvalid_0's multi_logloss: 0.643473\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[252]\tvalid_0's multi_logloss: 0.643476\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[253]\tvalid_0's multi_logloss: 0.643386\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[254]\tvalid_0's multi_logloss: 0.643346\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[255]\tvalid_0's multi_logloss: 0.643296\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[256]\tvalid_0's multi_logloss: 0.643229\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[257]\tvalid_0's multi_logloss: 0.643159\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[258]\tvalid_0's multi_logloss: 0.643094\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[259]\tvalid_0's multi_logloss: 0.643081\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[260]\tvalid_0's multi_logloss: 0.643047\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[261]\tvalid_0's multi_logloss: 0.642995\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[262]\tvalid_0's multi_logloss: 0.642959\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[263]\tvalid_0's multi_logloss: 0.642934\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[264]\tvalid_0's multi_logloss: 0.642923\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[265]\tvalid_0's multi_logloss: 0.642859\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[266]\tvalid_0's multi_logloss: 0.642841\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[267]\tvalid_0's multi_logloss: 0.642804\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[268]\tvalid_0's multi_logloss: 0.642767\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[269]\tvalid_0's multi_logloss: 0.642719\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[270]\tvalid_0's multi_logloss: 0.642676\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[271]\tvalid_0's multi_logloss: 0.642623\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[272]\tvalid_0's multi_logloss: 0.6426\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[273]\tvalid_0's multi_logloss: 0.64258\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[274]\tvalid_0's multi_logloss: 0.64255\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[275]\tvalid_0's multi_logloss: 0.642564\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[276]\tvalid_0's multi_logloss: 0.642497\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[277]\tvalid_0's multi_logloss: 0.642456\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[278]\tvalid_0's multi_logloss: 0.64247\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[279]\tvalid_0's multi_logloss: 0.642448\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[280]\tvalid_0's multi_logloss: 0.642388\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[281]\tvalid_0's multi_logloss: 0.642361\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[282]\tvalid_0's multi_logloss: 0.64231\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[283]\tvalid_0's multi_logloss: 0.642295\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[284]\tvalid_0's multi_logloss: 0.642231\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[285]\tvalid_0's multi_logloss: 0.642213\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[286]\tvalid_0's multi_logloss: 0.642208\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[287]\tvalid_0's multi_logloss: 0.6422\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[288]\tvalid_0's multi_logloss: 0.642123\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[289]\tvalid_0's multi_logloss: 0.642113\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[290]\tvalid_0's multi_logloss: 0.642097\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[291]\tvalid_0's multi_logloss: 0.642055\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[292]\tvalid_0's multi_logloss: 0.642083\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[293]\tvalid_0's multi_logloss: 0.642061\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[294]\tvalid_0's multi_logloss: 0.642015\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[295]\tvalid_0's multi_logloss: 0.641953\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[296]\tvalid_0's multi_logloss: 0.641922\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[297]\tvalid_0's multi_logloss: 0.64192\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[298]\tvalid_0's multi_logloss: 0.641898\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[299]\tvalid_0's multi_logloss: 0.641927\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[300]\tvalid_0's multi_logloss: 0.641869\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[301]\tvalid_0's multi_logloss: 0.641807\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[302]\tvalid_0's multi_logloss: 0.641734\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[303]\tvalid_0's multi_logloss: 0.641726\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[304]\tvalid_0's multi_logloss: 0.641666\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[305]\tvalid_0's multi_logloss: 0.641615\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[306]\tvalid_0's multi_logloss: 0.641584\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[307]\tvalid_0's multi_logloss: 0.641563\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[308]\tvalid_0's multi_logloss: 0.641573\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[309]\tvalid_0's multi_logloss: 0.641588\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[310]\tvalid_0's multi_logloss: 0.641542\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[311]\tvalid_0's multi_logloss: 0.641478\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[312]\tvalid_0's multi_logloss: 0.641446\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[313]\tvalid_0's multi_logloss: 0.641433\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[314]\tvalid_0's multi_logloss: 0.641428\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[315]\tvalid_0's multi_logloss: 0.641448\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[316]\tvalid_0's multi_logloss: 0.641445\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[317]\tvalid_0's multi_logloss: 0.641407\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[318]\tvalid_0's multi_logloss: 0.641375\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[319]\tvalid_0's multi_logloss: 0.64134\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[320]\tvalid_0's multi_logloss: 0.641294\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[321]\tvalid_0's multi_logloss: 0.641284\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[322]\tvalid_0's multi_logloss: 0.64128\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[323]\tvalid_0's multi_logloss: 0.641242\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[324]\tvalid_0's multi_logloss: 0.641224\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[325]\tvalid_0's multi_logloss: 0.641189\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[326]\tvalid_0's multi_logloss: 0.64119\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[327]\tvalid_0's multi_logloss: 0.64115\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[328]\tvalid_0's multi_logloss: 0.641107\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[329]\tvalid_0's multi_logloss: 0.641091\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[330]\tvalid_0's multi_logloss: 0.641092\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[331]\tvalid_0's multi_logloss: 0.641045\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[332]\tvalid_0's multi_logloss: 0.641031\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[333]\tvalid_0's multi_logloss: 0.640969\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[334]\tvalid_0's multi_logloss: 0.640924\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[335]\tvalid_0's multi_logloss: 0.640916\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[336]\tvalid_0's multi_logloss: 0.640879\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[337]\tvalid_0's multi_logloss: 0.640875\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[338]\tvalid_0's multi_logloss: 0.640867\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[339]\tvalid_0's multi_logloss: 0.640838\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[340]\tvalid_0's multi_logloss: 0.640789\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[341]\tvalid_0's multi_logloss: 0.640759\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[342]\tvalid_0's multi_logloss: 0.640747\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[343]\tvalid_0's multi_logloss: 0.640707\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[344]\tvalid_0's multi_logloss: 0.640679\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[345]\tvalid_0's multi_logloss: 0.640665\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[346]\tvalid_0's multi_logloss: 0.640649\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[347]\tvalid_0's multi_logloss: 0.640626\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[348]\tvalid_0's multi_logloss: 0.640588\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[349]\tvalid_0's multi_logloss: 0.640566\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[350]\tvalid_0's multi_logloss: 0.640535\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[351]\tvalid_0's multi_logloss: 0.640543\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[352]\tvalid_0's multi_logloss: 0.640541\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[353]\tvalid_0's multi_logloss: 0.64047\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[354]\tvalid_0's multi_logloss: 0.64048\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[355]\tvalid_0's multi_logloss: 0.640436\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[356]\tvalid_0's multi_logloss: 0.64042\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[357]\tvalid_0's multi_logloss: 0.640395\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[358]\tvalid_0's multi_logloss: 0.640416\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[359]\tvalid_0's multi_logloss: 0.640363\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[360]\tvalid_0's multi_logloss: 0.640336\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[361]\tvalid_0's multi_logloss: 0.640315\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[362]\tvalid_0's multi_logloss: 0.640296\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[363]\tvalid_0's multi_logloss: 0.640278\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[364]\tvalid_0's multi_logloss: 0.640237\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[365]\tvalid_0's multi_logloss: 0.64021\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[366]\tvalid_0's multi_logloss: 0.640196\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[367]\tvalid_0's multi_logloss: 0.640215\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[368]\tvalid_0's multi_logloss: 0.640244\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[369]\tvalid_0's multi_logloss: 0.640247\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[370]\tvalid_0's multi_logloss: 0.640201\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[371]\tvalid_0's multi_logloss: 0.640208\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[372]\tvalid_0's multi_logloss: 0.640186\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[373]\tvalid_0's multi_logloss: 0.640203\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[374]\tvalid_0's multi_logloss: 0.640184\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[375]\tvalid_0's multi_logloss: 0.640155\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[376]\tvalid_0's multi_logloss: 0.640135\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[377]\tvalid_0's multi_logloss: 0.64009\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[378]\tvalid_0's multi_logloss: 0.640071\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[379]\tvalid_0's multi_logloss: 0.640051\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[380]\tvalid_0's multi_logloss: 0.640042\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[381]\tvalid_0's multi_logloss: 0.64003\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[382]\tvalid_0's multi_logloss: 0.64005\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[383]\tvalid_0's multi_logloss: 0.640056\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[384]\tvalid_0's multi_logloss: 0.639997\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[385]\tvalid_0's multi_logloss: 0.639991\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[386]\tvalid_0's multi_logloss: 0.639999\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[387]\tvalid_0's multi_logloss: 0.639981\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[388]\tvalid_0's multi_logloss: 0.639942\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[389]\tvalid_0's multi_logloss: 0.639921\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[390]\tvalid_0's multi_logloss: 0.63992\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[391]\tvalid_0's multi_logloss: 0.639927\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[392]\tvalid_0's multi_logloss: 0.639926\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[393]\tvalid_0's multi_logloss: 0.639867\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[394]\tvalid_0's multi_logloss: 0.639882\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[395]\tvalid_0's multi_logloss: 0.639877\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[396]\tvalid_0's multi_logloss: 0.639869\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[397]\tvalid_0's multi_logloss: 0.639849\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[398]\tvalid_0's multi_logloss: 0.639839\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[399]\tvalid_0's multi_logloss: 0.639834\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[400]\tvalid_0's multi_logloss: 0.639819\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[401]\tvalid_0's multi_logloss: 0.639821\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[402]\tvalid_0's multi_logloss: 0.639785\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[403]\tvalid_0's multi_logloss: 0.63976\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[404]\tvalid_0's multi_logloss: 0.63973\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[405]\tvalid_0's multi_logloss: 0.639733\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[406]\tvalid_0's multi_logloss: 0.639747\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[407]\tvalid_0's multi_logloss: 0.639713\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[408]\tvalid_0's multi_logloss: 0.639693\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[409]\tvalid_0's multi_logloss: 0.63963\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[410]\tvalid_0's multi_logloss: 0.639582\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[411]\tvalid_0's multi_logloss: 0.639572\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[412]\tvalid_0's multi_logloss: 0.639554\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[413]\tvalid_0's multi_logloss: 0.639564\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[414]\tvalid_0's multi_logloss: 0.639527\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[415]\tvalid_0's multi_logloss: 0.639535\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[416]\tvalid_0's multi_logloss: 0.639513\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[417]\tvalid_0's multi_logloss: 0.639483\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[418]\tvalid_0's multi_logloss: 0.639503\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[419]\tvalid_0's multi_logloss: 0.639489\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[420]\tvalid_0's multi_logloss: 0.639469\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[421]\tvalid_0's multi_logloss: 0.639454\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[422]\tvalid_0's multi_logloss: 0.639441\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[423]\tvalid_0's multi_logloss: 0.639401\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[424]\tvalid_0's multi_logloss: 0.639392\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[425]\tvalid_0's multi_logloss: 0.63939\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[426]\tvalid_0's multi_logloss: 0.639372\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[427]\tvalid_0's multi_logloss: 0.639367\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[428]\tvalid_0's multi_logloss: 0.63936\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[429]\tvalid_0's multi_logloss: 0.639348\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[430]\tvalid_0's multi_logloss: 0.639356\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[431]\tvalid_0's multi_logloss: 0.639325\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[432]\tvalid_0's multi_logloss: 0.639301\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[433]\tvalid_0's multi_logloss: 0.639263\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[434]\tvalid_0's multi_logloss: 0.639244\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[435]\tvalid_0's multi_logloss: 0.639209\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[436]\tvalid_0's multi_logloss: 0.639202\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[437]\tvalid_0's multi_logloss: 0.639222\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[438]\tvalid_0's multi_logloss: 0.63919\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[439]\tvalid_0's multi_logloss: 0.639155\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[440]\tvalid_0's multi_logloss: 0.639159\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[441]\tvalid_0's multi_logloss: 0.639145\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[442]\tvalid_0's multi_logloss: 0.639117\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[443]\tvalid_0's multi_logloss: 0.639084\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[444]\tvalid_0's multi_logloss: 0.639075\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[445]\tvalid_0's multi_logloss: 0.639074\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[446]\tvalid_0's multi_logloss: 0.639083\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[447]\tvalid_0's multi_logloss: 0.639094\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[448]\tvalid_0's multi_logloss: 0.639046\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[449]\tvalid_0's multi_logloss: 0.639017\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[450]\tvalid_0's multi_logloss: 0.639035\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[451]\tvalid_0's multi_logloss: 0.639031\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[452]\tvalid_0's multi_logloss: 0.639028\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[453]\tvalid_0's multi_logloss: 0.639\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[454]\tvalid_0's multi_logloss: 0.638973\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[455]\tvalid_0's multi_logloss: 0.638964\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[456]\tvalid_0's multi_logloss: 0.638909\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[457]\tvalid_0's multi_logloss: 0.6389\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[458]\tvalid_0's multi_logloss: 0.638866\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[459]\tvalid_0's multi_logloss: 0.638871\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[460]\tvalid_0's multi_logloss: 0.63887\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[461]\tvalid_0's multi_logloss: 0.638857\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[462]\tvalid_0's multi_logloss: 0.63886\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[463]\tvalid_0's multi_logloss: 0.638843\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[464]\tvalid_0's multi_logloss: 0.638851\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[465]\tvalid_0's multi_logloss: 0.638848\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[466]\tvalid_0's multi_logloss: 0.638818\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[467]\tvalid_0's multi_logloss: 0.638809\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[468]\tvalid_0's multi_logloss: 0.638763\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[469]\tvalid_0's multi_logloss: 0.638763\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[470]\tvalid_0's multi_logloss: 0.638755\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[471]\tvalid_0's multi_logloss: 0.638743\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[472]\tvalid_0's multi_logloss: 0.638708\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[473]\tvalid_0's multi_logloss: 0.638718\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[474]\tvalid_0's multi_logloss: 0.638675\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[475]\tvalid_0's multi_logloss: 0.638674\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[476]\tvalid_0's multi_logloss: 0.638668\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[477]\tvalid_0's multi_logloss: 0.638664\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[478]\tvalid_0's multi_logloss: 0.638641\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[479]\tvalid_0's multi_logloss: 0.638648\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[480]\tvalid_0's multi_logloss: 0.63867\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[481]\tvalid_0's multi_logloss: 0.638661\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[482]\tvalid_0's multi_logloss: 0.638656\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[483]\tvalid_0's multi_logloss: 0.638648\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[484]\tvalid_0's multi_logloss: 0.638618\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[485]\tvalid_0's multi_logloss: 0.63861\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[486]\tvalid_0's multi_logloss: 0.638627\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[487]\tvalid_0's multi_logloss: 0.638573\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[488]\tvalid_0's multi_logloss: 0.638571\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[489]\tvalid_0's multi_logloss: 0.638572\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[490]\tvalid_0's multi_logloss: 0.638567\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[491]\tvalid_0's multi_logloss: 0.638596\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[492]\tvalid_0's multi_logloss: 0.638604\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[493]\tvalid_0's multi_logloss: 0.638609\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[494]\tvalid_0's multi_logloss: 0.638594\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[495]\tvalid_0's multi_logloss: 0.638581\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[496]\tvalid_0's multi_logloss: 0.638561\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[497]\tvalid_0's multi_logloss: 0.638511\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[498]\tvalid_0's multi_logloss: 0.63848\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[499]\tvalid_0's multi_logloss: 0.638443\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[500]\tvalid_0's multi_logloss: 0.638444\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[501]\tvalid_0's multi_logloss: 0.638413\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[502]\tvalid_0's multi_logloss: 0.638405\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[503]\tvalid_0's multi_logloss: 0.638412\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[504]\tvalid_0's multi_logloss: 0.638429\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[505]\tvalid_0's multi_logloss: 0.63843\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[506]\tvalid_0's multi_logloss: 0.638421\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[507]\tvalid_0's multi_logloss: 0.638407\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[508]\tvalid_0's multi_logloss: 0.638362\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[509]\tvalid_0's multi_logloss: 0.638375\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[510]\tvalid_0's multi_logloss: 0.638398\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[511]\tvalid_0's multi_logloss: 0.638403\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[512]\tvalid_0's multi_logloss: 0.638375\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[513]\tvalid_0's multi_logloss: 0.638347\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[514]\tvalid_0's multi_logloss: 0.638316\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[515]\tvalid_0's multi_logloss: 0.638305\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[516]\tvalid_0's multi_logloss: 0.638313\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[517]\tvalid_0's multi_logloss: 0.638277\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[518]\tvalid_0's multi_logloss: 0.638298\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[519]\tvalid_0's multi_logloss: 0.638285\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[520]\tvalid_0's multi_logloss: 0.638241\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[521]\tvalid_0's multi_logloss: 0.638202\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[522]\tvalid_0's multi_logloss: 0.6382\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[523]\tvalid_0's multi_logloss: 0.638185\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[524]\tvalid_0's multi_logloss: 0.638182\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[525]\tvalid_0's multi_logloss: 0.63818\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[526]\tvalid_0's multi_logloss: 0.638184\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[527]\tvalid_0's multi_logloss: 0.638159\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[528]\tvalid_0's multi_logloss: 0.638137\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[529]\tvalid_0's multi_logloss: 0.638103\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[530]\tvalid_0's multi_logloss: 0.63809\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[531]\tvalid_0's multi_logloss: 0.638102\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[532]\tvalid_0's multi_logloss: 0.63809\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[533]\tvalid_0's multi_logloss: 0.638098\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[534]\tvalid_0's multi_logloss: 0.638073\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[535]\tvalid_0's multi_logloss: 0.638071\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[536]\tvalid_0's multi_logloss: 0.638098\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[537]\tvalid_0's multi_logloss: 0.638086\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[538]\tvalid_0's multi_logloss: 0.638072\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[539]\tvalid_0's multi_logloss: 0.638064\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[540]\tvalid_0's multi_logloss: 0.638055\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[541]\tvalid_0's multi_logloss: 0.638083\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[542]\tvalid_0's multi_logloss: 0.638049\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[543]\tvalid_0's multi_logloss: 0.638023\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[544]\tvalid_0's multi_logloss: 0.637986\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[545]\tvalid_0's multi_logloss: 0.637979\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[546]\tvalid_0's multi_logloss: 0.637959\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[547]\tvalid_0's multi_logloss: 0.637952\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[548]\tvalid_0's multi_logloss: 0.637976\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[549]\tvalid_0's multi_logloss: 0.637951\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[550]\tvalid_0's multi_logloss: 0.637954\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[551]\tvalid_0's multi_logloss: 0.637941\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[552]\tvalid_0's multi_logloss: 0.637914\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[553]\tvalid_0's multi_logloss: 0.637948\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[554]\tvalid_0's multi_logloss: 0.637969\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[555]\tvalid_0's multi_logloss: 0.637964\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[556]\tvalid_0's multi_logloss: 0.63796\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[557]\tvalid_0's multi_logloss: 0.637926\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[558]\tvalid_0's multi_logloss: 0.637911\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[559]\tvalid_0's multi_logloss: 0.637863\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[560]\tvalid_0's multi_logloss: 0.637849\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[561]\tvalid_0's multi_logloss: 0.637856\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[562]\tvalid_0's multi_logloss: 0.637872\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[563]\tvalid_0's multi_logloss: 0.637875\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[564]\tvalid_0's multi_logloss: 0.637862\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[565]\tvalid_0's multi_logloss: 0.637845\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[566]\tvalid_0's multi_logloss: 0.637819\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[567]\tvalid_0's multi_logloss: 0.637824\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[568]\tvalid_0's multi_logloss: 0.63778\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[569]\tvalid_0's multi_logloss: 0.637767\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[570]\tvalid_0's multi_logloss: 0.63777\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[571]\tvalid_0's multi_logloss: 0.637774\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[572]\tvalid_0's multi_logloss: 0.637788\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[573]\tvalid_0's multi_logloss: 0.637804\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[574]\tvalid_0's multi_logloss: 0.637795\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[575]\tvalid_0's multi_logloss: 0.637821\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[576]\tvalid_0's multi_logloss: 0.637829\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[577]\tvalid_0's multi_logloss: 0.637795\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[578]\tvalid_0's multi_logloss: 0.637762\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[579]\tvalid_0's multi_logloss: 0.637765\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[580]\tvalid_0's multi_logloss: 0.637745\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[581]\tvalid_0's multi_logloss: 0.63774\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[582]\tvalid_0's multi_logloss: 0.637738\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[583]\tvalid_0's multi_logloss: 0.637699\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[584]\tvalid_0's multi_logloss: 0.637669\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[585]\tvalid_0's multi_logloss: 0.637677\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[586]\tvalid_0's multi_logloss: 0.637676\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[587]\tvalid_0's multi_logloss: 0.637685\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[588]\tvalid_0's multi_logloss: 0.637682\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[589]\tvalid_0's multi_logloss: 0.637659\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[590]\tvalid_0's multi_logloss: 0.637643\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[591]\tvalid_0's multi_logloss: 0.63764\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[592]\tvalid_0's multi_logloss: 0.637614\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[593]\tvalid_0's multi_logloss: 0.637592\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[594]\tvalid_0's multi_logloss: 0.637601\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[595]\tvalid_0's multi_logloss: 0.637592\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[596]\tvalid_0's multi_logloss: 0.637598\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[597]\tvalid_0's multi_logloss: 0.63758\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[598]\tvalid_0's multi_logloss: 0.63757\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[599]\tvalid_0's multi_logloss: 0.637566\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[600]\tvalid_0's multi_logloss: 0.637542\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[601]\tvalid_0's multi_logloss: 0.637533\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[602]\tvalid_0's multi_logloss: 0.637524\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[603]\tvalid_0's multi_logloss: 0.637505\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[604]\tvalid_0's multi_logloss: 0.63749\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[605]\tvalid_0's multi_logloss: 0.637478\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[606]\tvalid_0's multi_logloss: 0.637448\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[607]\tvalid_0's multi_logloss: 0.637448\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[608]\tvalid_0's multi_logloss: 0.637426\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[609]\tvalid_0's multi_logloss: 0.637427\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[610]\tvalid_0's multi_logloss: 0.637423\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[611]\tvalid_0's multi_logloss: 0.637421\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[612]\tvalid_0's multi_logloss: 0.63741\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[613]\tvalid_0's multi_logloss: 0.637395\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[614]\tvalid_0's multi_logloss: 0.63738\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[615]\tvalid_0's multi_logloss: 0.637371\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[616]\tvalid_0's multi_logloss: 0.637373\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[617]\tvalid_0's multi_logloss: 0.637344\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[618]\tvalid_0's multi_logloss: 0.637319\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[619]\tvalid_0's multi_logloss: 0.637311\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[620]\tvalid_0's multi_logloss: 0.637327\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[621]\tvalid_0's multi_logloss: 0.637346\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[622]\tvalid_0's multi_logloss: 0.637333\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[623]\tvalid_0's multi_logloss: 0.637339\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[624]\tvalid_0's multi_logloss: 0.637338\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[625]\tvalid_0's multi_logloss: 0.637331\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[626]\tvalid_0's multi_logloss: 0.637345\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[627]\tvalid_0's multi_logloss: 0.637324\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[628]\tvalid_0's multi_logloss: 0.637313\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[629]\tvalid_0's multi_logloss: 0.637305\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[630]\tvalid_0's multi_logloss: 0.637293\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[631]\tvalid_0's multi_logloss: 0.637292\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[632]\tvalid_0's multi_logloss: 0.63731\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[633]\tvalid_0's multi_logloss: 0.637304\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[634]\tvalid_0's multi_logloss: 0.637302\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[635]\tvalid_0's multi_logloss: 0.637283\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[636]\tvalid_0's multi_logloss: 0.637277\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[637]\tvalid_0's multi_logloss: 0.63727\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[638]\tvalid_0's multi_logloss: 0.637281\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[639]\tvalid_0's multi_logloss: 0.637249\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[640]\tvalid_0's multi_logloss: 0.637254\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[641]\tvalid_0's multi_logloss: 0.637271\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[642]\tvalid_0's multi_logloss: 0.637237\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[643]\tvalid_0's multi_logloss: 0.637206\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[644]\tvalid_0's multi_logloss: 0.637194\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[645]\tvalid_0's multi_logloss: 0.637202\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[646]\tvalid_0's multi_logloss: 0.637197\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[647]\tvalid_0's multi_logloss: 0.637223\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[648]\tvalid_0's multi_logloss: 0.637232\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[649]\tvalid_0's multi_logloss: 0.63723\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[650]\tvalid_0's multi_logloss: 0.637226\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[651]\tvalid_0's multi_logloss: 0.637223\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[652]\tvalid_0's multi_logloss: 0.637189\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[653]\tvalid_0's multi_logloss: 0.637177\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[654]\tvalid_0's multi_logloss: 0.637161\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[655]\tvalid_0's multi_logloss: 0.637164\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[656]\tvalid_0's multi_logloss: 0.637154\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[657]\tvalid_0's multi_logloss: 0.637126\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[658]\tvalid_0's multi_logloss: 0.637128\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[659]\tvalid_0's multi_logloss: 0.637133\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[660]\tvalid_0's multi_logloss: 0.637147\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[661]\tvalid_0's multi_logloss: 0.637141\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[662]\tvalid_0's multi_logloss: 0.637155\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[663]\tvalid_0's multi_logloss: 0.637125\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[664]\tvalid_0's multi_logloss: 0.63713\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[665]\tvalid_0's multi_logloss: 0.637134\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[666]\tvalid_0's multi_logloss: 0.637108\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[667]\tvalid_0's multi_logloss: 0.637102\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[668]\tvalid_0's multi_logloss: 0.637121\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[669]\tvalid_0's multi_logloss: 0.637092\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[670]\tvalid_0's multi_logloss: 0.637069\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[671]\tvalid_0's multi_logloss: 0.637066\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[672]\tvalid_0's multi_logloss: 0.6371\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[673]\tvalid_0's multi_logloss: 0.637113\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[674]\tvalid_0's multi_logloss: 0.637081\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[675]\tvalid_0's multi_logloss: 0.637077\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[676]\tvalid_0's multi_logloss: 0.637095\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[677]\tvalid_0's multi_logloss: 0.637093\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[678]\tvalid_0's multi_logloss: 0.637117\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[679]\tvalid_0's multi_logloss: 0.637121\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[680]\tvalid_0's multi_logloss: 0.637123\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[681]\tvalid_0's multi_logloss: 0.637108\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[682]\tvalid_0's multi_logloss: 0.637108\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[683]\tvalid_0's multi_logloss: 0.637127\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[684]\tvalid_0's multi_logloss: 0.637102\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[685]\tvalid_0's multi_logloss: 0.637095\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[686]\tvalid_0's multi_logloss: 0.637106\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[687]\tvalid_0's multi_logloss: 0.637092\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[688]\tvalid_0's multi_logloss: 0.637124\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[689]\tvalid_0's multi_logloss: 0.637119\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[690]\tvalid_0's multi_logloss: 0.637131\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[691]\tvalid_0's multi_logloss: 0.637161\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[692]\tvalid_0's multi_logloss: 0.637148\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[693]\tvalid_0's multi_logloss: 0.63715\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[694]\tvalid_0's multi_logloss: 0.637159\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[695]\tvalid_0's multi_logloss: 0.637178\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[696]\tvalid_0's multi_logloss: 0.637154\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[697]\tvalid_0's multi_logloss: 0.637186\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[698]\tvalid_0's multi_logloss: 0.637203\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[699]\tvalid_0's multi_logloss: 0.637198\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[700]\tvalid_0's multi_logloss: 0.637185\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[701]\tvalid_0's multi_logloss: 0.637216\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[702]\tvalid_0's multi_logloss: 0.637233\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[703]\tvalid_0's multi_logloss: 0.637211\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[704]\tvalid_0's multi_logloss: 0.63721\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[705]\tvalid_0's multi_logloss: 0.637213\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[706]\tvalid_0's multi_logloss: 0.637184\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[707]\tvalid_0's multi_logloss: 0.637185\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[708]\tvalid_0's multi_logloss: 0.63716\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[709]\tvalid_0's multi_logloss: 0.63715\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[710]\tvalid_0's multi_logloss: 0.637123\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[711]\tvalid_0's multi_logloss: 0.637127\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[712]\tvalid_0's multi_logloss: 0.637151\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[713]\tvalid_0's multi_logloss: 0.637153\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[714]\tvalid_0's multi_logloss: 0.637162\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[715]\tvalid_0's multi_logloss: 0.637185\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[716]\tvalid_0's multi_logloss: 0.637187\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[717]\tvalid_0's multi_logloss: 0.637177\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[718]\tvalid_0's multi_logloss: 0.637165\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[719]\tvalid_0's multi_logloss: 0.637165\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[720]\tvalid_0's multi_logloss: 0.637159\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[721]\tvalid_0's multi_logloss: 0.637145\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[722]\tvalid_0's multi_logloss: 0.637148\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[723]\tvalid_0's multi_logloss: 0.637157\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[724]\tvalid_0's multi_logloss: 0.637146\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[725]\tvalid_0's multi_logloss: 0.637151\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[726]\tvalid_0's multi_logloss: 0.637123\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[727]\tvalid_0's multi_logloss: 0.637088\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[728]\tvalid_0's multi_logloss: 0.637072\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[729]\tvalid_0's multi_logloss: 0.637083\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[730]\tvalid_0's multi_logloss: 0.637057\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[731]\tvalid_0's multi_logloss: 0.637074\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[732]\tvalid_0's multi_logloss: 0.637057\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[733]\tvalid_0's multi_logloss: 0.637073\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[734]\tvalid_0's multi_logloss: 0.637033\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[735]\tvalid_0's multi_logloss: 0.637043\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[736]\tvalid_0's multi_logloss: 0.636995\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[737]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[738]\tvalid_0's multi_logloss: 0.637059\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[739]\tvalid_0's multi_logloss: 0.637067\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[740]\tvalid_0's multi_logloss: 0.637076\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[741]\tvalid_0's multi_logloss: 0.637077\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[742]\tvalid_0's multi_logloss: 0.637059\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[743]\tvalid_0's multi_logloss: 0.63704\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[744]\tvalid_0's multi_logloss: 0.637038\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[745]\tvalid_0's multi_logloss: 0.637077\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[746]\tvalid_0's multi_logloss: 0.637094\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[747]\tvalid_0's multi_logloss: 0.637101\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[748]\tvalid_0's multi_logloss: 0.637092\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[749]\tvalid_0's multi_logloss: 0.637087\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[750]\tvalid_0's multi_logloss: 0.637104\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[751]\tvalid_0's multi_logloss: 0.637124\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[752]\tvalid_0's multi_logloss: 0.637105\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[753]\tvalid_0's multi_logloss: 0.637086\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[754]\tvalid_0's multi_logloss: 0.637103\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[755]\tvalid_0's multi_logloss: 0.637092\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[756]\tvalid_0's multi_logloss: 0.637099\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[757]\tvalid_0's multi_logloss: 0.637111\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[758]\tvalid_0's multi_logloss: 0.637091\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[759]\tvalid_0's multi_logloss: 0.637094\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[760]\tvalid_0's multi_logloss: 0.637085\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[761]\tvalid_0's multi_logloss: 0.637057\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[762]\tvalid_0's multi_logloss: 0.637049\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[763]\tvalid_0's multi_logloss: 0.637033\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[764]\tvalid_0's multi_logloss: 0.637046\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[765]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[766]\tvalid_0's multi_logloss: 0.637018\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[767]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[768]\tvalid_0's multi_logloss: 0.637009\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[769]\tvalid_0's multi_logloss: 0.63701\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[770]\tvalid_0's multi_logloss: 0.637055\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[771]\tvalid_0's multi_logloss: 0.63707\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[772]\tvalid_0's multi_logloss: 0.637083\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[773]\tvalid_0's multi_logloss: 0.637079\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[774]\tvalid_0's multi_logloss: 0.637046\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[775]\tvalid_0's multi_logloss: 0.63705\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[776]\tvalid_0's multi_logloss: 0.637045\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[777]\tvalid_0's multi_logloss: 0.637029\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[778]\tvalid_0's multi_logloss: 0.637044\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[779]\tvalid_0's multi_logloss: 0.637067\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[780]\tvalid_0's multi_logloss: 0.637052\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[781]\tvalid_0's multi_logloss: 0.63704\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[782]\tvalid_0's multi_logloss: 0.637044\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[783]\tvalid_0's multi_logloss: 0.63702\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[784]\tvalid_0's multi_logloss: 0.637021\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[785]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[786]\tvalid_0's multi_logloss: 0.63702\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[787]\tvalid_0's multi_logloss: 0.637006\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[788]\tvalid_0's multi_logloss: 0.636995\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[789]\tvalid_0's multi_logloss: 0.637011\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[790]\tvalid_0's multi_logloss: 0.637007\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[791]\tvalid_0's multi_logloss: 0.637019\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[792]\tvalid_0's multi_logloss: 0.637015\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[793]\tvalid_0's multi_logloss: 0.637005\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[794]\tvalid_0's multi_logloss: 0.636997\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[795]\tvalid_0's multi_logloss: 0.637019\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[796]\tvalid_0's multi_logloss: 0.636992\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[797]\tvalid_0's multi_logloss: 0.636984\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[798]\tvalid_0's multi_logloss: 0.637\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[799]\tvalid_0's multi_logloss: 0.636969\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[800]\tvalid_0's multi_logloss: 0.636952\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[801]\tvalid_0's multi_logloss: 0.636957\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[802]\tvalid_0's multi_logloss: 0.636958\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[803]\tvalid_0's multi_logloss: 0.636955\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[804]\tvalid_0's multi_logloss: 0.636978\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[805]\tvalid_0's multi_logloss: 0.636937\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[806]\tvalid_0's multi_logloss: 0.636913\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[807]\tvalid_0's multi_logloss: 0.6369\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[808]\tvalid_0's multi_logloss: 0.636897\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[809]\tvalid_0's multi_logloss: 0.636878\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[810]\tvalid_0's multi_logloss: 0.636865\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[811]\tvalid_0's multi_logloss: 0.636845\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[812]\tvalid_0's multi_logloss: 0.636847\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[813]\tvalid_0's multi_logloss: 0.636832\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[814]\tvalid_0's multi_logloss: 0.636832\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[815]\tvalid_0's multi_logloss: 0.636859\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[816]\tvalid_0's multi_logloss: 0.636856\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[817]\tvalid_0's multi_logloss: 0.636861\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[818]\tvalid_0's multi_logloss: 0.636891\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[819]\tvalid_0's multi_logloss: 0.636866\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[820]\tvalid_0's multi_logloss: 0.636869\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[821]\tvalid_0's multi_logloss: 0.636895\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[822]\tvalid_0's multi_logloss: 0.636895\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[823]\tvalid_0's multi_logloss: 0.636901\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[824]\tvalid_0's multi_logloss: 0.636902\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[825]\tvalid_0's multi_logloss: 0.636914\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[826]\tvalid_0's multi_logloss: 0.636885\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[827]\tvalid_0's multi_logloss: 0.636917\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[828]\tvalid_0's multi_logloss: 0.636948\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[829]\tvalid_0's multi_logloss: 0.636957\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[830]\tvalid_0's multi_logloss: 0.636982\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[831]\tvalid_0's multi_logloss: 0.636952\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[832]\tvalid_0's multi_logloss: 0.636986\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[833]\tvalid_0's multi_logloss: 0.637005\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[834]\tvalid_0's multi_logloss: 0.636978\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[835]\tvalid_0's multi_logloss: 0.636947\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[836]\tvalid_0's multi_logloss: 0.636954\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[837]\tvalid_0's multi_logloss: 0.636966\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[838]\tvalid_0's multi_logloss: 0.636958\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[839]\tvalid_0's multi_logloss: 0.636968\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[840]\tvalid_0's multi_logloss: 0.636971\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[841]\tvalid_0's multi_logloss: 0.636961\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[842]\tvalid_0's multi_logloss: 0.636955\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[843]\tvalid_0's multi_logloss: 0.636954\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[844]\tvalid_0's multi_logloss: 0.636922\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[845]\tvalid_0's multi_logloss: 0.636912\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[846]\tvalid_0's multi_logloss: 0.636891\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[847]\tvalid_0's multi_logloss: 0.636894\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[848]\tvalid_0's multi_logloss: 0.636913\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[849]\tvalid_0's multi_logloss: 0.636907\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[850]\tvalid_0's multi_logloss: 0.636902\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[851]\tvalid_0's multi_logloss: 0.63691\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[852]\tvalid_0's multi_logloss: 0.636933\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[853]\tvalid_0's multi_logloss: 0.63694\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[854]\tvalid_0's multi_logloss: 0.636939\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[855]\tvalid_0's multi_logloss: 0.636963\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[856]\tvalid_0's multi_logloss: 0.636942\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[857]\tvalid_0's multi_logloss: 0.636946\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[858]\tvalid_0's multi_logloss: 0.636932\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[859]\tvalid_0's multi_logloss: 0.636906\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[860]\tvalid_0's multi_logloss: 0.636892\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[861]\tvalid_0's multi_logloss: 0.636906\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[862]\tvalid_0's multi_logloss: 0.636903\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[863]\tvalid_0's multi_logloss: 0.636892\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[864]\tvalid_0's multi_logloss: 0.636874\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[865]\tvalid_0's multi_logloss: 0.636857\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[866]\tvalid_0's multi_logloss: 0.636854\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[867]\tvalid_0's multi_logloss: 0.636851\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[868]\tvalid_0's multi_logloss: 0.636845\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[869]\tvalid_0's multi_logloss: 0.636826\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[870]\tvalid_0's multi_logloss: 0.63683\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[871]\tvalid_0's multi_logloss: 0.636857\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[872]\tvalid_0's multi_logloss: 0.636823\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[873]\tvalid_0's multi_logloss: 0.636832\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[874]\tvalid_0's multi_logloss: 0.636847\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[875]\tvalid_0's multi_logloss: 0.63683\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[876]\tvalid_0's multi_logloss: 0.636821\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[877]\tvalid_0's multi_logloss: 0.636843\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[878]\tvalid_0's multi_logloss: 0.636834\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[879]\tvalid_0's multi_logloss: 0.636825\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[880]\tvalid_0's multi_logloss: 0.636833\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[881]\tvalid_0's multi_logloss: 0.636826\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[882]\tvalid_0's multi_logloss: 0.636846\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[883]\tvalid_0's multi_logloss: 0.636855\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[884]\tvalid_0's multi_logloss: 0.636868\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[885]\tvalid_0's multi_logloss: 0.636854\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[886]\tvalid_0's multi_logloss: 0.636833\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[887]\tvalid_0's multi_logloss: 0.636853\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[888]\tvalid_0's multi_logloss: 0.636854\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[889]\tvalid_0's multi_logloss: 0.636849\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[890]\tvalid_0's multi_logloss: 0.636846\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[891]\tvalid_0's multi_logloss: 0.63683\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[892]\tvalid_0's multi_logloss: 0.63683\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[893]\tvalid_0's multi_logloss: 0.636825\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[894]\tvalid_0's multi_logloss: 0.636823\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[895]\tvalid_0's multi_logloss: 0.636842\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[896]\tvalid_0's multi_logloss: 0.636857\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[897]\tvalid_0's multi_logloss: 0.636878\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[898]\tvalid_0's multi_logloss: 0.636888\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[899]\tvalid_0's multi_logloss: 0.636884\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[900]\tvalid_0's multi_logloss: 0.636851\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[901]\tvalid_0's multi_logloss: 0.636824\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[902]\tvalid_0's multi_logloss: 0.636825\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[903]\tvalid_0's multi_logloss: 0.636836\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[904]\tvalid_0's multi_logloss: 0.63683\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[905]\tvalid_0's multi_logloss: 0.636854\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[906]\tvalid_0's multi_logloss: 0.636841\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[907]\tvalid_0's multi_logloss: 0.636808\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[908]\tvalid_0's multi_logloss: 0.636805\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[909]\tvalid_0's multi_logloss: 0.63682\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[910]\tvalid_0's multi_logloss: 0.636805\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[911]\tvalid_0's multi_logloss: 0.636779\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[912]\tvalid_0's multi_logloss: 0.636786\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[913]\tvalid_0's multi_logloss: 0.636785\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[914]\tvalid_0's multi_logloss: 0.636799\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[915]\tvalid_0's multi_logloss: 0.636778\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[916]\tvalid_0's multi_logloss: 0.636775\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[917]\tvalid_0's multi_logloss: 0.636767\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[918]\tvalid_0's multi_logloss: 0.636744\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[919]\tvalid_0's multi_logloss: 0.636742\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[920]\tvalid_0's multi_logloss: 0.636743\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[921]\tvalid_0's multi_logloss: 0.636756\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[922]\tvalid_0's multi_logloss: 0.636771\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[923]\tvalid_0's multi_logloss: 0.636776\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[924]\tvalid_0's multi_logloss: 0.636782\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[925]\tvalid_0's multi_logloss: 0.63677\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[926]\tvalid_0's multi_logloss: 0.636775\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[927]\tvalid_0's multi_logloss: 0.636782\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[928]\tvalid_0's multi_logloss: 0.636777\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[929]\tvalid_0's multi_logloss: 0.636773\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[930]\tvalid_0's multi_logloss: 0.636744\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[931]\tvalid_0's multi_logloss: 0.636756\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[932]\tvalid_0's multi_logloss: 0.636739\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[933]\tvalid_0's multi_logloss: 0.636756\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[934]\tvalid_0's multi_logloss: 0.636738\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[935]\tvalid_0's multi_logloss: 0.636754\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[936]\tvalid_0's multi_logloss: 0.63676\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[937]\tvalid_0's multi_logloss: 0.636771\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[938]\tvalid_0's multi_logloss: 0.636797\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[939]\tvalid_0's multi_logloss: 0.636817\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[940]\tvalid_0's multi_logloss: 0.636813\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[941]\tvalid_0's multi_logloss: 0.636832\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[942]\tvalid_0's multi_logloss: 0.636814\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[943]\tvalid_0's multi_logloss: 0.636831\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[944]\tvalid_0's multi_logloss: 0.636823\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[945]\tvalid_0's multi_logloss: 0.636819\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[946]\tvalid_0's multi_logloss: 0.636823\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[947]\tvalid_0's multi_logloss: 0.636831\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[948]\tvalid_0's multi_logloss: 0.636855\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[949]\tvalid_0's multi_logloss: 0.636838\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[950]\tvalid_0's multi_logloss: 0.636838\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[951]\tvalid_0's multi_logloss: 0.636816\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[952]\tvalid_0's multi_logloss: 0.63682\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[953]\tvalid_0's multi_logloss: 0.6368\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[954]\tvalid_0's multi_logloss: 0.636797\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[955]\tvalid_0's multi_logloss: 0.636811\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[956]\tvalid_0's multi_logloss: 0.636815\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[957]\tvalid_0's multi_logloss: 0.636823\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[958]\tvalid_0's multi_logloss: 0.636823\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[959]\tvalid_0's multi_logloss: 0.636853\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[960]\tvalid_0's multi_logloss: 0.63685\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[961]\tvalid_0's multi_logloss: 0.636871\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[962]\tvalid_0's multi_logloss: 0.636857\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[963]\tvalid_0's multi_logloss: 0.63685\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[964]\tvalid_0's multi_logloss: 0.636864\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[965]\tvalid_0's multi_logloss: 0.636843\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[966]\tvalid_0's multi_logloss: 0.636846\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[967]\tvalid_0's multi_logloss: 0.636841\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[968]\tvalid_0's multi_logloss: 0.636853\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[969]\tvalid_0's multi_logloss: 0.636883\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[970]\tvalid_0's multi_logloss: 0.636867\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[971]\tvalid_0's multi_logloss: 0.636882\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[972]\tvalid_0's multi_logloss: 0.636915\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[973]\tvalid_0's multi_logloss: 0.636909\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[974]\tvalid_0's multi_logloss: 0.636911\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[975]\tvalid_0's multi_logloss: 0.636934\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[976]\tvalid_0's multi_logloss: 0.636912\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[977]\tvalid_0's multi_logloss: 0.636932\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[978]\tvalid_0's multi_logloss: 0.636927\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[979]\tvalid_0's multi_logloss: 0.636939\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[980]\tvalid_0's multi_logloss: 0.636936\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[981]\tvalid_0's multi_logloss: 0.636948\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[982]\tvalid_0's multi_logloss: 0.636971\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[983]\tvalid_0's multi_logloss: 0.636984\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[984]\tvalid_0's multi_logloss: 0.63699\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[985]\tvalid_0's multi_logloss: 0.636971\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[986]\tvalid_0's multi_logloss: 0.636955\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[987]\tvalid_0's multi_logloss: 0.636975\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[988]\tvalid_0's multi_logloss: 0.636973\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[989]\tvalid_0's multi_logloss: 0.636986\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[990]\tvalid_0's multi_logloss: 0.636964\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[991]\tvalid_0's multi_logloss: 0.636964\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[992]\tvalid_0's multi_logloss: 0.636953\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[993]\tvalid_0's multi_logloss: 0.636983\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[994]\tvalid_0's multi_logloss: 0.636985\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[995]\tvalid_0's multi_logloss: 0.637001\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[996]\tvalid_0's multi_logloss: 0.637005\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[997]\tvalid_0's multi_logloss: 0.637002\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[998]\tvalid_0's multi_logloss: 0.637021\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[999]\tvalid_0's multi_logloss: 0.637021\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1000]\tvalid_0's multi_logloss: 0.636987\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1001]\tvalid_0's multi_logloss: 0.636988\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1002]\tvalid_0's multi_logloss: 0.636985\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1003]\tvalid_0's multi_logloss: 0.636993\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1004]\tvalid_0's multi_logloss: 0.637021\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1005]\tvalid_0's multi_logloss: 0.637037\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1006]\tvalid_0's multi_logloss: 0.637039\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1007]\tvalid_0's multi_logloss: 0.637056\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1008]\tvalid_0's multi_logloss: 0.637045\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1009]\tvalid_0's multi_logloss: 0.637032\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1010]\tvalid_0's multi_logloss: 0.637045\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1011]\tvalid_0's multi_logloss: 0.637043\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1012]\tvalid_0's multi_logloss: 0.637054\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1013]\tvalid_0's multi_logloss: 0.637055\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1014]\tvalid_0's multi_logloss: 0.637035\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1015]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1016]\tvalid_0's multi_logloss: 0.637046\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1017]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1018]\tvalid_0's multi_logloss: 0.637033\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1019]\tvalid_0's multi_logloss: 0.637036\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1020]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1021]\tvalid_0's multi_logloss: 0.637007\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1022]\tvalid_0's multi_logloss: 0.637033\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1023]\tvalid_0's multi_logloss: 0.637012\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1024]\tvalid_0's multi_logloss: 0.637009\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1025]\tvalid_0's multi_logloss: 0.637007\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1026]\tvalid_0's multi_logloss: 0.637015\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1027]\tvalid_0's multi_logloss: 0.637008\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1028]\tvalid_0's multi_logloss: 0.637008\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1029]\tvalid_0's multi_logloss: 0.637016\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1030]\tvalid_0's multi_logloss: 0.637\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1031]\tvalid_0's multi_logloss: 0.636988\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1032]\tvalid_0's multi_logloss: 0.637003\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1033]\tvalid_0's multi_logloss: 0.637013\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1034]\tvalid_0's multi_logloss: 0.637012\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1035]\tvalid_0's multi_logloss: 0.637\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1036]\tvalid_0's multi_logloss: 0.63701\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1037]\tvalid_0's multi_logloss: 0.637001\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1038]\tvalid_0's multi_logloss: 0.637014\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1039]\tvalid_0's multi_logloss: 0.637028\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1040]\tvalid_0's multi_logloss: 0.637015\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1041]\tvalid_0's multi_logloss: 0.637009\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1042]\tvalid_0's multi_logloss: 0.637018\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1043]\tvalid_0's multi_logloss: 0.637003\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1044]\tvalid_0's multi_logloss: 0.636989\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1045]\tvalid_0's multi_logloss: 0.636979\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1046]\tvalid_0's multi_logloss: 0.636961\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1047]\tvalid_0's multi_logloss: 0.636973\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1048]\tvalid_0's multi_logloss: 0.636974\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1049]\tvalid_0's multi_logloss: 0.636989\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1050]\tvalid_0's multi_logloss: 0.637018\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1051]\tvalid_0's multi_logloss: 0.637036\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1052]\tvalid_0's multi_logloss: 0.637069\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1053]\tvalid_0's multi_logloss: 0.637071\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1054]\tvalid_0's multi_logloss: 0.637095\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1055]\tvalid_0's multi_logloss: 0.637109\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1056]\tvalid_0's multi_logloss: 0.637115\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1057]\tvalid_0's multi_logloss: 0.637093\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1058]\tvalid_0's multi_logloss: 0.63709\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1059]\tvalid_0's multi_logloss: 0.637075\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1060]\tvalid_0's multi_logloss: 0.637095\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1061]\tvalid_0's multi_logloss: 0.637068\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1062]\tvalid_0's multi_logloss: 0.637068\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1063]\tvalid_0's multi_logloss: 0.637065\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1064]\tvalid_0's multi_logloss: 0.637048\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1065]\tvalid_0's multi_logloss: 0.637029\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1066]\tvalid_0's multi_logloss: 0.637029\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1067]\tvalid_0's multi_logloss: 0.637026\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1068]\tvalid_0's multi_logloss: 0.637028\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1069]\tvalid_0's multi_logloss: 0.637021\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1070]\tvalid_0's multi_logloss: 0.637019\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1071]\tvalid_0's multi_logloss: 0.637037\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1072]\tvalid_0's multi_logloss: 0.637032\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1073]\tvalid_0's multi_logloss: 0.637042\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1074]\tvalid_0's multi_logloss: 0.637018\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1075]\tvalid_0's multi_logloss: 0.636995\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1076]\tvalid_0's multi_logloss: 0.636995\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1077]\tvalid_0's multi_logloss: 0.637002\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1078]\tvalid_0's multi_logloss: 0.637003\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1079]\tvalid_0's multi_logloss: 0.636998\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1080]\tvalid_0's multi_logloss: 0.637032\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1081]\tvalid_0's multi_logloss: 0.637001\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1082]\tvalid_0's multi_logloss: 0.637008\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1083]\tvalid_0's multi_logloss: 0.637013\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1084]\tvalid_0's multi_logloss: 0.637016\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1085]\tvalid_0's multi_logloss: 0.637028\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1086]\tvalid_0's multi_logloss: 0.637006\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1087]\tvalid_0's multi_logloss: 0.637015\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1088]\tvalid_0's multi_logloss: 0.637012\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1089]\tvalid_0's multi_logloss: 0.637023\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1090]\tvalid_0's multi_logloss: 0.637016\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1091]\tvalid_0's multi_logloss: 0.637036\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1092]\tvalid_0's multi_logloss: 0.637017\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1093]\tvalid_0's multi_logloss: 0.637031\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1094]\tvalid_0's multi_logloss: 0.637035\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1095]\tvalid_0's multi_logloss: 0.637041\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1096]\tvalid_0's multi_logloss: 0.63706\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1097]\tvalid_0's multi_logloss: 0.63703\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1098]\tvalid_0's multi_logloss: 0.637021\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1099]\tvalid_0's multi_logloss: 0.636994\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1100]\tvalid_0's multi_logloss: 0.636999\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1101]\tvalid_0's multi_logloss: 0.63701\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1102]\tvalid_0's multi_logloss: 0.637019\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1103]\tvalid_0's multi_logloss: 0.637029\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1104]\tvalid_0's multi_logloss: 0.637024\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1105]\tvalid_0's multi_logloss: 0.637002\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1106]\tvalid_0's multi_logloss: 0.636987\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1107]\tvalid_0's multi_logloss: 0.63702\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1108]\tvalid_0's multi_logloss: 0.637017\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1109]\tvalid_0's multi_logloss: 0.637003\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1110]\tvalid_0's multi_logloss: 0.637\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1111]\tvalid_0's multi_logloss: 0.636994\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1112]\tvalid_0's multi_logloss: 0.636986\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1113]\tvalid_0's multi_logloss: 0.637009\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1114]\tvalid_0's multi_logloss: 0.637009\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1115]\tvalid_0's multi_logloss: 0.637017\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1116]\tvalid_0's multi_logloss: 0.637032\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1117]\tvalid_0's multi_logloss: 0.637054\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1118]\tvalid_0's multi_logloss: 0.637037\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1119]\tvalid_0's multi_logloss: 0.637026\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1120]\tvalid_0's multi_logloss: 0.637036\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1121]\tvalid_0's multi_logloss: 0.637029\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1122]\tvalid_0's multi_logloss: 0.637038\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1123]\tvalid_0's multi_logloss: 0.637048\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1124]\tvalid_0's multi_logloss: 0.637066\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1125]\tvalid_0's multi_logloss: 0.637082\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1126]\tvalid_0's multi_logloss: 0.637073\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1127]\tvalid_0's multi_logloss: 0.63707\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[1128]\tvalid_0's multi_logloss: 0.637087\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1129]\tvalid_0's multi_logloss: 0.637081\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1130]\tvalid_0's multi_logloss: 0.637083\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1131]\tvalid_0's multi_logloss: 0.637083\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1132]\tvalid_0's multi_logloss: 0.637075\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 3\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1133]\tvalid_0's multi_logloss: 0.637087\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[LightGBM] [Debug] Trained a tree with leaves = 5 and depth = 4\n",
            "[1134]\tvalid_0's multi_logloss: 0.637063\n",
            "Early stopping, best iteration is:\n",
            "[934]\tvalid_0's multi_logloss: 0.636738\n",
            "lightgbm: train_f1 = 0.4771662516355042\n",
            "lightgbm: valid_f1 = 0.45734422308729616\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_fin"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        },
        "id": "Q-qRESfBMX0i",
        "outputId": "d4adc985-9834-4cc2-9d0b-6f022af2d312"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      abort  access       act    action  activ  actual  administr     admit  \\\n",
              "0       0.0     0.0  0.158984  0.000000    0.0     0.0   0.000000  0.000000   \n",
              "1       0.0     0.0  0.000000  0.282648    0.0     0.0   0.000000  0.000000   \n",
              "2       0.0     0.0  0.068059  0.000000    0.0     0.0   0.124201  0.000000   \n",
              "3       0.0     0.0  0.000000  0.000000    0.0     0.0   0.000000  0.182098   \n",
              "4       0.0     0.0  0.000000  0.000000    0.0     0.0   0.000000  0.000000   \n",
              "...     ...     ...       ...       ...    ...     ...        ...       ...   \n",
              "1235    0.0     0.0  0.073933  0.000000    0.0     0.0   0.000000  0.000000   \n",
              "1236    0.0     0.0  0.062422  0.000000    0.0     0.0   0.341743  0.000000   \n",
              "1237    0.0     0.0  0.000000  0.076272    0.0     0.0   0.000000  0.000000   \n",
              "1238    0.0     0.0  0.000000  0.000000    0.0     0.0   0.000000  0.000000   \n",
              "1239    0.0     0.0  0.000000  0.000000    0.0     0.0   0.000000  0.000000   \n",
              "\n",
              "        affirm     agenc  ...  would  writ  year      york  first_party  \\\n",
              "0     0.000000  0.000000  ...    0.0   0.0   0.0  0.000000       others   \n",
              "1     0.048168  0.000000  ...    0.0   0.0   0.0  0.000000       PERSON   \n",
              "2     0.000000  0.000000  ...    0.0   0.0   0.0  0.000000          ORG   \n",
              "3     0.170553  0.000000  ...    0.0   0.0   0.0  0.000000       PERSON   \n",
              "4     0.000000  0.000000  ...    0.0   0.0   0.0  0.000000       PERSON   \n",
              "...        ...       ...  ...    ...   ...   ...       ...          ...   \n",
              "1235  0.000000  0.000000  ...    0.0   0.0   0.0  0.163162          ORG   \n",
              "1236  0.000000  0.242915  ...    0.0   0.0   0.0  0.000000       others   \n",
              "1237  0.051992  0.000000  ...    0.0   0.0   0.0  0.000000       PERSON   \n",
              "1238  0.000000  0.000000  ...    0.0   0.0   0.0  0.000000          ORG   \n",
              "1239  0.105982  0.000000  ...    0.0   0.0   0.0  0.122720       PERSON   \n",
              "\n",
              "      second_party  issued_area  winning_percent  sen_len  word_len  \n",
              "0              GPE       others                2        7       201  \n",
              "1              ORG     criminal                2        7       219  \n",
              "2              ORG     criminal                2        8       191  \n",
              "3              GPE       others                2        3        59  \n",
              "4           others       others                2        9       200  \n",
              "...            ...          ...              ...      ...       ...  \n",
              "1235           ORG     criminal                2        5       157  \n",
              "1236           ORG     criminal                2        6       218  \n",
              "1237        PERSON       others                2        4       148  \n",
              "1238        PERSON       others                2        7       185  \n",
              "1239           GPE       others                2        4       135  \n",
              "\n",
              "[1240 rows x 406 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-2e0eedfe-e0a8-4b4c-9b35-606be3de0786\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>abort</th>\n",
              "      <th>access</th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activ</th>\n",
              "      <th>actual</th>\n",
              "      <th>administr</th>\n",
              "      <th>admit</th>\n",
              "      <th>affirm</th>\n",
              "      <th>agenc</th>\n",
              "      <th>...</th>\n",
              "      <th>would</th>\n",
              "      <th>writ</th>\n",
              "      <th>year</th>\n",
              "      <th>york</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>issued_area</th>\n",
              "      <th>winning_percent</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.158984</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>others</td>\n",
              "      <td>GPE</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.282648</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.048168</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>ORG</td>\n",
              "      <td>criminal</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.068059</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.124201</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>criminal</td>\n",
              "      <td>2</td>\n",
              "      <td>8</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.182098</td>\n",
              "      <td>0.170553</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>others</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>9</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.073933</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.163162</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>criminal</td>\n",
              "      <td>2</td>\n",
              "      <td>5</td>\n",
              "      <td>157</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.062422</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.341743</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.242915</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>others</td>\n",
              "      <td>ORG</td>\n",
              "      <td>criminal</td>\n",
              "      <td>2</td>\n",
              "      <td>6</td>\n",
              "      <td>218</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.076272</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.051992</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>148</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>ORG</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>7</td>\n",
              "      <td>185</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.105982</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>...</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.122720</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>4</td>\n",
              "      <td>135</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows × 406 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-2e0eedfe-e0a8-4b4c-9b35-606be3de0786')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-2e0eedfe-e0a8-4b4c-9b35-606be3de0786 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-2e0eedfe-e0a8-4b4c-9b35-606be3de0786');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test = np.asarray(test_fin)\n",
        "Y_pred = lgb_model_base.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 398
        },
        "id": "vZe4PoGf5kU0",
        "outputId": "566c3316-08fb-413a-f172-843cde113ee8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-106-1c3feda773d1>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mX_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0masarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtest_fin\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mY_pred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlgb_model_base\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mDataFrame\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mY_pred\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalue_counts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape, **kwargs)\u001b[0m\n\u001b[1;32m   3536\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3537\u001b[0m                 \u001b[0mnum_iteration\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 3538\u001b[0;31m         return predictor.predict(data, start_iteration, num_iteration,\n\u001b[0m\u001b[1;32m   3539\u001b[0m                                  \u001b[0mraw_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_leaf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpred_contrib\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   3540\u001b[0m                                  data_has_header, is_reshape)\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36mpredict\u001b[0;34m(self, data, start_iteration, num_iteration, raw_score, pred_leaf, pred_contrib, data_has_header, is_reshape)\u001b[0m\n\u001b[1;32m    846\u001b[0m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_csc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    847\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mndarray\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 848\u001b[0;31m             \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__pred_for_np2d\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    849\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    850\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36m__pred_for_np2d\u001b[0;34m(self, mat, start_iteration, num_iteration, predict_type)\u001b[0m\n\u001b[1;32m    936\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnrow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    937\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 938\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0minner_predict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    939\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    940\u001b[0m     def __create_sparse_native(self, cs, out_shape, out_ptr_indptr, out_ptr_indices, out_ptr_data,\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/lightgbm/basic.py\u001b[0m in \u001b[0;36minner_predict\u001b[0;34m(mat, start_iteration, num_iteration, predict_type, preds)\u001b[0m\n\u001b[1;32m    898\u001b[0m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    899\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# change non-float data to float data, need to copy\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 900\u001b[0;31m                 \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0marray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msize\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfloat32\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    901\u001b[0m             \u001b[0mptr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtype_ptr_data\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mc_float_array\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    902\u001b[0m             \u001b[0mn_preds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__get_num_preds\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnum_iteration\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmat\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpredict_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: could not convert string to float: 'others'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit['first_party_winner'] = Y_pred\n",
        "submit.to_csv('./submit_xgboost0703.csv', index=False)\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mhYol2K8KeK9",
        "outputId": "63d02e53-3e5a-4d48-e985-55bdb8d3acf5"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Boosting 앙상블"
      ],
      "metadata": {
        "id": "SNA5-CRM6m_j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 특정 범주형 변수(categorical variable)을 더미변수 생성\n",
        "train_cat = pd.get_dummies(data = train_df[[\"first_party\",\"second_party\",\"issued_area\"]], drop_first=True)\n",
        "test_cat = pd.get_dummies(data = test_df[[\"first_party\",\"second_party\",\"issued_area\"]], drop_first=True)\n",
        "\n",
        "#train_cat = train_df[list(train_df.select_dtypes(include='category').columns)]\n",
        "#test_cat = test_df[list(train_df.select_dtypes(include='category').columns)]\n",
        "\n",
        "train_fin = pd.concat([train_fact,train_cat,train_num,train_target],axis=1,join='inner')\n",
        "test_fin = pd.concat([test_fact, test_cat, test_num],axis=1,join='inner')\n",
        "\n",
        "X_train = train_fin.drop(columns={'first_party_winner'})\n",
        "y_train = train_fin['first_party_winner'].astype('category')\n",
        "\n",
        "X_test = np.asarray(test_fin)"
      ],
      "metadata": {
        "id": "LccXPn0LOPf7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train"
      ],
      "metadata": {
        "id": "XsXMZ-vvS89i",
        "outputId": "281d2da6-85e4-44a8-fd56-4e9624d6f921",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 487
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           act    action     activ  actual     addit  administr     admit  \\\n",
              "0     0.071479  0.000000  0.141011     0.0  0.000000        0.0  0.000000   \n",
              "1     0.000000  0.000000  0.000000     0.0  0.000000        0.0  0.000000   \n",
              "2     0.000000  0.000000  0.000000     0.0  0.000000        0.0  0.000000   \n",
              "3     0.000000  0.000000  0.000000     0.0  0.000000        0.0  0.000000   \n",
              "4     0.000000  0.000000  0.000000     0.0  0.000000        0.0  0.175023   \n",
              "...        ...       ...       ...     ...       ...        ...       ...   \n",
              "2473  0.138034  0.000000  0.000000     0.0  0.000000        0.0  0.000000   \n",
              "2474  0.000000  0.090972  0.000000     0.0  0.000000        0.0  0.000000   \n",
              "2475  0.000000  0.000000  0.000000     0.0  0.000000        0.0  0.000000   \n",
              "2476  0.178368  0.000000  0.000000     0.0  0.000000        0.0  0.000000   \n",
              "2477  0.000000  0.000000  0.000000     0.0  0.117976        0.0  0.000000   \n",
              "\n",
              "        affirm     agenc  agent  ...  first_party_ORG  first_party_PERSON  \\\n",
              "0     0.000000  0.000000    0.0  ...                0                   1   \n",
              "1     0.000000  0.000000    0.0  ...                0                   1   \n",
              "2     0.000000  0.000000    0.0  ...                0                   1   \n",
              "3     0.000000  0.000000    0.0  ...                0                   0   \n",
              "4     0.078894  0.000000    0.0  ...                0                   1   \n",
              "...        ...       ...    ...  ...              ...                 ...   \n",
              "2473  0.000000  0.145406    0.0  ...                1                   0   \n",
              "2474  0.061473  0.000000    0.0  ...                0                   1   \n",
              "2475  0.053455  0.000000    0.0  ...                1                   0   \n",
              "2476  0.057859  0.000000    0.0  ...                1                   0   \n",
              "2477  0.054840  0.000000    0.0  ...                0                   0   \n",
              "\n",
              "      first_party_others  second_party_ORG  second_party_PERSON  \\\n",
              "0                      0                 0                    1   \n",
              "1                      0                 0                    1   \n",
              "2                      0                 0                    0   \n",
              "3                      1                 0                    0   \n",
              "4                      0                 0                    0   \n",
              "...                  ...               ...                  ...   \n",
              "2473                   0                 1                    0   \n",
              "2474                   0                 1                    0   \n",
              "2475                   0                 0                    0   \n",
              "2476                   0                 0                    0   \n",
              "2477                   1                 1                    0   \n",
              "\n",
              "      second_party_others  issued_area_criminal  issued_area_others  sen_len  \\\n",
              "0                       0                     0                   1        7   \n",
              "1                       0                     1                   0        7   \n",
              "2                       0                     1                   0        8   \n",
              "3                       1                     0                   1        3   \n",
              "4                       0                     0                   1        9   \n",
              "...                   ...                   ...                 ...      ...   \n",
              "2473                    0                     0                   1        5   \n",
              "2474                    0                     0                   1        7   \n",
              "2475                    0                     1                   0        6   \n",
              "2476                    1                     0                   1        8   \n",
              "2477                    0                     0                   1        6   \n",
              "\n",
              "      word_len  \n",
              "0          201  \n",
              "1          219  \n",
              "2          191  \n",
              "3           59  \n",
              "4          200  \n",
              "...        ...  \n",
              "2473       144  \n",
              "2474       184  \n",
              "2475       195  \n",
              "2476       194  \n",
              "2477       205  \n",
              "\n",
              "[2478 rows x 410 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-501e631c-e932-41b4-9726-fe04c77a5521\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>act</th>\n",
              "      <th>action</th>\n",
              "      <th>activ</th>\n",
              "      <th>actual</th>\n",
              "      <th>addit</th>\n",
              "      <th>administr</th>\n",
              "      <th>admit</th>\n",
              "      <th>affirm</th>\n",
              "      <th>agenc</th>\n",
              "      <th>agent</th>\n",
              "      <th>...</th>\n",
              "      <th>first_party_ORG</th>\n",
              "      <th>first_party_PERSON</th>\n",
              "      <th>first_party_others</th>\n",
              "      <th>second_party_ORG</th>\n",
              "      <th>second_party_PERSON</th>\n",
              "      <th>second_party_others</th>\n",
              "      <th>issued_area_criminal</th>\n",
              "      <th>issued_area_others</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.071479</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.141011</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>201</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>7</td>\n",
              "      <td>219</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>8</td>\n",
              "      <td>191</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.175023</td>\n",
              "      <td>0.078894</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>9</td>\n",
              "      <td>200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>0.138034</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.145406</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>5</td>\n",
              "      <td>144</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.090972</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.061473</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>7</td>\n",
              "      <td>184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.053455</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>6</td>\n",
              "      <td>195</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>0.178368</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.057859</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>8</td>\n",
              "      <td>194</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.117976</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.054840</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.0</td>\n",
              "      <td>...</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "      <td>205</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2478 rows × 410 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-501e631c-e932-41b4-9726-fe04c77a5521')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-501e631c-e932-41b4-9726-fe04c77a5521 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-501e631c-e932-41b4-9726-fe04c77a5521');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 121
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from lightgbm import LGBMClassifier\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "from sklearn.model_selection import train_test_split, KFold\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix, classification_report\n",
        "\n",
        "model1 = LGBMClassifier(n_estimators=400)\n",
        "model1.fit(X=X_train, y=y_train)\n",
        "\n",
        "model2 = XGBClassifier()\n",
        "model2.fit(X=X_train, y=y_train)\n",
        "\n",
        "model3 =  RandomForestClassifier()\n",
        "model3.fit(X=X_train, y=y_train)"
      ],
      "metadata": {
        "id": "XV-z_QpM6qw0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "49d6bcf5-f635-49f6-a913-e299f47576d8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "RandomForestClassifier()"
            ],
            "text/html": [
              "<style>#sk-container-id-4 {color: black;background-color: white;}#sk-container-id-4 pre{padding: 0;}#sk-container-id-4 div.sk-toggleable {background-color: white;}#sk-container-id-4 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-4 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-4 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-4 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-4 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-4 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-4 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-4 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-4 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-4 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-4 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-4 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-4 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-4 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-4 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-4 div.sk-item {position: relative;z-index: 1;}#sk-container-id-4 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-4 div.sk-item::before, #sk-container-id-4 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-4 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-4 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-4 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-4 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-4 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-4 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-4 div.sk-label-container {text-align: center;}#sk-container-id-4 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-4 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-4\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>RandomForestClassifier()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-7\" type=\"checkbox\" checked><label for=\"sk-estimator-id-7\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">RandomForestClassifier</label><div class=\"sk-toggleable__content\"><pre>RandomForestClassifier()</pre></div></div></div></div></div>"
            ]
          },
          "metadata": {},
          "execution_count": 113
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model1.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ],
      "metadata": {
        "id": "2Pop5eQ-6qsn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bc08280b-b6dd-4fa1-ffaf-6edbaf396cb9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    874\n",
              "0    366\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 117
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model2.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ],
      "metadata": {
        "id": "bLfGSUFW6qoe",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a95bdc59-f00b-4bcf-d16b-5f9713f6f190"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    884\n",
              "0    356\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 119
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit['first_party_winner'] = Y_pred\n",
        "submit.to_csv('./submit_model2.csv', index=False)\n",
        "print('Done')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nYgyY7fSQmOh",
        "outputId": "2238f96c-dbd2-44ce-9813-393bacc427d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "Y_pred = model3.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ],
      "metadata": {
        "id": "-dzQfGbp6qjT",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09261d0d-e1b2-4e79-893c-eacaaa0422d4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1054\n",
              "0     186\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 116
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "mMlnKsDO6qeG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "kW7A6aJQ6qY0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "FwM_2k_n6qUm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "tJ56G8dF6qOJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "vLpA9AXZsqlF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Dljy4PcTLtgC"
      },
      "source": [
        "# Inference & Submission"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LB-5XGpGKwgp"
      },
      "outputs": [],
      "source": [
        "submit = pd.read_csv('./sample_submission.csv')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4pjcbEMUKwed"
      },
      "outputs": [],
      "source": [
        "X_test = np.asarray(test_fin)\n",
        "Y_pred = model.predict(X_test)\n",
        "pd.DataFrame(list(Y_pred)).value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kgvUGxT5Kwbr",
        "outputId": "d8a19649-a3a6-4fe2-aa1d-831b0ddfc6e5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Done\n"
          ]
        }
      ],
      "source": [
        "submit['first_party_winner'] = Y_pred\n",
        "submit.to_csv('./submit_catboost0701_3.csv', index=False)\n",
        "print('Done')"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "b-8JnO3w4FHu"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [
        "iRPp8KUvoaYe",
        "jlQJ7PNeyk0i",
        "yEUcy72P3ad_",
        "NCK9FTesKJrz",
        "KF3E14LWKM2N",
        "C6vVvxUT3eaw",
        "xhgZOAY10UaJ",
        "EiFJJWNL_VaW",
        "cTDtHoZUsrsz",
        "wPmczv8VKC3N",
        "Xx-CBb9FKE_D",
        "mNKIfQVKglX_",
        "Ehd609yniglg",
        "lWvq8i8wij9k",
        "ZXCPcVE7o8ci",
        "HaNFyCf8yeDY",
        "8GBBZDkAdSMp",
        "NDMI7GTLrEac",
        "CZ7zdXtQuHX9",
        "0o54bQ-7vJmi"
      ],
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}