{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "M-kwkVq10Ixj",
        "outputId": "309890ee-50d0-4d3e-9f62-61993b013423"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "cIO4PSSgzWg0"
      },
      "source": [
        "# **1. Importing libraries**"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Tk4M_IVkFnyy"
      },
      "outputs": [],
      "source": [
        "import numpy as np # linear algebra\n",
        "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.pipeline import Pipeline\n",
        "from xgboost import XGBClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "\n",
        "from sklearn.metrics import accuracy_score\n",
        "## for data\n",
        "import pandas as pd\n",
        "\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report, confusion_matrix\n",
        "from sklearn.svm import LinearSVC\n"
      ],
      "metadata": {
        "id": "0It5Y0Ma0S2w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LMi0pjS2votn",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "914dff4b-7e0f-4d54-8c5b-7c4b2119a7a6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "[nltk_data] Downloading collection 'all'\n",
            "[nltk_data]    | \n",
            "[nltk_data]    | Downloading package abc to /root/nltk_data...\n",
            "[nltk_data]    |   Package abc is already up-to-date!\n",
            "[nltk_data]    | Downloading package alpino to /root/nltk_data...\n",
            "[nltk_data]    |   Package alpino is already up-to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger is already up-\n",
            "[nltk_data]    |       to-date!\n",
            "[nltk_data]    | Downloading package averaged_perceptron_tagger_ru to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package averaged_perceptron_tagger_ru is already\n",
            "[nltk_data]    |       up-to-date!\n",
            "[nltk_data]    | Downloading package basque_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package basque_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package bcp47 to /root/nltk_data...\n",
            "[nltk_data]    |   Package bcp47 is already up-to-date!\n",
            "[nltk_data]    | Downloading package biocreative_ppi to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package biocreative_ppi is already up-to-date!\n",
            "[nltk_data]    | Downloading package bllip_wsj_no_aux to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package bllip_wsj_no_aux is already up-to-date!\n",
            "[nltk_data]    | Downloading package book_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package book_grammars is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown is already up-to-date!\n",
            "[nltk_data]    | Downloading package brown_tei to /root/nltk_data...\n",
            "[nltk_data]    |   Package brown_tei is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_cat to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_cat is already up-to-date!\n",
            "[nltk_data]    | Downloading package cess_esp to /root/nltk_data...\n",
            "[nltk_data]    |   Package cess_esp is already up-to-date!\n",
            "[nltk_data]    | Downloading package chat80 to /root/nltk_data...\n",
            "[nltk_data]    |   Package chat80 is already up-to-date!\n",
            "[nltk_data]    | Downloading package city_database to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package city_database is already up-to-date!\n",
            "[nltk_data]    | Downloading package cmudict to /root/nltk_data...\n",
            "[nltk_data]    |   Package cmudict is already up-to-date!\n",
            "[nltk_data]    | Downloading package comparative_sentences to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package comparative_sentences is already up-to-\n",
            "[nltk_data]    |       date!\n",
            "[nltk_data]    | Downloading package comtrans to /root/nltk_data...\n",
            "[nltk_data]    |   Package comtrans is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2000 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2000 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2002 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2002 is already up-to-date!\n",
            "[nltk_data]    | Downloading package conll2007 to /root/nltk_data...\n",
            "[nltk_data]    |   Package conll2007 is already up-to-date!\n",
            "[nltk_data]    | Downloading package crubadan to /root/nltk_data...\n",
            "[nltk_data]    |   Package crubadan is already up-to-date!\n",
            "[nltk_data]    | Downloading package dependency_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package dependency_treebank is already up-to-date!\n",
            "[nltk_data]    | Downloading package dolch to /root/nltk_data...\n",
            "[nltk_data]    |   Package dolch is already up-to-date!\n",
            "[nltk_data]    | Downloading package europarl_raw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package europarl_raw is already up-to-date!\n",
            "[nltk_data]    | Downloading package extended_omw to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package extended_omw is already up-to-date!\n",
            "[nltk_data]    | Downloading package floresta to /root/nltk_data...\n",
            "[nltk_data]    |   Package floresta is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v15 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v15 is already up-to-date!\n",
            "[nltk_data]    | Downloading package framenet_v17 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Package framenet_v17 is already up-to-date!\n",
            "[nltk_data]    | Downloading package gazetteers to /root/nltk_data...\n",
            "[nltk_data]    |   Package gazetteers is already up-to-date!\n",
            "[nltk_data]    | Downloading package genesis to /root/nltk_data...\n",
            "[nltk_data]    |   Package genesis is already up-to-date!\n",
            "[nltk_data]    | Downloading package gutenberg to /root/nltk_data...\n",
            "[nltk_data]    |   Package gutenberg is already up-to-date!\n",
            "[nltk_data]    | Downloading package ieer to /root/nltk_data...\n",
            "[nltk_data]    |   Package ieer is already up-to-date!\n",
            "[nltk_data]    | Downloading package inaugural to /root/nltk_data...\n",
            "[nltk_data]    |   Package inaugural is already up-to-date!\n",
            "[nltk_data]    | Downloading package indian to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/indian.zip.\n",
            "[nltk_data]    | Downloading package jeita to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package kimmo to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/kimmo.zip.\n",
            "[nltk_data]    | Downloading package knbc to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package large_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/large_grammars.zip.\n",
            "[nltk_data]    | Downloading package lin_thesaurus to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/lin_thesaurus.zip.\n",
            "[nltk_data]    | Downloading package mac_morpho to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mac_morpho.zip.\n",
            "[nltk_data]    | Downloading package machado to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package masc_tagged to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package maxent_ne_chunker to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping chunkers/maxent_ne_chunker.zip.\n",
            "[nltk_data]    | Downloading package maxent_treebank_pos_tagger to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/maxent_treebank_pos_tagger.zip.\n",
            "[nltk_data]    | Downloading package moses_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/moses_sample.zip.\n",
            "[nltk_data]    | Downloading package movie_reviews to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/movie_reviews.zip.\n",
            "[nltk_data]    | Downloading package mte_teip5 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/mte_teip5.zip.\n",
            "[nltk_data]    | Downloading package mwa_ppdb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/mwa_ppdb.zip.\n",
            "[nltk_data]    | Downloading package names to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/names.zip.\n",
            "[nltk_data]    | Downloading package nombank.1.0 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package nonbreaking_prefixes to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nonbreaking_prefixes.zip.\n",
            "[nltk_data]    | Downloading package nps_chat to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/nps_chat.zip.\n",
            "[nltk_data]    | Downloading package omw to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package omw-1.4 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package opinion_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/opinion_lexicon.zip.\n",
            "[nltk_data]    | Downloading package panlex_swadesh to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package paradigms to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/paradigms.zip.\n",
            "[nltk_data]    | Downloading package pe08 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pe08.zip.\n",
            "[nltk_data]    | Downloading package perluniprops to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping misc/perluniprops.zip.\n",
            "[nltk_data]    | Downloading package pil to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pil.zip.\n",
            "[nltk_data]    | Downloading package pl196x to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pl196x.zip.\n",
            "[nltk_data]    | Downloading package porter_test to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/porter_test.zip.\n",
            "[nltk_data]    | Downloading package ppattach to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ppattach.zip.\n",
            "[nltk_data]    | Downloading package problem_reports to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/problem_reports.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_1 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_1.zip.\n",
            "[nltk_data]    | Downloading package product_reviews_2 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/product_reviews_2.zip.\n",
            "[nltk_data]    | Downloading package propbank to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package pros_cons to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/pros_cons.zip.\n",
            "[nltk_data]    | Downloading package ptb to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ptb.zip.\n",
            "[nltk_data]    | Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping tokenizers/punkt.zip.\n",
            "[nltk_data]    | Downloading package qc to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/qc.zip.\n",
            "[nltk_data]    | Downloading package reuters to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package rslp to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping stemmers/rslp.zip.\n",
            "[nltk_data]    | Downloading package rte to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/rte.zip.\n",
            "[nltk_data]    | Downloading package sample_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/sample_grammars.zip.\n",
            "[nltk_data]    | Downloading package semcor to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package senseval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/senseval.zip.\n",
            "[nltk_data]    | Downloading package sentence_polarity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentence_polarity.zip.\n",
            "[nltk_data]    | Downloading package sentiwordnet to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sentiwordnet.zip.\n",
            "[nltk_data]    | Downloading package shakespeare to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/shakespeare.zip.\n",
            "[nltk_data]    | Downloading package sinica_treebank to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/sinica_treebank.zip.\n",
            "[nltk_data]    | Downloading package smultron to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/smultron.zip.\n",
            "[nltk_data]    | Downloading package snowball_data to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package spanish_grammars to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping grammars/spanish_grammars.zip.\n",
            "[nltk_data]    | Downloading package state_union to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/state_union.zip.\n",
            "[nltk_data]    | Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/stopwords.zip.\n",
            "[nltk_data]    | Downloading package subjectivity to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/subjectivity.zip.\n",
            "[nltk_data]    | Downloading package swadesh to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/swadesh.zip.\n",
            "[nltk_data]    | Downloading package switchboard to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/switchboard.zip.\n",
            "[nltk_data]    | Downloading package tagsets to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping help/tagsets.zip.\n",
            "[nltk_data]    | Downloading package timit to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/timit.zip.\n",
            "[nltk_data]    | Downloading package toolbox to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/toolbox.zip.\n",
            "[nltk_data]    | Downloading package treebank to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/treebank.zip.\n",
            "[nltk_data]    | Downloading package twitter_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/twitter_samples.zip.\n",
            "[nltk_data]    | Downloading package udhr to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr.zip.\n",
            "[nltk_data]    | Downloading package udhr2 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/udhr2.zip.\n",
            "[nltk_data]    | Downloading package unicode_samples to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/unicode_samples.zip.\n",
            "[nltk_data]    | Downloading package universal_tagset to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping taggers/universal_tagset.zip.\n",
            "[nltk_data]    | Downloading package universal_treebanks_v20 to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package vader_lexicon to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    | Downloading package verbnet to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet.zip.\n",
            "[nltk_data]    | Downloading package verbnet3 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/verbnet3.zip.\n",
            "[nltk_data]    | Downloading package webtext to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/webtext.zip.\n",
            "[nltk_data]    | Downloading package wmt15_eval to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/wmt15_eval.zip.\n",
            "[nltk_data]    | Downloading package word2vec_sample to\n",
            "[nltk_data]    |     /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping models/word2vec_sample.zip.\n",
            "[nltk_data]    | Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2021 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet2022 to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet2022.zip.\n",
            "[nltk_data]    | Downloading package wordnet31 to /root/nltk_data...\n",
            "[nltk_data]    | Downloading package wordnet_ic to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/wordnet_ic.zip.\n",
            "[nltk_data]    | Downloading package words to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/words.zip.\n",
            "[nltk_data]    | Downloading package ycoe to /root/nltk_data...\n",
            "[nltk_data]    |   Unzipping corpora/ycoe.zip.\n",
            "[nltk_data]    | \n",
            "[nltk_data]  Done downloading collection all\n",
            "[nltk_data] Downloading package wordnet to /root/nltk_data...\n",
            "[nltk_data]   Package wordnet is already up-to-date!\n",
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Package stopwords is already up-to-date!\n"
          ]
        }
      ],
      "source": [
        "import nltk # 문장 토크나이저\n",
        "\n",
        "# 영어 불용어 - 불용어 모아 놓은 리스트 다운로드해 제거\n",
        "nltk.download('all')\n",
        "nltk.download('wordnet')\n",
        "nltk.download('stopwords')\n",
        "from nltk.corpus import stopwords\n",
        "\n",
        "from nltk.tokenize import word_tokenize # 토큰화\n",
        "from nltk.stem.porter import PorterStemmer # 어근 동일화 <-> 이거 말고도 \"Lancaster Stemmer\"\n",
        "\n",
        "# 표제어 추출\n",
        "from nltk.stem import WordNetLemmatizer\n",
        "\n",
        "# 정규표현 처리\n",
        "import re"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EyzGg1XrLAJp"
      },
      "outputs": [],
      "source": [
        "test = pd.read_csv('/content/drive/MyDrive/DACON_JudgmentPrediction/data/testnew1')\n",
        "train = pd.read_csv('/content/drive/MyDrive/DACON_JudgmentPrediction/data/trainnew1')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df = train.copy()"
      ],
      "metadata": {
        "id": "n0yexdHcHqqg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 843
        },
        "id": "t65hcIltJUAj",
        "outputId": "d6e0abc0-c1ae-4cd9-a8e0-ff52d90ef82a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "   Unnamed: 0          ID first_party second_party  \\\n",
              "0           0  TRAIN_0000      PERSON       PERSON   \n",
              "1           1  TRAIN_0001      PERSON       PERSON   \n",
              "2           2  TRAIN_0002      PERSON          GPE   \n",
              "3           3  TRAIN_0003      others       others   \n",
              "4           4  TRAIN_0004      PERSON          GPE   \n",
              "\n",
              "                                                fact issued_area  sen_len  \\\n",
              "0  On June 27, 1962, <p1> a candidate for public ...      others        7   \n",
              "1  Ramon Nelson was riding his bike when he suffe...    criminal        7   \n",
              "2  An Alabama state court convicted <p1> of murde...    criminal        8   \n",
              "3  Victor <p1> was convicted in state court on ev...      others        3   \n",
              "4  On April 24, 1953 in Selma, <p2> an intruder b...      others        9   \n",
              "\n",
              "   word_len  winning_percent  first_party_winner  승률범주형분류  \\\n",
              "0       201              0.5                   1        1   \n",
              "1       219              0.5                   0        1   \n",
              "2       191              0.5                   1        1   \n",
              "3        59              0.5                   0        1   \n",
              "4       200              0.5                   1        1   \n",
              "\n",
              "                                     fact_processing  \n",
              "0  june <p1> candid public offic make televis spe...  \n",
              "1  ramon nelson rid bike suffer lethal blow back ...  \n",
              "2  alabama state court convict <p1> murder senten...  \n",
              "3  victor <p1> convict state court evid illeg obt...  \n",
              "4  april selma <p2> intrud break apart daughter c...  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-1402043e-ab04-4e09-a24b-a04843ccb59a\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>fact</th>\n",
              "      <th>issued_area</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "      <th>winning_percent</th>\n",
              "      <th>first_party_winner</th>\n",
              "      <th>승률범주형분류</th>\n",
              "      <th>fact_processing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TRAIN_0000</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>On June 27, 1962, &lt;p1&gt; a candidate for public ...</td>\n",
              "      <td>others</td>\n",
              "      <td>7</td>\n",
              "      <td>201</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>june &lt;p1&gt; candid public offic make televis spe...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TRAIN_0001</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>Ramon Nelson was riding his bike when he suffe...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>219</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>ramon nelson rid bike suffer lethal blow back ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TRAIN_0002</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>An Alabama state court convicted &lt;p1&gt; of murde...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>8</td>\n",
              "      <td>191</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>alabama state court convict &lt;p1&gt; murder senten...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TRAIN_0003</td>\n",
              "      <td>others</td>\n",
              "      <td>others</td>\n",
              "      <td>Victor &lt;p1&gt; was convicted in state court on ev...</td>\n",
              "      <td>others</td>\n",
              "      <td>3</td>\n",
              "      <td>59</td>\n",
              "      <td>0.5</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>victor &lt;p1&gt; convict state court evid illeg obt...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>TRAIN_0004</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>On April 24, 1953 in Selma, &lt;p2&gt; an intruder b...</td>\n",
              "      <td>others</td>\n",
              "      <td>9</td>\n",
              "      <td>200</td>\n",
              "      <td>0.5</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>april selma &lt;p2&gt; intrud break apart daughter c...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-1402043e-ab04-4e09-a24b-a04843ccb59a')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-1402043e-ab04-4e09-a24b-a04843ccb59a button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-1402043e-ab04-4e09-a24b-a04843ccb59a');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df = test.copy()"
      ],
      "metadata": {
        "id": "8kmYqC2BIsFh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "train, test split"
      ],
      "metadata": {
        "id": "AdL9xJB6npOQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# import random\n",
        "\n",
        "# from sklearn.model_selection import train_test_split\n",
        "# train_df, val_df = train_test_split(train, test_size=0.2, random_state=40)\n",
        "# train_df = train_df.reset_index(drop=True)\n",
        "# val_df = val_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "JlwHJBp7no8-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# train_df['winner']=0\n",
        "# train_df['winner_frequency']=0\n",
        "# train_df['win_percentage']=0\n",
        "\n",
        "# for i in range(len(train_df)):\n",
        "#   if train_df['first_party_winner'][i]==1:\n",
        "#     train_df['winner'][i] = train_df['first_party'][i]\n",
        "#   else:\n",
        "#     train_df['winner'][i] = train_df['second_party'][i]\n",
        "\n",
        "# train_df['first_party_win_percent'] = 0\n",
        "# train_df['first_party_frequency'] = 0\n",
        "\n",
        "# for i in range(len(train_df)):\n",
        "#   train_df['first_party_frequency'][i] = len(train_df.loc[train_df['first_party'] == train_df['first_party'][i]]) + len(train_df.loc[train_df['second_party'] == train_df['first_party'][i]])\n",
        "\n",
        "#   if (len(train_df.loc[train_df['first_party'] == train_df['first_party'][i]]) + len(train_df.loc[train_df['second_party'] == train_df['first_party'][i]])) > 1:\n",
        "#     train_df['first_party_win_percent'][i]= len(train_df.loc[train_df['winner'] == train_df['first_party'][i]]) /(len(train_df.loc[train_df['first_party'] == train_df['first_party'][i]]) + len(train_df.loc[train_df['second_party'] == train_df['first_party'][i]]))\n",
        "#   else:\n",
        "#     train_df['first_party_win_percent'][i] = 0.5\n",
        "\n",
        "# train_df=train_df.drop(['winner',\t'winner_frequency','first_party_frequency','win_percentage'],axis=1)"
      ],
      "metadata": {
        "id": "R9woTFLtnHl8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# val_df_first_party = val_df['first_party']\n",
        "# train_df_first_party = train_df[['first_party','first_party_win_percent']]\n",
        "# train_df_first_party=train_df_first_party.drop_duplicates()\n",
        "# test_first_party_병합 = pd.merge(val_df_first_party, train_df_first_party, how='left')\n",
        "# test_first_party_병합 = test_first_party_병합.fillna(0.5)\n",
        "# val_df['first_party_win_percent'] = test_first_party_병합['first_party_win_percent']"
      ],
      "metadata": {
        "id": "4qPz93zKnNYD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def categorize_probability(x):\n",
        "    if x == 0:\n",
        "        return 0\n",
        "    elif 0 < x <= 0.33:\n",
        "        return 1\n",
        "    elif 0.33 < x < 0.5:\n",
        "        return 2\n",
        "    elif x == 0.5:\n",
        "        return 3\n",
        "    elif 0.5 < x < 0.57:\n",
        "        return 2\n",
        "    elif 0.57 <= x < 0.75:\n",
        "        return 4\n",
        "    elif 0.75 <= x < 1:\n",
        "        return 5\n",
        "    elif x == 1:\n",
        "        return 6\n",
        "    else:\n",
        "        return -1"
      ],
      "metadata": {
        "id": "QlNNQM46cMqW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# def categorize_probability(x):\n",
        "#     if x < 0.2:\n",
        "#       return 'lose'\n",
        "#     elif x >= 0.8:\n",
        "#       return 'win'\n",
        "#     else:\n",
        "#       return \"미정\""
      ],
      "metadata": {
        "id": "ZzR9VMx1_oah"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['승률범주형분류'] = 0"
      ],
      "metadata": {
        "id": "0_jj4579DQSq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(train_df)):\n",
        "  train_df['승률범주형분류'][i] = categorize_probability(train_df['winning_percent'][i])"
      ],
      "metadata": {
        "id": "STdl8hWiyhPA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['승률범주형분류'] = 0\n",
        "\n",
        "for i in range(len(test_df)):\n",
        "  test_df['승률범주형분류'][i] = categorize_probability(test_df['winning_percent'][i])"
      ],
      "metadata": {
        "id": "3epms5IJIo_9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['승률범주형분류'].value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_zKAC6xFBOru",
        "outputId": "1c0d10e1-c352-44ad-b64f-a7964c15e033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "3    2023\n",
              "4     231\n",
              "6      92\n",
              "2      71\n",
              "1      26\n",
              "5      19\n",
              "0      16\n",
              "Name: 승률범주형분류, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk.corpus import names #corpus=말뭉치,이름 관련 부분 다루기 위한 객체\n"
      ],
      "metadata": {
        "id": "f21i9uhtlpkO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VLmb12rJ2Dos"
      },
      "outputs": [],
      "source": [
        "# 영어 데이터 전처리 함수\n",
        "stops = set(stopwords.words('english'))\n",
        "ps = nltk.stem.porter.PorterStemmer()\n",
        "all_names=set(names.words())\n",
        "lem = nltk.stem.wordnet.WordNetLemmatizer()\n",
        "\n",
        "def cleaning(str):\n",
        "    replaceAll = str\n",
        "\n",
        "    # 특수문자 및 기호 등 필요없는 문자 제거\n",
        "    words = replaceAll.split()\n",
        "    only_english = ''\n",
        "    for word in words:\n",
        "      if word in ['<p1>','<p2>']:\n",
        "        only_english = only_english + word + ' '\n",
        "      else:\n",
        "        only_english += re.sub(r\"[^a-zA-Z]\", ' ', word)\n",
        "        only_english += ' '  # 띄어쓰기 추가\n",
        "    only_english = only_english.strip()\n",
        "\n",
        "    # 대소문자 모두 소문자로 통일\n",
        "    no_capitals = only_english.lower().split()\n",
        "\n",
        "    # 이름, 불용어(분석에 필요없는 토큰) 제거\n",
        "    all_names=set(names.words())\n",
        "    no_stops = [word for word in no_capitals if not word in all_names|stops]\n",
        "\n",
        "    # 표제어 : 단어의 원형 형태를 나타내며, 명사의 경우 복수형이나 동사의 경우 시제 등을 고려하여 변환\n",
        "    lem_text = [lem.lemmatize(word, pos='v') for word in no_stops]\n",
        "\n",
        "    # 어근 추츨 : 단어의 형태를 보존하는 특징이 있지만 추출된 어근이 실제로는 사전에 존재하지 않은 단어일 수 있음\n",
        "    stemmer_words = [ps.stem(word) for word in lem_text]\n",
        "\n",
        "    # back to string from list\n",
        "    text = \" \".join(stemmer_words)\n",
        "\n",
        "    return text"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.feature_extraction.text import TfidfVectorizer"
      ],
      "metadata": {
        "id": "ETCxoIIalxBE"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "vectorizer = TfidfVectorizer(max_features = 400)\n",
        "\n",
        "def get_vector(vectorizer, df, train_mode):\n",
        "    if train_mode:\n",
        "        X_facts = vectorizer.fit_transform(df['fact_processing'])\n",
        "    else:\n",
        "        X_facts = vectorizer.transform(df['fact_processing'])\n",
        "\n",
        "    X = np.concatenate([X_facts.todense()], axis=1)\n",
        "    return X"
      ],
      "metadata": {
        "id": "RTyIzCVnwW-E"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 클리닝\n",
        "train_df[\"fact_processing\"] = train_df[\"fact\"].apply(cleaning)"
      ],
      "metadata": {
        "id": "MZDQo_b8l9h0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"fact_processing\"] = test_df[\"fact\"].apply(cleaning)"
      ],
      "metadata": {
        "id": "P7UBtp7IJ8A_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df.to_csv('/content/drive/MyDrive/DACON_JudgmentPrediction/data/trainnew1')"
      ],
      "metadata": {
        "id": "-4ObBcx3LGe6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df.to_csv('/content/drive/MyDrive/DACON_JudgmentPrediction/data/testnew1')"
      ],
      "metadata": {
        "id": "15F-D8j3MLdZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_df['first_party'].astype(\"category\")\n",
        "train_df['second_party'].astype(\"category\")\n",
        "train_df['issued_area'].astype(\"category\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "m8WpOT5wqEcn",
        "outputId": "a30fb5ce-e180-46ec-9320-033cddf73946"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         others\n",
              "1       criminal\n",
              "2       criminal\n",
              "3         others\n",
              "4         others\n",
              "          ...   \n",
              "2473      others\n",
              "2474      others\n",
              "2475    criminal\n",
              "2476      others\n",
              "2477      others\n",
              "Name: issued_area, Length: 2478, dtype: category\n",
              "Categories (3, object): ['civil', 'criminal', 'others']"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df['first_party'].astype(\"category\")\n",
        "test_df['second_party'].astype(\"category\")\n",
        "test_df['issued_area'].astype(\"category\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TT9l3FEqJ_g9",
        "outputId": "b2a15ca4-6021-49f0-ae9e-c3d9bcbb15ca"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0         others\n",
              "1       criminal\n",
              "2       criminal\n",
              "3         others\n",
              "4         others\n",
              "          ...   \n",
              "1235    criminal\n",
              "1236    criminal\n",
              "1237      others\n",
              "1238      others\n",
              "1239      others\n",
              "Name: issued_area, Length: 1240, dtype: category\n",
              "Categories (3, object): ['civil', 'criminal', 'others']"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # 특정 범주형 변수(categorical variable)을 더미변수 생성\n",
        "# train_cat = pd.get_dummies(data = train_df[[\"first_party\",\"second_party\",\"issued_area\"]])\n",
        "# test_cat = pd.get_dummies(data = test_df[[\"first_party\",\"second_party\",\"issued_area\"]])\n",
        "# 특정 범주형 변수(categorical variable)을 더미변수 생성\n",
        "train_cat = pd.get_dummies(data = train_df[[\"first_party\",\"second_party\",\"issued_area\"]])\n",
        "test_cat = pd.get_dummies(data = test_df[[\"first_party\",\"second_party\",\"issued_area\"]])"
      ],
      "metadata": {
        "id": "ILMmEoTTk2IT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 데이터 벡터화\n",
        "train_fact = get_vector(vectorizer, train_df, True)\n",
        "train_fact = np.asarray(train_fact)\n",
        "train_fact = pd.DataFrame(data=train_fact)\n",
        "\n",
        "test_fact = get_vector(vectorizer, test_df, False)\n",
        "test_fact = np.asarray(test_fact)\n",
        "test_fact = pd.DataFrame(data=test_fact)"
      ],
      "metadata": {
        "id": "VHEHQFZNoml1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_num = train_df['승률범주형분류']\n",
        "train_target = train_df[['first_party_winner']]\n",
        "\n",
        "test_num = test_df['승률범주형분류']"
      ],
      "metadata": {
        "id": "O_DwXhebpTo-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_fin = pd.concat([train_fact,train_cat,train_num,train_target],axis=1,join='inner')\n",
        "test_fin = pd.concat([test_fact, test_cat, test_num],axis=1,join='inner')"
      ],
      "metadata": {
        "id": "9T9UjzlUxHaA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_fin.drop(columns=['first_party_winner'])\n",
        "y_train = train_fin['first_party_winner']\n",
        "\n",
        "X_test = test_fin"
      ],
      "metadata": {
        "id": "xXLJw-MCrGGZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns = X_train.columns.astype(str)\n",
        "X_test.columns = X_test.columns.astype(str)"
      ],
      "metadata": {
        "id": "p-9PJq3-sLBj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "지금부터 교차검증 수행"
      ],
      "metadata": {
        "id": "7npySwP4NAjZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n"
      ],
      "metadata": {
        "id": "ko_UWbYoNGPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "logreg = LogisticRegression()\n",
        "scores = cross_val_score(logreg, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "print('Cross-Validation Scores:', scores)\n",
        "print('Average Score:', scores.mean())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SRDuzwJjMym9",
        "outputId": "eeabea20-547f-4bbf-df03-fb63c83b01a3"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.67540323 0.68346774 0.66330645 0.65454545 0.65858586]\n",
            "Average Score: 0.6670617464972304\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "odQ0unAmdU9x"
      },
      "source": [
        "랜덤포레스트"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "metadata": {
        "id": "mxL7KYNCGJtp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3n3CjE8Ic_AP",
        "outputId": "67d97136-65d5-406f-eaea-3138788a5cd1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.66532258 0.65524194 0.67741935 0.65858586 0.66666667]\n",
            "Average Score: 0.6646472792440534\n"
          ]
        }
      ],
      "source": [
        "rdf = RandomForestClassifier()\n",
        "scores = cross_val_score(rdf, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "print('Cross-Validation Scores:', scores)\n",
        "print('Average Score:', scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RDm6uniJdqP4"
      },
      "source": [
        "KNeighborsClassifier(n_neighbors=3)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Jzv8pwopeMrk",
        "outputId": "1383ef06-7e06-4b27-f23f-e68c7026ff67"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.64112903 0.56653226 0.62701613 0.60606061 0.61010101]\n",
            "Average Score: 0.6101678071032909\n"
          ]
        }
      ],
      "source": [
        "knn = knn=KNeighborsClassifier(n_neighbors=3)\n",
        "scores = cross_val_score(knn, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "print('Cross-Validation Scores:', scores)\n",
        "print('Average Score:', scores.mean())"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "CATBOOST"
      ],
      "metadata": {
        "id": "OCWRQ1EI2M3X"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vLYcpqlce0Bm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "60743cb4-1246-4019-dd5a-714bcee17d17"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: catboost in /usr/local/lib/python3.10/dist-packages (1.2)\n",
            "Requirement already satisfied: graphviz in /usr/local/lib/python3.10/dist-packages (from catboost) (0.20.1)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from catboost) (3.7.1)\n",
            "Requirement already satisfied: numpy>=1.16.0 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.22.4)\n",
            "Requirement already satisfied: pandas>=0.24 in /usr/local/lib/python3.10/dist-packages (from catboost) (1.5.3)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from catboost) (1.10.1)\n",
            "Requirement already satisfied: plotly in /usr/local/lib/python3.10/dist-packages (from catboost) (5.13.1)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from catboost) (1.16.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas>=0.24->catboost) (2022.7.1)\n",
            "Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.1.0)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (0.11.0)\n",
            "Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (4.40.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (1.4.4)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (23.1)\n",
            "Requirement already satisfied: pillow>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (8.4.0)\n",
            "Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->catboost) (3.1.0)\n",
            "Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly->catboost) (8.2.2)\n"
          ]
        }
      ],
      "source": [
        "!pip install catboost"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from catboost import CatBoostClassifier, Pool"
      ],
      "metadata": {
        "id": "HsvWJs7Y2a3A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "counts = list(y_train.value_counts())\n",
        "class_weight = [counts[1]/sum(counts), counts[0]/sum(counts)]\n",
        "print(\"weight :\", class_weight)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4nrdMPVb2ibQ",
        "outputId": "9db19c75-44ea-49ad-b87c-f4ff6dcbaa3f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "weight : [0.33454398708635996, 0.66545601291364]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cbc = CatBoostClassifier(random_seed=42,class_weights=class_weight, verbose=0)\n",
        "scores = cross_val_score(cbc, X_train, y_train, cv=5, scoring='accuracy')\n",
        "\n",
        "print('Cross-Validation Scores:', scores)\n",
        "print('Average Score:', scores.mean())"
      ],
      "metadata": {
        "id": "z8jjsVzj2THZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "새로운 모델 등장"
      ],
      "metadata": {
        "id": "Dt6CpmzSUx8k"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install --upgrade tensorflow\n"
      ],
      "metadata": {
        "id": "FQQ0hKpfUz-S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorflow-text"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IeF1dxq7VPKw",
        "outputId": "da92083d-107d-4c39-9cf5-12e9b453e161"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorflow-text\n",
            "  Downloading tensorflow_text-2.12.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (6.0 MB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/6.0 MB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/6.0 MB\u001b[0m \u001b[31m174.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.1/6.0 MB\u001b[0m \u001b[31m174.5 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[91m╸\u001b[0m\u001b[90m━━━━━━━━━━━━\u001b[0m \u001b[32m4.2/6.0 MB\u001b[0m \u001b[31m40.8 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m6.0/6.0 MB\u001b[0m \u001b[31m43.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tensorflow-hub>=0.8.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (0.13.0)\n",
            "Requirement already satisfied: tensorflow<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow-text) (2.12.0)\n",
            "Requirement already satisfied: absl-py>=1.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.4.0)\n",
            "Requirement already satisfied: astunparse>=1.6.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.6.3)\n",
            "Requirement already satisfied: flatbuffers>=2.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (23.5.26)\n",
            "Requirement already satisfied: gast<=0.4.0,>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.4.0)\n",
            "Requirement already satisfied: google-pasta>=0.1.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: grpcio<2.0,>=1.24.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.56.0)\n",
            "Requirement already satisfied: h5py>=2.9.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (3.8.0)\n",
            "Requirement already satisfied: jax>=0.3.15 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.4.10)\n",
            "Requirement already satisfied: keras<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.12.0)\n",
            "Requirement already satisfied: libclang>=13.0.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (16.0.0)\n",
            "Requirement already satisfied: numpy<1.24,>=1.22 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.22.4)\n",
            "Requirement already satisfied: opt-einsum>=2.3.2 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (3.3.0)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (23.1)\n",
            "Requirement already satisfied: protobuf!=4.21.0,!=4.21.1,!=4.21.2,!=4.21.3,!=4.21.4,!=4.21.5,<5.0.0dev,>=3.20.3 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (3.20.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (67.7.2)\n",
            "Requirement already satisfied: six>=1.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.16.0)\n",
            "Requirement already satisfied: tensorboard<2.13,>=2.12 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.12.3)\n",
            "Requirement already satisfied: tensorflow-estimator<2.13,>=2.12.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.12.0)\n",
            "Requirement already satisfied: termcolor>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (2.3.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.6 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (4.6.3)\n",
            "Requirement already satisfied: wrapt<1.15,>=1.11.0 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (1.14.1)\n",
            "Requirement already satisfied: tensorflow-io-gcs-filesystem>=0.23.1 in /usr/local/lib/python3.10/dist-packages (from tensorflow<2.13,>=2.12.0->tensorflow-text) (0.32.0)\n",
            "Requirement already satisfied: wheel<1.0,>=0.23.0 in /usr/local/lib/python3.10/dist-packages (from astunparse>=1.6.0->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.40.0)\n",
            "Requirement already satisfied: ml-dtypes>=0.1.0 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.2.0)\n",
            "Requirement already satisfied: scipy>=1.7 in /usr/local/lib/python3.10/dist-packages (from jax>=0.3.15->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.10.1)\n",
            "Requirement already satisfied: google-auth<3,>=1.6.3 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.17.3)\n",
            "Requirement already satisfied: google-auth-oauthlib<1.1,>=0.5 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.0.0)\n",
            "Requirement already satisfied: markdown>=2.6.8 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (3.4.3)\n",
            "Requirement already satisfied: requests<3,>=2.21.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.27.1)\n",
            "Requirement already satisfied: tensorboard-data-server<0.8.0,>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.7.1)\n",
            "Requirement already satisfied: werkzeug>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.3.6)\n",
            "Requirement already satisfied: cachetools<6.0,>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (5.3.1)\n",
            "Requirement already satisfied: pyasn1-modules>=0.2.1 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.3.0)\n",
            "Requirement already satisfied: rsa<5,>=3.1.4 in /usr/local/lib/python3.10/dist-packages (from google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (4.9)\n",
            "Requirement already satisfied: requests-oauthlib>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.3.1)\n",
            "Requirement already satisfied: urllib3<1.27,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (1.26.16)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2023.5.7)\n",
            "Requirement already satisfied: charset-normalizer~=2.0.0 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.0.12)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.21.0->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (3.4)\n",
            "Requirement already satisfied: MarkupSafe>=2.1.1 in /usr/local/lib/python3.10/dist-packages (from werkzeug>=1.0.1->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (2.1.3)\n",
            "Requirement already satisfied: pyasn1<0.6.0,>=0.4.6 in /usr/local/lib/python3.10/dist-packages (from pyasn1-modules>=0.2.1->google-auth<3,>=1.6.3->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (0.5.0)\n",
            "Requirement already satisfied: oauthlib>=3.0.0 in /usr/local/lib/python3.10/dist-packages (from requests-oauthlib>=0.7.0->google-auth-oauthlib<1.1,>=0.5->tensorboard<2.13,>=2.12->tensorflow<2.13,>=2.12.0->tensorflow-text) (3.2.2)\n",
            "Installing collected packages: tensorflow-text\n",
            "Successfully installed tensorflow-text-2.12.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow_text as text"
      ],
      "metadata": {
        "id": "rbV3hV-2Uebt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "import tensorflow as tf\n"
      ],
      "metadata": {
        "id": "NcIS0zXqXQAn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bert_preprocess = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_preprocess/3\")\n",
        "bert_encoder = hub.KerasLayer(\"https://tfhub.dev/tensorflow/bert_en_uncased_L-12_H-768_A-12/4\")"
      ],
      "metadata": {
        "id": "hhpbCUGjO_J7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.utils import resample\n"
      ],
      "metadata": {
        "id": "LQtfWoAnA1J8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "subset_0 = train_df[train_df[\"first_party_winner\"] == 0]\n",
        "subset_1 = train_df[train_df[\"first_party_winner\"] == 1]\n",
        "\n",
        "subset_1_downsampled = resample(subset_1,\n",
        "                                replace=False,\n",
        "                                n_samples=800,\n",
        "                                random_state=42)\n",
        "\n",
        "train_df = pd.concat([subset_0, subset_1_downsampled])"
      ],
      "metadata": {
        "id": "At0ES54LjvPW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#X_train, X_val, y_train, y_val = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "xg6upWuriZ3G"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_input = tf.keras.layers.Input(shape=(), dtype=tf.string, name=\"text\")\n",
        "numeric_input = tf.keras.layers.Input(shape=(1,), dtype=tf.float32, name=\"numeric_input\")\n",
        "categorical_input = tf.keras.layers.Input(shape=(9,), dtype=tf.int32, name=\"categorical_input\")\n",
        "\n",
        "preprocessed_text = bert_preprocess(text_input)\n",
        "outputs = bert_encoder(preprocessed_text)\n",
        "\n",
        "processed_numeric = tf.keras.layers.Dense(32, activation=\"relu\")(numeric_input)\n",
        "processed_categorical = tf.keras.layers.Embedding(9, 32)(categorical_input)\n",
        "processed_categorical = tf.keras.layers.Flatten()(processed_categorical)\n",
        "\n",
        "combined_outputs = tf.keras.layers.Concatenate()([outputs[\"pooled_output\"], processed_numeric, processed_categorical])\n",
        "\n",
        "l = tf.keras.layers.Dropout(0.1, name=\"dropout\")(combined_outputs)\n",
        "l = tf.keras.layers.Dense(1, activation=\"sigmoid\", name=\"output\")(l)\n",
        "\n",
        "model = tf.keras.Model(inputs=[text_input, numeric_input, categorical_input], outputs=[l])\n",
        "model.summary()\n",
        "\n",
        "METRICS = [\n",
        "    tf.keras.metrics.BinaryAccuracy(name=\"accuracy\")\n",
        "]\n",
        "\n",
        "model.compile(\n",
        "    optimizer=\"adam\",\n",
        "    loss=\"binary_crossentropy\",\n",
        "    metrics=METRICS\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "87Lmt3UcjaWm",
        "outputId": "5ef9ba9d-2614-49c1-b5a8-db9e12d637f2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " text (InputLayer)              [(None,)]            0           []                               \n",
            "                                                                                                  \n",
            " categorical_input (InputLayer)  [(None, 9)]         0           []                               \n",
            "                                                                                                  \n",
            " keras_layer (KerasLayer)       {'input_word_ids':   0           ['text[0][0]']                   \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_type_ids':                                                \n",
            "                                (None, 128),                                                      \n",
            "                                 'input_mask': (Non                                               \n",
            "                                e, 128)}                                                          \n",
            "                                                                                                  \n",
            " numeric_input (InputLayer)     [(None, 1)]          0           []                               \n",
            "                                                                                                  \n",
            " embedding (Embedding)          (None, 9, 32)        288         ['categorical_input[0][0]']      \n",
            "                                                                                                  \n",
            " keras_layer_1 (KerasLayer)     {'sequence_output':  109482241   ['keras_layer[0][0]',            \n",
            "                                 (None, 128, 768),                'keras_layer[0][1]',            \n",
            "                                 'pooled_output': (               'keras_layer[0][2]']            \n",
            "                                None, 768),                                                       \n",
            "                                 'encoder_outputs':                                               \n",
            "                                 [(None, 128, 768),                                               \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768),                                                \n",
            "                                 (None, 128, 768)],                                               \n",
            "                                 'default': (None,                                                \n",
            "                                768)}                                                             \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 32)           64          ['numeric_input[0][0]']          \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 288)          0           ['embedding[0][0]']              \n",
            "                                                                                                  \n",
            " concatenate (Concatenate)      (None, 1088)         0           ['keras_layer_1[0][13]',         \n",
            "                                                                  'dense[0][0]',                  \n",
            "                                                                  'flatten[0][0]']                \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 1088)         0           ['concatenate[0][0]']            \n",
            "                                                                                                  \n",
            " output (Dense)                 (None, 1)            1089        ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 109,483,682\n",
            "Trainable params: 1,441\n",
            "Non-trainable params: 109,482,241\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-_M_NIq2rI4J",
        "outputId": "db432698-1c72-4ef6-ed18-0b734b559122"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index([                     0,                      1,                      2,\n",
              "                            3,                      4,                      5,\n",
              "                            6,                      7,                      8,\n",
              "                            9,\n",
              "       ...\n",
              "         'first_party_PERSON',   'first_party_others',     'second_party_GPE',\n",
              "           'second_party_ORG',  'second_party_PERSON',  'second_party_others',\n",
              "          'issued_area_civil', 'issued_area_criminal',   'issued_area_others',\n",
              "                    '승률범주형분류'],\n",
              "      dtype='object', length=412)"
            ]
          },
          "metadata": {},
          "execution_count": 101
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_train"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VvRcs96VrPmF",
        "outputId": "44a1e299-e37d-42fa-e469-b365f682b983"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1       0\n",
              "3       0\n",
              "4       1\n",
              "5       1\n",
              "7       1\n",
              "       ..\n",
              "1617    0\n",
              "1620    0\n",
              "1621    0\n",
              "1624    1\n",
              "1627    1\n",
              "Name: first_party_winner, Length: 1068, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 102
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train['first_party_winner'] = train_df['first_party_winner']\n"
      ],
      "metadata": {
        "id": "0XyVfQ9otlw2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yG14EL4yBpmS",
        "outputId": "84a78bb2-775e-4fc3-a0dd-6bcd68865f9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1068, 413)"
            ]
          },
          "metadata": {},
          "execution_count": 106
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_df[\"fact_processing\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iyNcKcOCBrw6",
        "outputId": "b451b5b8-cfe2-48a6-9983-6399596862e1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1       ramon nelson rid bike suffer lethal blow back ...\n",
              "3       victor <p1> convict state court evid illeg obt...\n",
              "14      name plaintiff <p1> thole other bring class ac...\n",
              "16      revis texa educ law allow state withhold local...\n",
              "21      maher kara join citigroup healthcar invest ban...\n",
              "                              ...                        \n",
              "951     plaintiff case compris <p1> labor organ sue <p...\n",
              "1360    <p2> shoot kill wayn drummond two wit shoot re...\n",
              "1070    mari e <p2> other appli patent upon method inc...\n",
              "1035    follow censu democrat control <p1> legislatur ...\n",
              "1513    <p1> tanner <p1> indict charg conspiraci defra...\n",
              "Name: fact_processing, Length: 1629, dtype: object"
            ]
          },
          "metadata": {},
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train[\"승률범주형분류\"]"
      ],
      "metadata": {
        "id": "geFCplRnB1AZ",
        "outputId": "a2a06c79-0d91-458a-d084-4d1efdf5dda8",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1       3\n",
              "3       3\n",
              "4       3\n",
              "5       3\n",
              "7       3\n",
              "       ..\n",
              "1617    3\n",
              "1620    3\n",
              "1621    3\n",
              "1624    4\n",
              "1627    3\n",
              "Name: 승률범주형분류, Length: 1068, dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 108
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train_text, X_val_text, X_train_numeric, X_val_numeric, X_train_categorical, X_val_categorical, y_train, y_val = train_test_split(\n",
        "    train_df[\"fact_processing\"], X_train[\"승률범주형분류\"], X_train[['first_party_PERSON', 'first_party_others', 'second_party_GPE',\n",
        "       'second_party_ORG', 'second_party_PERSON', 'second_party_others','issued_area_civil', 'issued_area_criminal', 'issued_area_others']], X_train[\"first_party_winner\"],\n",
        "    test_size=0.25, random_state=42\n",
        ")"
      ],
      "metadata": {
        "id": "26x7a2H7lB1g"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.callbacks import EarlyStopping\n",
        "from keras.callbacks import ModelCheckpoint\n"
      ],
      "metadata": {
        "id": "wnmakKU-yoNy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "es = EarlyStopping(monitor='val_loss', mode='min', verbose=1, patience=4)\n"
      ],
      "metadata": {
        "id": "sGJWeKasykYb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "mc = ModelCheckpoint('best_model.h5', monitor='val_accuracy', mode='max', verbose=1, save_best_only=True)"
      ],
      "metadata": {
        "id": "S23Yr94LzD35"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    [X_train_text, X_train_numeric, X_train_categorical], y_train, batch_size=32,\n",
        "    validation_data=([X_val_text, X_val_numeric, X_val_categorical], y_val),callbacks=[es, mc],\n",
        "    epochs=30\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VdFHfv71iZw3",
        "outputId": "ff07cbab-6e40-46ce-b6d1-d263dfaf792e"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6188 - accuracy: 0.6686\n",
            "Epoch 1: val_accuracy did not improve from 0.68548\n",
            "59/59 [==============================] - 30s 512ms/step - loss: 0.6190 - accuracy: 0.6685 - val_loss: 0.6141 - val_accuracy: 0.6823\n",
            "Epoch 2/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6156 - accuracy: 0.6789\n",
            "Epoch 2: val_accuracy improved from 0.68548 to 0.68710, saving model to best_model.h5\n",
            "59/59 [==============================] - 35s 604ms/step - loss: 0.6158 - accuracy: 0.6787 - val_loss: 0.6107 - val_accuracy: 0.6871\n",
            "Epoch 3/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6196 - accuracy: 0.6670\n",
            "Epoch 3: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 28s 470ms/step - loss: 0.6200 - accuracy: 0.6668 - val_loss: 0.6182 - val_accuracy: 0.6823\n",
            "Epoch 4/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6190 - accuracy: 0.6665\n",
            "Epoch 4: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 31s 527ms/step - loss: 0.6189 - accuracy: 0.6668 - val_loss: 0.6132 - val_accuracy: 0.6855\n",
            "Epoch 5/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6158 - accuracy: 0.6633\n",
            "Epoch 5: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 31s 519ms/step - loss: 0.6161 - accuracy: 0.6631 - val_loss: 0.6213 - val_accuracy: 0.6806\n",
            "Epoch 6/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6105 - accuracy: 0.6659\n",
            "Epoch 6: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 31s 534ms/step - loss: 0.6105 - accuracy: 0.6658 - val_loss: 0.6082 - val_accuracy: 0.6871\n",
            "Epoch 7/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6159 - accuracy: 0.6616\n",
            "Epoch 7: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 31s 530ms/step - loss: 0.6159 - accuracy: 0.6615 - val_loss: 0.6110 - val_accuracy: 0.6871\n",
            "Epoch 8/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6122 - accuracy: 0.6697\n",
            "Epoch 8: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 31s 524ms/step - loss: 0.6119 - accuracy: 0.6701 - val_loss: 0.6092 - val_accuracy: 0.6871\n",
            "Epoch 9/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6152 - accuracy: 0.6686\n",
            "Epoch 9: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 31s 527ms/step - loss: 0.6156 - accuracy: 0.6679 - val_loss: 0.6500 - val_accuracy: 0.5935\n",
            "Epoch 10/30\n",
            "58/59 [============================>.] - ETA: 0s - loss: 0.6163 - accuracy: 0.6649\n",
            "Epoch 10: val_accuracy did not improve from 0.68710\n",
            "59/59 [==============================] - 28s 468ms/step - loss: 0.6162 - accuracy: 0.6652 - val_loss: 0.6107 - val_accuracy: 0.6855\n",
            "Epoch 10: early stopping\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "rEoq1rlo1XDL",
        "outputId": "83cd8b23-360a-4932-bc6f-478e94960036"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0         ID first_party second_party  \\\n",
              "0              0  TEST_0000      others          GPE   \n",
              "1              1  TEST_0001      PERSON          ORG   \n",
              "2              2  TEST_0002         ORG          ORG   \n",
              "3              3  TEST_0003      PERSON          GPE   \n",
              "4              4  TEST_0004      PERSON       others   \n",
              "...          ...        ...         ...          ...   \n",
              "1235        1235  TEST_1235         ORG          ORG   \n",
              "1236        1236  TEST_1236      others          ORG   \n",
              "1237        1237  TEST_1237      PERSON       PERSON   \n",
              "1238        1238  TEST_1238         ORG       PERSON   \n",
              "1239        1239  TEST_1239      PERSON          GPE   \n",
              "\n",
              "                                                   fact issued_area  sen_len  \\\n",
              "0     The 1984 Bail Reform Act allowed the federal c...      others        2   \n",
              "1     Lexecon <p2> was a defendant in a class action...    criminal        7   \n",
              "2     In 2002 and 2003, <p2> Stations broadcast the ...    criminal        7   \n",
              "3     During his trial for armed robbery of a federa...      others        6   \n",
              "4     In 1993, a magistrate judge issued a warrant a...      others        6   \n",
              "...                                                 ...         ...      ...   \n",
              "1235  According to Executive Order No. 12807 signed ...    criminal        5   \n",
              "1236  Section 109(a) of the Clean Air Act (CAA) requ...    criminal        7   \n",
              "1237  <p1> created a plan for utilizing $2.6 million...      others       12   \n",
              "1238  In 1972, the North Carolina Board of Agricultu...      others        3   \n",
              "1239  On August 23, 1961, Dr. Paul Berheldt was stab...      others       12   \n",
              "\n",
              "      word_len  winning_percent  승률범주형분류  \\\n",
              "0           55              0.5        3   \n",
              "1          209              0.5        3   \n",
              "2          181              0.5        3   \n",
              "3           99              0.5        3   \n",
              "4          154              0.5        3   \n",
              "...        ...              ...      ...   \n",
              "1235       156              0.5        3   \n",
              "1236       221              0.5        3   \n",
              "1237       236              0.5        3   \n",
              "1238        84              0.5        3   \n",
              "1239       240              0.5        3   \n",
              "\n",
              "                                        fact_processing  \n",
              "0     bail reform act allow feder court detain arres...  \n",
              "1     lexecon <p2> defend class action lawsuit usc s...  \n",
              "2     <p2> station broadcast billboard music award a...  \n",
              "3     trial arm robberi feder insur save loan associ...  \n",
              "4     magistr judg issu warrant author search paul e...  \n",
              "...                                                 ...  \n",
              "1235  accord execut order sign presid georg h w bush...  \n",
              "1236  section clean air act caa requir environment p...  \n",
              "1237  <p1> creat plan util million fund offic hous e...  \n",
              "1238  north carolina board agricultur adopt regul re...  \n",
              "1239  august dr paul berheldt stab death kitchen hom...  \n",
              "\n",
              "[1240 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-c334f720-6770-46cc-a534-72d529f60fd9\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>fact</th>\n",
              "      <th>issued_area</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "      <th>winning_percent</th>\n",
              "      <th>승률범주형분류</th>\n",
              "      <th>fact_processing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>others</td>\n",
              "      <td>GPE</td>\n",
              "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>bail reform act allow feder court detain arres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>ORG</td>\n",
              "      <td>Lexecon &lt;p2&gt; was a defendant in a class action...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>209</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>lexecon &lt;p2&gt; defend class action lawsuit usc s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>In 2002 and 2003, &lt;p2&gt; Stations broadcast the ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>181</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;p2&gt; station broadcast billboard music award a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>During his trial for armed robbery of a federa...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>99</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>trial arm robberi feder insur save loan associ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>others</td>\n",
              "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>154</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>magistr judg issu warrant author search paul e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>1235</td>\n",
              "      <td>TEST_1235</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>According to Executive Order No. 12807 signed ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>5</td>\n",
              "      <td>156</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>accord execut order sign presid georg h w bush...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>1236</td>\n",
              "      <td>TEST_1236</td>\n",
              "      <td>others</td>\n",
              "      <td>ORG</td>\n",
              "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>221</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>section clean air act caa requir environment p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>1237</td>\n",
              "      <td>TEST_1237</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>&lt;p1&gt; created a plan for utilizing $2.6 million...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>236</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;p1&gt; creat plan util million fund offic hous e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>1238</td>\n",
              "      <td>TEST_1238</td>\n",
              "      <td>ORG</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
              "      <td>others</td>\n",
              "      <td>3</td>\n",
              "      <td>84</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>north carolina board agricultur adopt regul re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>1239</td>\n",
              "      <td>TEST_1239</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>240</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>august dr paul berheldt stab death kitchen hom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-c334f720-6770-46cc-a534-72d529f60fd9')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-c334f720-6770-46cc-a534-72d529f60fd9 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-c334f720-6770-46cc-a534-72d529f60fd9');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_df[\"fact_processing\"], X_train[\"승률범주형분류\"], X_train[['first_party_PERSON', 'first_party_others', 'second_party_GPE',\n",
        "       'second_party_ORG', 'second_party_PERSON', 'second_party_others','issued_area_civil', 'issued_area_criminal', 'issued_area_others']]"
      ],
      "metadata": {
        "id": "7upaNLZZ2vuh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_text = test_df[\"fact_processing\"]\n",
        "X_test_numeric = X_train[\"승률범주형분류\"]\n",
        "X_test_categorical = X_train[['first_party_PERSON', 'first_party_others', 'second_party_GPE',\n",
        "       'second_party_ORG', 'second_party_PERSON', 'second_party_others','issued_area_civil', 'issued_area_criminal', 'issued_area_others']]"
      ],
      "metadata": {
        "id": "YdWtuq_U2333"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_categorical"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 488
        },
        "id": "NCYsQ2s550IA",
        "outputId": "036a1846-47cc-4164-f305-1b9fd57a23ae"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      first_party_PERSON  first_party_others  second_party_GPE  \\\n",
              "0                      1                   0                 0   \n",
              "1                      1                   0                 0   \n",
              "2                      1                   0                 1   \n",
              "3                      0                   1                 0   \n",
              "4                      1                   0                 1   \n",
              "...                  ...                 ...               ...   \n",
              "2473                   0                   0                 0   \n",
              "2474                   1                   0                 0   \n",
              "2475                   0                   0                 1   \n",
              "2476                   0                   0                 0   \n",
              "2477                   0                   1                 0   \n",
              "\n",
              "      second_party_ORG  second_party_PERSON  second_party_others  \\\n",
              "0                    0                    1                    0   \n",
              "1                    0                    1                    0   \n",
              "2                    0                    0                    0   \n",
              "3                    0                    0                    1   \n",
              "4                    0                    0                    0   \n",
              "...                ...                  ...                  ...   \n",
              "2473                 1                    0                    0   \n",
              "2474                 1                    0                    0   \n",
              "2475                 0                    0                    0   \n",
              "2476                 0                    0                    1   \n",
              "2477                 1                    0                    0   \n",
              "\n",
              "      issued_area_civil  issued_area_criminal  issued_area_others  \n",
              "0                     0                     0                   1  \n",
              "1                     0                     1                   0  \n",
              "2                     0                     1                   0  \n",
              "3                     0                     0                   1  \n",
              "4                     0                     0                   1  \n",
              "...                 ...                   ...                 ...  \n",
              "2473                  0                     0                   1  \n",
              "2474                  0                     0                   1  \n",
              "2475                  0                     1                   0  \n",
              "2476                  0                     0                   1  \n",
              "2477                  0                     0                   1  \n",
              "\n",
              "[2478 rows x 9 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-8907cefe-dd80-464c-bc2a-736147a9fa2e\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>first_party_PERSON</th>\n",
              "      <th>first_party_others</th>\n",
              "      <th>second_party_GPE</th>\n",
              "      <th>second_party_ORG</th>\n",
              "      <th>second_party_PERSON</th>\n",
              "      <th>second_party_others</th>\n",
              "      <th>issued_area_civil</th>\n",
              "      <th>issued_area_criminal</th>\n",
              "      <th>issued_area_others</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2473</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2474</th>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2475</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2476</th>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2477</th>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2478 rows × 9 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-8907cefe-dd80-464c-bc2a-736147a9fa2e')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-8907cefe-dd80-464c-bc2a-736147a9fa2e button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-8907cefe-dd80-464c-bc2a-736147a9fa2e');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 61
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "U7wma4WT51cX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_hub as hub\n",
        "\n",
        "# 모델 로드 시 'custom_objects'에 TensorFlow Hub의 'KerasLayer' 전달\n",
        "best_model = load_model('best_model.h5', custom_objects={'KerasLayer': hub.KerasLayer})\n",
        "\n",
        "# 이후 작업을 위해 모델 사용\n"
      ],
      "metadata": {
        "id": "3l437Z5q0Bhm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_text = test_df[\"fact_processing\"]\n",
        "X_test_numeric = X_test[\"승률범주형분류\"]\n",
        "X_test_categorical = X_test[['first_party_PERSON', 'first_party_others', 'second_party_GPE',\n",
        "       'second_party_ORG', 'second_party_PERSON', 'second_party_others','issued_area_civil', 'issued_area_criminal', 'issued_area_others']]"
      ],
      "metadata": {
        "id": "DHMly9xG7E5M"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "h8fkaun86lbs",
        "outputId": "c73fae96-9e2e-4137-dff5-9ae6643f87e6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "      Unnamed: 0         ID first_party second_party  \\\n",
              "0              0  TEST_0000      others          GPE   \n",
              "1              1  TEST_0001      PERSON          ORG   \n",
              "2              2  TEST_0002         ORG          ORG   \n",
              "3              3  TEST_0003      PERSON          GPE   \n",
              "4              4  TEST_0004      PERSON       others   \n",
              "...          ...        ...         ...          ...   \n",
              "1235        1235  TEST_1235         ORG          ORG   \n",
              "1236        1236  TEST_1236      others          ORG   \n",
              "1237        1237  TEST_1237      PERSON       PERSON   \n",
              "1238        1238  TEST_1238         ORG       PERSON   \n",
              "1239        1239  TEST_1239      PERSON          GPE   \n",
              "\n",
              "                                                   fact issued_area  sen_len  \\\n",
              "0     The 1984 Bail Reform Act allowed the federal c...      others        2   \n",
              "1     Lexecon <p2> was a defendant in a class action...    criminal        7   \n",
              "2     In 2002 and 2003, <p2> Stations broadcast the ...    criminal        7   \n",
              "3     During his trial for armed robbery of a federa...      others        6   \n",
              "4     In 1993, a magistrate judge issued a warrant a...      others        6   \n",
              "...                                                 ...         ...      ...   \n",
              "1235  According to Executive Order No. 12807 signed ...    criminal        5   \n",
              "1236  Section 109(a) of the Clean Air Act (CAA) requ...    criminal        7   \n",
              "1237  <p1> created a plan for utilizing $2.6 million...      others       12   \n",
              "1238  In 1972, the North Carolina Board of Agricultu...      others        3   \n",
              "1239  On August 23, 1961, Dr. Paul Berheldt was stab...      others       12   \n",
              "\n",
              "      word_len  winning_percent  승률범주형분류  \\\n",
              "0           55              0.5        3   \n",
              "1          209              0.5        3   \n",
              "2          181              0.5        3   \n",
              "3           99              0.5        3   \n",
              "4          154              0.5        3   \n",
              "...        ...              ...      ...   \n",
              "1235       156              0.5        3   \n",
              "1236       221              0.5        3   \n",
              "1237       236              0.5        3   \n",
              "1238        84              0.5        3   \n",
              "1239       240              0.5        3   \n",
              "\n",
              "                                        fact_processing  \n",
              "0     bail reform act allow feder court detain arres...  \n",
              "1     lexecon <p2> defend class action lawsuit usc s...  \n",
              "2     <p2> station broadcast billboard music award a...  \n",
              "3     trial arm robberi feder insur save loan associ...  \n",
              "4     magistr judg issu warrant author search paul e...  \n",
              "...                                                 ...  \n",
              "1235  accord execut order sign presid georg h w bush...  \n",
              "1236  section clean air act caa requir environment p...  \n",
              "1237  <p1> creat plan util million fund offic hous e...  \n",
              "1238  north carolina board agricultur adopt regul re...  \n",
              "1239  august dr paul berheldt stab death kitchen hom...  \n",
              "\n",
              "[1240 rows x 11 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-55c07e92-6ac8-4d9a-8f35-134d3e397c70\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Unnamed: 0</th>\n",
              "      <th>ID</th>\n",
              "      <th>first_party</th>\n",
              "      <th>second_party</th>\n",
              "      <th>fact</th>\n",
              "      <th>issued_area</th>\n",
              "      <th>sen_len</th>\n",
              "      <th>word_len</th>\n",
              "      <th>winning_percent</th>\n",
              "      <th>승률범주형분류</th>\n",
              "      <th>fact_processing</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0</td>\n",
              "      <td>TEST_0000</td>\n",
              "      <td>others</td>\n",
              "      <td>GPE</td>\n",
              "      <td>The 1984 Bail Reform Act allowed the federal c...</td>\n",
              "      <td>others</td>\n",
              "      <td>2</td>\n",
              "      <td>55</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>bail reform act allow feder court detain arres...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>1</td>\n",
              "      <td>TEST_0001</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>ORG</td>\n",
              "      <td>Lexecon &lt;p2&gt; was a defendant in a class action...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>209</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>lexecon &lt;p2&gt; defend class action lawsuit usc s...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>2</td>\n",
              "      <td>TEST_0002</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>In 2002 and 2003, &lt;p2&gt; Stations broadcast the ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>181</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;p2&gt; station broadcast billboard music award a...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>3</td>\n",
              "      <td>TEST_0003</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>During his trial for armed robbery of a federa...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>99</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>trial arm robberi feder insur save loan associ...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>4</td>\n",
              "      <td>TEST_0004</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>others</td>\n",
              "      <td>In 1993, a magistrate judge issued a warrant a...</td>\n",
              "      <td>others</td>\n",
              "      <td>6</td>\n",
              "      <td>154</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>magistr judg issu warrant author search paul e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1235</th>\n",
              "      <td>1235</td>\n",
              "      <td>TEST_1235</td>\n",
              "      <td>ORG</td>\n",
              "      <td>ORG</td>\n",
              "      <td>According to Executive Order No. 12807 signed ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>5</td>\n",
              "      <td>156</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>accord execut order sign presid georg h w bush...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1236</th>\n",
              "      <td>1236</td>\n",
              "      <td>TEST_1236</td>\n",
              "      <td>others</td>\n",
              "      <td>ORG</td>\n",
              "      <td>Section 109(a) of the Clean Air Act (CAA) requ...</td>\n",
              "      <td>criminal</td>\n",
              "      <td>7</td>\n",
              "      <td>221</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>section clean air act caa requir environment p...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1237</th>\n",
              "      <td>1237</td>\n",
              "      <td>TEST_1237</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>&lt;p1&gt; created a plan for utilizing $2.6 million...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>236</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>&lt;p1&gt; creat plan util million fund offic hous e...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1238</th>\n",
              "      <td>1238</td>\n",
              "      <td>TEST_1238</td>\n",
              "      <td>ORG</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>In 1972, the North Carolina Board of Agricultu...</td>\n",
              "      <td>others</td>\n",
              "      <td>3</td>\n",
              "      <td>84</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>north carolina board agricultur adopt regul re...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1239</th>\n",
              "      <td>1239</td>\n",
              "      <td>TEST_1239</td>\n",
              "      <td>PERSON</td>\n",
              "      <td>GPE</td>\n",
              "      <td>On August 23, 1961, Dr. Paul Berheldt was stab...</td>\n",
              "      <td>others</td>\n",
              "      <td>12</td>\n",
              "      <td>240</td>\n",
              "      <td>0.5</td>\n",
              "      <td>3</td>\n",
              "      <td>august dr paul berheldt stab death kitchen hom...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1240 rows × 11 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-55c07e92-6ac8-4d9a-8f35-134d3e397c70')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-55c07e92-6ac8-4d9a-8f35-134d3e397c70 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-55c07e92-6ac8-4d9a-8f35-134d3e397c70');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "predictions = best_model.predict([X_test_text, X_test_numeric, X_test_categorical])\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JB7jhdyR5ZY_",
        "outputId": "1da96414-563c-40a5-afd9-6ff5cf8d9978"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "39/39 [==============================] - 13s 334ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "threshold = 0.5\n",
        "binary_predictions = [1 if pred >= threshold else 0 for pred in predictions]\n",
        "\n",
        "# 이진 분류 결과 출력\n",
        "pd.DataFrame(binary_predictions).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "CIeLDCpp8GSx",
        "outputId": "8a57c1ef-69d2-4787-eefb-fa73023925eb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    1231\n",
              "0       9\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 86
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit = pd.read_csv(\"/content/drive/MyDrive/DACON_JudgmentPrediction/data/sample_submission.csv\")"
      ],
      "metadata": {
        "id": "nQy9vvcr9SCA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "submit[\"first_party_winner\"] = binary_predictions\n"
      ],
      "metadata": {
        "id": "53lf1tCP9iO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pd.DataFrame(binary_predictions).value_counts()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0_7lW1E79mvV",
        "outputId": "3abc9cca-71e9-4e29-89a2-d8c93eed9db7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1    971\n",
              "0    269\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "submit.to_csv(\"bert_submit.csv\", index=False)\n"
      ],
      "metadata": {
        "id": "Tuz8D1Ve9lj0"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}